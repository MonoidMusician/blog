<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="https://blog.veritates.love/rss.xml" rel="self" type="application/rss+xml" />
<title>MonoidMusicianʼs blog</title>
<link>https://blog.veritates.love</link>
<description>MonoidMusicianʼs blog</description>
<language>en-US</language>
<copyright>GPLv3</copyright>
<docs>https://www.rssboard.org/rss-specification</docs>
<generator>pandoc-rss</generator>
<item>
<title>Efficient Quapteryx Evaluator</title>
<pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/quapteryx4.html</guid>
<description><![CDATA[<div class="centered">
<p><em>Continued from <a href="https://blog.veritates.love/quapteryx3.html">Quapteryx Part III: Quaternary Combinators</a>, where I was writing WASM by hand and then ported it to C and got it working.</em></p>
</div>
<p>The next step was rewriting it from scratch for an efficient evaluator, and this is where I realized that having C structs and pointers (and malloc!) was really what I needed. I used <a href="https://wingolog.org/archives/2020/10/13/malloc-as-a-service">walloc.c</a> for the malloc implementation, also to keep it lightweight and WASMy.</p>
<p>Thus the stack is clang + LLVM + walloc.c + WASM builtins + a JS wrapper to run it.</p>
<h2 id="evaluation-in-practice">Evaluation in Practice</h2>
<p>Letʼs talk about what this new evaluator looks like.</p>
<h3 id="operand-datatypes">Operand datatypes</h3>
<p>The meaning (the denotation) of an operand is always given by the crumbstring it represents, even though we use thunking and other representations for efficiency.</p>
<p>Specifically an operand may be a singular word (&lt;32 crumbs, since a well-formed operand is always an odd number of crumbs), called an immediate operand. If it is not an immediate operand, it is a shared operand, which are our version of thunks.</p>
<p>These thunks are managed with ref counting: ref counting fits very well for this application<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> because references are acyclic, thunks only ever form a <span data-t="" data-widget="">DAG</span>, not a graph with cycles.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Shared operands come in two flavors: arbitrary-length crumbstrings allocated on the heap, and synthetic application nodes created during evaluation (to replace tthe burden of copying crumbstrings with mere pointer references (and refcounting)).</p>
<pre class="c"><code>​////////////////////////////////////////////////////////////////////////////////
// Data structures for operands: immediate or shared (heap or synthetic)      //
////////////////////////////////////////////////////////////////////////////////

// An operand is either shared (heap or synthetic), or an inline word (immediate).
typedef struct operand {
  union {
    struct shared_operand* shared;
    word crumbs;
  };
  bool immediate; // false: shared, true: crumbs
} operand;

// A shared operand is ref-counted and used for sharing work from lazy evaluation.
// The pointer it stores is updated after it is evaluated, and `work` increased.
typedef struct shared_operand {
  int ref_count;
  word work;
  union {
    struct synthetic_operand* synth;
    struct heap_operand* heap;
  };
  bool on_heap; // false: synth, true: heap
  // These bound indices of weakrefs `was_evaling` on the stack, so they can
  // be zeroed out when this `shared_operand` is freed. If they are already
  // zeroed out or otherwise replaced, this is fine!
  int weakref_stack_min;
  int weakref_stack_max;
} shared_operand;

// An operand on the heap. As the `shared_operand` that owns this `heap_operand`
// is evaluated, it will (eventually) free this `heap_operand` and replace
// it with a new one so that the evaluation is shared.
//
// Terms that are immediate but too large to fit into a word also end up
// as a `heap_operand`.
typedef struct heap_operand {
  int length; // length in words
  word crumbstring[];
} heap_operand;

// A synthetic apply node, produced during evaluation of `S`. It counts as a
// single reference to its operands while it is alive. It represents the
// crumbstring `0(fun)(arg)`.
typedef struct synthetic_operand {
  operand fun;
  operand arg;
} synthetic_operand;</code></pre>
<div class="Details" data-box-name="Memory management">
<p>Each shared operand owns its heap or synthetic application node.</p>
<p>In rare circumstances, when a thunk is evaluated, they can be transferred from one shared operand to another, but generally this does not happen: they stay with their shared operand.</p>
</div>
<p>So, in my view, one of the most important functions is <code class="c">write_out(operand op)</code>: it gives us the <em>denotation</em> – its meaning as a crumbstring.</p>
<pre class="c"><code>// Write out an operand into the output buffer. This is an important operation
// because it gives the semantics of operands as crumbstrings! ^^
void write_out(const operand op) {
  goodptrbit(output_at);
  if (op.immediate) {
    const u8 len = reachesZero(1, op.crumbs);
    copy_to_unaligned(from_ptr(output_words, output_at), &amp;op.crumbs, output_at.bit, 1, false);
    output_at = ptrbit_incr_bits(output_at, len);
    drop(op);
  } else if (op.shared-&gt;on_heap) {
    const word len = bitlength(op.shared-&gt;heap-&gt;crumbstring, op.shared-&gt;heap-&gt;length);
    copy_to_unaligned(from_ptr(output_words, output_at), op.shared-&gt;heap-&gt;crumbstring, output_at.bit, len % word_size, false);
    output_at = ptrbit_incr_bits(output_at, len);
    drop(op);
  } else {
    // Write a zero crumb `0q0` (application)
    // (we may have written other bits to the word already, from hapless copying)
    word_of(output_words, output_at) &amp;= mask_hi(output_at.bit);
    output_at = ptrbit_incr_bits(output_at, 2);
    // Write each operand
    write_out(op.shared-&gt;synth-&gt;fun);
    write_out(op.shared-&gt;synth-&gt;arg);
    drop(op);
  }
}</code></pre>
<p>Thatʼs, uh … thatʼs kind of ugly. Thanks, C!</p>
<p>Letʼs try this again, in <a href="https://www.explainxkcd.com/wiki/index.php/1312:_Haskell">pseudo-Haskell</a>.</p>
<pre class="haskell"><code>data Operand
  = Immediate Word
  | Shared (IORef Shared)
data Shared
  = OnHeap [Word]
  | Synthetic (Operand, Operand)

operandToCrumbs :: Operand -&gt; IO Text
operandToCrumbs (Immediate crumbs) = do
  pure (wordToCrumbs crumbs)
operandToCrumbs (Shared ref) = do
  lastEvaluatedTo &lt;- readIORef ref
  case lastEvaluatedTo of
    OnHeap crumbstring -&gt; do
      pure (wordsToCrumbs crumbstring)
    Synthetic (fun, arg) -&gt; do
      pure "0"
        &lt;&gt; operandToCrumbs fun
        &lt;&gt; operandToCrumbs arg

wordsToCrumbs :: [Word] -&gt; Text
wordsToCrumbs = go 1
  where
    go exp [] = undefined
    go exp [final] =
      wordToCrumbs (Just (reachesZero exp final)) final
    go exp (head : tail) =
      wordToCrumbs Nothing head
        &lt;&gt; go (exp - deltaExpecting head) tail

wordToCrumbs :: Maybe Int -&gt; Word -&gt; Text
-- Convert the full word to text, 32 crumbs
wordToCrumbs Nothing word =
  let
    shown = showIntAtBase 4 showInt word
    width = (bitSize word) / 2
  in
    replicate (width - length shown) "0" &lt;&gt; shown
-- Truncate to the leading crumbs of the word
wordToCrumbs (Just numberOfCrumbs) word =
  take numberOfCrumbs (wordToCrumbs Nothing word)</code></pre>
<h3 id="stack">Stack</h3>
<p>The role of the stack is simple: it queues arguments (in whatever form they show up in).</p>
<p>This is exactly the metaphorical stack that weʼve talked about in the grammar of Ojo and now Quaternary Combinators – reified as a data structure now.</p>
<p>Semantically speaking, the stack always represents a function application: the top of the stack is applied to all the remaining items: <code>fun arg_1 arg_2 ... arg_n</code>, which needs to be left-nested in binary applications like <code>(((fun arg_1) arg2) ...) arg_n</code>.</p>
<p>However, the stack is also where we need to keep track of the thunks that we are evaluating.</p>
<pre class="c"><code>////////////////////////////////////////////////////////////////////////////////
// Stack, for evaluation                                                      //
////////////////////////////////////////////////////////////////////////////////

#define SZ 1024

// When you evaluate an application node `0xy`, `y` goes onto the stack (first)
// and `x` is the new top of stack. Reaching `I`, `K`, or `S` will pop from the
// stack and push back onto it: `Sxyz = xz(yz)` will create a synthetic operand
// for its last value `(yz)` in doing so.
//
// The interpreter wants to maintain one thing on the stack (mostly to keep
// the `was_evaling` pointer for simplicity). If it reaches zero for real, that
// means it is time to stop evaluation: then the value of `was_evaluting` would
// theoretically be the whole input/output node.
struct stack_frame {
  operand to_eval;
  shared_operand* was_evaling; // weak ref! must be zeroed out when freed
} stack[SZ];
u32 stack_top = 0;

// Create a new stack frame, without `was_evaling`.
#define FRAME(value) ((struct stack_frame) { .to_eval = (value) })</code></pre>
<p>You should think of this stack as an interleaving of <code class="c">was_evaling</code> with <code class="c">to_eval</code>.</p>
<pre class="c"><code>// stack[0].was_evaling should always be NULL
stack[0].was_evaling = NULL;
// since we *are* evaluating the top argument
stack[0].to_eval // the head of the expression

// Once it is a lone combinator, its value goes in
stack[1].was_evaling
  // (i.e. WHNF_I0, WHNF_K0, WHNF_S0)
// And then you have this argument
stack[1].to_eval

// Their synthetic application goes into
stack[2].was_evaling
  // (i.e. WHNF_K1, WHNF_S1)
// And the next argument
stack[2].to_eval

// The last thunk for the head is
stack[3].was_evaling
  // (i.e. WHNF_S2)
// And the last argument available to `S`
stack[3].to_eval

// Then the rest of the stack is merely pending,
// waiting for the head to reduce enough to
// continue on with them, if it ever does!</code></pre>
<p>So the goal of the <span data-t="" data-widget="">WHNF</span> evaluator is to unpack all function applications, saving their arguments onto the stack along the way, in order to get down to a lone combinator on the left: this is the first nonzero digit in the crumbstring.</p>
<p>Then the <span data-t="" data-widget="">WHNF</span> evaluator keeps performing reductions on the top of this stack. While the top operand is <code class="st">1</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span>, <code class="st">2</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>, or <code class="st">3</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span>, it can perform a reduction. Otherwise it needs to unpack more applications: save <em>those</em> arguments to the stack, and recurse into the function side.</p>
<p>When the stack underflows, it needs to parse a new operand from the input buffer, advancing its state. <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> If the input buffer is already at the end, the <span data-t="" data-widget="">WHNF</span> evaluation is complete: it is in Weak Head Normal Form!</p>
<p>In this state, the top of the stack is a combinator <code class="st">1</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span>, <code class="st">2</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>, or <code class="st">3</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span>, and the total stack size (including this combinator) is less than or equal to its digit value. The <span data-t="" data-widget="">WHNF</span> expression can be then read off of the stack like this.</p>
<p>Note that this is not a complete normal form: just because reductions stopped at the head does not mean that every operand is normalized – the rest of the stack can still be arbitrary operands!</p>
<p>So a <span data-t="" data-widget="">NF</span> evaluator needs to restart <span data-t="" data-widget="">WHNF</span> evaluation for each sub-expression, track their results, and re-assemble the tree. However, once each subexpression from left-to-right stops in <span data-t="" data-widget="">WHNF</span>, then its <em>head</em> can be written out to the output buffer: that portion of the crumbstring is already set in stone.</p>
<h3 id="input-and-output">Input and output</h3>
<p>I already alluded to input and output buffers earlier.</p>
<p>They are not too complicated, just long crumbstrings that maintain some state:</p>
<pre class="c"><code>ptrbit input_at = {};
ptrbit stop_at = {};
ptrbit output_at = {};

// read once
word input_words[SZ];
// write once
word output_words[SZ];</code></pre>
<p>I just think it is neat that this evaluation algorithm is “streaming”, in the sense that it reads each crumb of the input buffer once when it is otherwise stuck on evaluations, and it writes crumbs to the output buffer once when it really <em>is</em> stuck on evaluations.</p>
<h3 id="beta-reductions">Beta Reductions</h3>
<p>This is the core of the evaluation algorithm: beta reductions for each combinator.</p>
<p>More special cases could be added for other combinators, like <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span> and so on!</p>
<details class="Details">
<summary>
Code
</summary>
<pre class="c"><code>// This is the procedure to pop an item from the stack: if the stack is
// empty, we try to refill it from the input buffer, and if we cannot, then
// we have to return. If it succeeded, we save it to the given variable.
#define POP_OR(lvalue, stmt) BLOCK( \
  if (!stack_top &amp;&amp; !refill()) { \
    stmt; __builtin_trap(); \
  }; \
  lvalue = stack[--stack_top].to_eval; \
  assert(stack[stack_top].was_evaling = NULL); \
)
// Now we handle the particular opcodes: I=1, K=2, S=3
if (crumb == 1) {
  // Check that there is an argument available; otherwise, we need to restore
  // the head operand back to the stack
  if (!stack_top &amp;&amp; !refill()) { stack_top += 1; return false; }

  // Just drop this identity node, good riddance
  // (Morally we pop the argument and push it back onto the stack.)
  work++;
  return true;
} else if (crumb == 2) {
  // Get two arguments
  operand x, y;
  POP_OR(x, { stack_top += 1; return false; });
  // TODO: tell `refill()` that it does not need to actually copy this operand?
  POP_OR(y, { stack_top += 2; return false; });

  // Drop `y` and put `x` back onto the stack: `Kxy = x`
  drop(y);
  stack[stack_top++] = FRAME(x);
  work++;
  return true;
} else if (crumb == 3) {
  // Get three arguments
  operand x, y, z;
  POP_OR(x, { stack_top += 1; return false; });
  POP_OR(y, { stack_top += 2; return false; });
  POP_OR(z, { stack_top += 3; return false; });

  // `Sxyz = 00xz0yz = ((xz)(yz))`
  // Increase the ref count on `z`
  z = dup(z);
  // Put `x`, `z`, and the synthetic `(yz)` on the stack
  operand yz = apply(y, z);
  stack[stack_top++] = FRAME(yz);
  stack[stack_top++] = FRAME(z);
  stack[stack_top++] = FRAME(x);
  work++;
  // Evaluation will continue with `x` on the next `step()`!
  return true;
}</code></pre>
</details>
<h3 id="unpacking-applications">Unpacking applications</h3>
<p>On the other hand, sometimes we have to unpack the synthetic applications we created while reducing <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span>:</p>
<details class="Details">
<summary>
Code
</summary>
<pre class="c"><code>// We might as well walk the spine of synthetic applications here in a tight
// loop, instead of waiting for the next `step();`
operand spine = op;
// #pragma unfold(2)
while (!spine.immediate &amp;&amp; !spine.shared-&gt;on_heap) {
  shared_operand* this = spine.shared;
  if (stack_top &amp;&amp; this-&gt;ref_count &gt; 1) {
    stack_was_evaling(stack_top, spine.shared);
  }
  // Now we add it onto the stack
  stack[++stack_top] = FRAME(dup(this-&gt;synth-&gt;arg));
  // And proceed down the spine
  spine = this-&gt;synth-&gt;fun;
}
// Finally, whatever we ended up with is at the top of the stack.
stack[++stack_top] = FRAME(dup(spine));
// And free the spine (all the arguments were dup'ed, so are safe)
drop(op);
return true;</code></pre>
</details>
<p>A little more complicated, but still the same idea, is unpacking a crumbstring from a shared heap value.</p>
<details class="Details">
<summary>
Code
</summary>
<pre class="c"><code>// Cache the amount of bytes
const int bytes = sizeof(word) * op.shared-&gt;heap-&gt;length;
// Here is the crumbstring
word* crumbstring = op.shared-&gt;heap-&gt;crumbstring;
// Start at the first crumb
ptrbit i = (ptrbit) {};

// Count the leading zero crumbs
{
  // Whole words
  while (i.ptr &lt; bytes &amp;&amp; word_of(crumbstring, i) == 0) {
    i.ptr += sizeof(word);
  }
  // Remaining crumbs
  i.bit = clz(word_of(crumbstring, i)) &amp; ~1;
}

// This is now our arity
const word arity = ptrbit2crumbs(i);

// Increase stack_top already, and then we will walk back and fill in the
// arguments on the stack.
stack_top += arity;
for (int stacked = 0; stacked &lt; arity; stacked++) {
  goodptrbit(i);
  const ptrbit last = i;
  // Scan ahead one item
  i = scan1(crumbstring, last, (ptrbit) { .ptr = bytes, .bit = 0 });
  const int crumblen = ptrbit2crumbs(i) - ptrbit2crumbs(last);
  // Copy it into its own heap
  shared_operand* sh = alloc_shared_heap(ROUNDUPDIV(crumblen, word_crumbs));
  copy_from_unaligned(sh-&gt;heap-&gt;crumbstring, from_ptr(crumbstring, last), last.bit, sh-&gt;heap-&gt;length);
  // And plop it on the stack
  stack[stack_top - stacked] = FRAME(shared(sh));
}
return true;</code></pre>
</details>
<h2 id="appendix-links">Appendix: Links</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Iota_and_Jot" class="uri">https://en.wikipedia.org/wiki/Iota_and_Jot</a></li>
<li><a href="https://en.wikipedia.org/wiki/SKI_combinator_calculus#SKI_expressions" class="uri">https://en.wikipedia.org/wiki/SKI_combinator_calculus#SKI_expressions</a></li>
<li><a href="https://crypto.stanford.edu/~blynn/lambda/cl.html" class="uri">https://crypto.stanford.edu/~blynn/lambda/cl.html</a></li>
<li><a href="https://crypto.stanford.edu/~blynn/lambda/crazyl.html" class="uri">https://crypto.stanford.edu/~blynn/lambda/crazyl.html</a></li>
<li><a href="https://web.archive.org/web/20160823182917/http://semarch.linguistics.fas.nyu.edu/barker/Iota" class="uri">https://web.archive.org/web/20160823182917/http://semarch.linguistics.fas.nyu.edu/barker/Iota</a></li>
<li><a href="https://doisinkidney.com/posts/2020-10-17-ski.html" class="uri">https://doisinkidney.com/posts/2020-10-17-ski.html</a></li>
<li><a href="https://www.angelfire.com/tx4/cus/combinator/birds.html" class="uri">https://www.angelfire.com/tx4/cus/combinator/birds.html</a></li>
<li><a href="https://cs.stackexchange.com/questions/57361/combinator-equivalent-to-eta-conversion#57371" class="uri">https://cs.stackexchange.com/questions/57361/combinator-equivalent-to-eta-conversion#57371</a></li>
<li><a href="https://olydis.medium.com/one-point-bases-for-%CE%BB-calculus-4163b1b326ad" class="uri">https://olydis.medium.com/one-point-bases-for-%CE%BB-calculus-4163b1b326ad</a></li>
<li><a href="http://www.chriswarbo.net/blog/2024-05-10-sk_logic_in_egglog_4.html" class="uri">http://www.chriswarbo.net/blog/2024-05-10-sk_logic_in_egglog_4.html</a></li>
<li><a href="https://okmij.org/ftp/tagless-final/ski.pdf" class="uri">https://okmij.org/ftp/tagless-final/ski.pdf</a></li>
<li><a href="https://cs.stackexchange.com/questions/57476/what-functions-can-combinator-calculus-expressions-compute" class="uri">https://cs.stackexchange.com/questions/57476/what-functions-can-combinator-calculus-expressions-compute</a></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>as opposed to garbage collectors<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This can be seen in the fact that each operand represents a crumbstring, which is a finite data structure, and introducing sharing between equal substrings does not introduce cycles!<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>You could just pre-scan the whole input and put it onto the stack, reversed, but that seems less elegant to me than lazily consuming the input.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Quaternary Combinators</title>
<pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/quapteryx3.html</guid>
<description><![CDATA[<div class="centered">
<p><em>See <a href="https://blog.veritates.love/quapteryx1.html">Quapteryx Part I: On the SKI Combinator Calculus</a> and <a href="https://blog.veritates.love/quapteryx2.html">Quapteryx Part II: Ojo: a Bitflipped Jot, and a Real Flop</a> for introduction/background on this topic.</em></p>
</div>
<p>Quaternary combinators.</p>
<p>If binary is base 2, then quaternary is base 4. Just as binary has bits (digits) and bitstrings (sequences of digits), quaternary has <a href="https://en.wikipedia.org/wiki/Quaternary_numeral_system#Relation_to_binary_and_hexadecimal">crumbs</a> and crumbstrings:</p>
<blockquote>
<p>By analogy with <em>byte</em> and <em>nybble</em>, a quaternary digit is sometimes called a <em>crumb</em>.</p>
</blockquote>
<p>Quapteryx, archaeopteryx.</p>
<p>Like Ojo, Quapteryx can be defined by a suffix-based translation to SK combinators. Unlike Ojo, it is simpler to define and <em>much</em> simpler to work with: one digit for each combinator, and <code class="st">0</code> to glue them together.</p>
<figure>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mi>I</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>0</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>2</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>3</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{ll}
[]   &amp;\triangleq I \\
[w0] &amp;\triangleq S(K([w])) \\
[w1] &amp;\triangleq [w](I) \\
[w2] &amp;\triangleq [w](K) \\
[w3] &amp;\triangleq [w](S) \\
\end{array}
</annotation></semantics></math></span></p>
<figcaption>
The translation of the empty string is the I combinator. The translation of a trailing zero is S applied to K applied to the translation of the rest of the string. The translation of each trailing digit 1, 2 or 3 is the translation of the prefix applied to the combinator I, K, or S, respectively – we will think of these as being pushed to the metaphorical stack of pending function arguments.
</figcaption>
</figure>
<p>In this way it mirrors the syntax of Iota (and the pure combinator fragment of Unlambda) more precisely, bridging the gap between Iota and Jot. Well-formed/atomic “operands” are defined by this simple grammar:</p>
<figure>
<pre><code>&lt;operand&gt; ::= "0" &lt;operand&gt; &lt;operand&gt; | "1" | "2" | "3"</code></pre>
<figcaption>
An operand is one of these productions: 1, 2, or 3 alone, or 0 followed by two operands.
</figcaption>
</figure>
<p>And the translation of arbitrary quaternary combinators into well-formed operands just needs to count crumbs and use this one fact to deal with zeros that “underflow” the stack (<span data-t="" data-widget="">e.g.</span> trailing zeros): <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>0</mn><mo stretchy="false">]</mo><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mn>0302</mn><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[w0] =_\beta [0302w]</annotation></semantics></math></span>.</p>
<p>For other zeros, those that are followed by enough operands, we have the key idea that <code class="st">0</code> operates as function application on a stack:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>0</mn><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">[w0\vec x\vec y] =_\beta [w]( [\vec x] [\vec y] ).</annotation></semantics></math></span></p>
<p>For example, we can get <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(SK)</annotation></semantics></math></span> on the stack by having two items <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(S)</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(K)</annotation></semantics></math></span> on the stack, and then using <code class="st">0</code> to apply them together:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>032</mn><mo stretchy="false">]</mo><mo>≜</mo><mo stretchy="false">[</mo><mi>w</mi><mn>0</mn><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">[w032] \triangleq [w0](S)(K) =_\beta [w](SK).</annotation></semantics></math></span></p>
<hr>
<p>The <em>really</em> cool fact is that each combinator is represented by its <em>arity</em>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> takes one argument, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> takes two, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> needs three to compute.</p>
<p>This means that (at least in well-formed operands), seeing beta reductions is trivial: just count the zeros before each nonzero digit: <code class="st">01x</code> reduces, <code class="st">002xy</code> reduces, <code class="st">0003xyz</code> reduces.</p>
<p>As discussed before, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> is technically redundant in this picture: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><msub><mo>≈</mo><mi>η</mi></msub><mi>S</mi><mi>K</mi><mi>x</mi><msub><mo>≈</mo><mi>η</mi></msub><mi>S</mi><mi>K</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">I \approx_\eta SKx \approx_\eta SKK</annotation></semantics></math></span>, or <code class="st">1 = 00322</code> in Quapteryx. However, including <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> is important for efficiency for several reasons:</p>
<ul>
<li>Most importantly, having quaternary combinators is better for computers than ternary combinators: everything stays nicely aligned to bits.</li>
<li>It fills out the arity–digits correspondence very nicely.</li>
<li><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">Ix</annotation></semantics></math></span> is easy to identify as a trivial reduction, whereas <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>x</mi><mi>y</mi><mi>z</mi></mrow><annotation encoding="application/x-tex">Sxyz</annotation></semantics></math></span> is a nontrivial reduction in general, so having <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> lets us spot more performance opportunities, potentially.</li>
</ul>
<h2 id="evaluation-in-theory">Evaluation in Theory</h2>
<p>Letʼs talk about the theory of SKI combinators using our syntactic model of crumbstrings.</p>
<p>We have these beta reduction rules, which are are allowed to apply anywhere in the string to generate a reduced string, as long as <code>&lt;x&gt;</code>, <code>&lt;y&gt;</code>, and <code>&lt;z&gt;</code> are well-formed operands:</p>
<figure>
<pre><code>01&lt;x:operand&gt; = &lt;x:operand&gt;
002&lt;x:operand&gt;&lt;y:operand&gt; = &lt;x:operand&gt;

0003&lt;x:operand&gt;&lt;y:operand&gt;&lt;z:operand&gt;
  = 00&lt;x:operand&gt;&lt;z:operand&gt;0&lt;y:operand&gt;&lt;z:operand&gt;</code></pre>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="right left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mn>01</mn><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mn>002</mn><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mn>0003</mn><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mover accent="true"><mi>z</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">[</mo><mn>00</mn><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mover accent="true"><mi>z</mi><mo>⃗</mo></mover><mn>0</mn><mover accent="true"><mi>y</mi><mo>⃗</mo></mover><mover accent="true"><mi>z</mi><mo>⃗</mo></mover><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{rl}
[01\vec x] &amp;=_\beta [\vec x] \\
[002\vec x\vec y] &amp;=_\beta [\vec x] \\
[0003\vec x\vec y\vec z] &amp;=_\beta [00\vec x\vec z0\vec y\vec z] \\
\end{array}
</annotation></semantics></math></span></p>
<figcaption>
“01x” beta reduces to “x”, “002xy” reduces to “x”, and “0003xyz” reduces to “00xz0yz”.
</figcaption>
</figure>
<p>If the first nonzero digit is irreducible (not enough following operands, which corresponds to not enough leading zeros for a well-formed operand), then the operand is in “Weak Head Normal Form” (<span data-t="" data-widget="">WHNF</span>). If all digits are irreducible, then it is in Normal Form (<span data-t="" data-widget="">NF</span>). The normal form, if it exists, is unique for an operand: any reduction sequence that terminates finds that same normal form when it becomes irreducible.</p>
<p>We can describe these properties on <span data-t="" data-widget="">AST</span>s (Abstract Syntax Trees, represented as Haskell data types):</p>
<pre class="haskell"><code>-- A well-formed operand is a binary tree
-- with combinators at its leaves
data Operand
  = Q0 Operand Operand
  | Q1
  | Q2
  | Q3

-- Only the top level of a WHNF node needs
-- to be evaluated to an irreducible operand
-- (Weak Head Normal Form)
data WHNF
  = WHNF_I0
  | WHNF_K0
  | WHNF_K1 Operand
  | WHNF_S0
  | WHNF_S1 Operand
  | WHNF_S2 Operand Operand

-- Every level of a Normal Form node needs
-- to be evaluated to an irreducible operand
data NF
  = NF_I0
  | NF_K0
  | NF_K1 NF
  | NF_S0
  | NF_S1 NF
  | NF_S2 NF NF</code></pre>
<div class="Note">
<p>The tradeoff between the string representation and the <span data-t="" data-widget="">AST</span>s is that in the <span data-t="" data-widget="">AST</span>, you have to drill down into the <code class="haskell.dt">Q0</code> nodes to see if there is a reduction, but then the arguments are already nicely separated for you, whereas in the string representation, you just have to scan from left to right, and then you have to parse out the arguments from the remaining bitstring (and check that there are enough, if it isnʼt guaranteed to be a valid operand string already).</p>
</div>
<p>So hopefully you see that Weak Head Normal Form isnʼt so scary after all, and Normal Form is just a recursive version of it. And “recursive” in the model of crumbstrings means that it is applied everywhere in the string.</p>
<p>Later we will come up with a stack-based algorithm for efficiently computing <span data-t="" data-widget="">WHNF</span> (it sort of sits and “spins” on the leftmost nonzero digit always), and we see how we will have to follow the tree structure to apply it to get the full <span data-t="" data-widget="">NF</span>.</p>
<h3 id="evaluation-order">Evaluation Order</h3>
<p>There are many ways to apply reduction rules. You could choose a unique reduction order for every string if you wanted. Or pick a reduction totally at random each other.</p>
<p>However, there are only a few coherent strategies for choosing reductions that are generally used.</p>
<p>Right-to-left evaluation is the simplest to explain: this is “applicative order evaluation”, where arguments (on the right) are reduced before their functions (on the left) are “called” with their evaluated result. This corresponds to strict programming languages, and is very common and familiar.</p>
<p>This is the simplest, and relatively performant, but it has a big downside: for arguments that are eventually discarded, it has performed unnecessary work evaluating them, and worst of all, it can get trapped in senseless nontermination. A lot of the “recursion combinators” that are commonly used for SKI calculus do not terminate under applicative order evaluation.</p>
<p>Left-to-right evaluation (to <span data-t="" data-widget="">WHNF</span> and then recursively to <span data-t="" data-widget="">NF</span>) solves this problem: all programs that <em>do</em> terminate, terminate under left-to-right evaluation. (Of course this is an <a href="https://en.wikipedia.org/wiki/Halting_problem">undecidable</a> proposition.)</p>
<p>“Aha! This is lazy evaluation, the dual of strict evaluation” you might say. Not so fast – we have to be careful.</p>
<p>True lazy evaluation uses <em>thunks</em> to share the results of evaluation: when a function duplicates an argument (in our case: <code>Sxyz = (xz)(yz)</code> duplicates <code>z</code>), it ensures it is stored in a thunk so work can be shared efficiently. Once the thunk is evaluated the first time (partially or fully), its value is updated, and the other occurrences of the thunk can then use this value to avoid duplicating work. And if the thunk is never demanded, no work is done to evaluate it.</p>
<p>Naïve left-to-right evaluation does not do this, there is no concept of a thunk. Instead each argument that is duplicated is re-evaluated from scratch every time. This is very inefficient for several reasons (not only the time inefficiency of duplicating the work, but the space inefficiency of duplicating many arguments before evaluating them), but at least it still finds normal forms for all terminating programs like lazy evaluation does. This is sometimes called “normal order evaluation” in the literature.</p>
<hr>
<p>So these are the three main evaluation strategies: right-to-left or “applicative order”, left-to-right or “normal order”, and lazy evaluation.</p>
<p>For Quapteryx, we want to generally implement lazy evaluation, for its nice termination properties, but we wonʼt implement it precisely correctly: we may cut some corners (such as not duplicating words that only contain trivial reductions, or evaluating those trivial reductions early).</p>
<h3 id="bithacking">Bithacking</h3>
<p>This is the transition from theoretical evaluation to practical evaluation.</p>
<p>The grammar of Quapteryx is so well-behaved that we can implement things really efficiently using bitwise operations. Itʼs what inspired me to actually implement it, and to chose lower-level languages for the task.</p>
<p>But the caveat here is that we donʼt want to end up with packed crumbstrings for our only representation. Copying crumbstrings (especially since it is unaligned memory!) is quadratically inefficient, and not being able to use thunks misses the whole point of it. So this is just the groundwork for an efficient evaluator, not the end result.</p>
<h4 id="redexes">Redexes</h4>
<p>A “redex” is a place where you can apply a reduction: a <em>reducible expression</em> within the larger expression tree.</p>
<p>In our case, since we are looking at well-formed operands in this evaluator, we have a very simple way to identify redexes: it is a nonzero digit preceded by that many zeros! Thus its arity is satisfied.</p>
<p>Thus redexes always occur at <code class="st">01</code>, <code class="st">002</code>, and <code class="st">0003</code>. These redex heads are followed by one, two, and three arguments respectively, and we have to parse those out of the crumbstring: but thatʼs work that we only have to do once weʼve identified the redex, which is pretty simple to do.</p>
<p>In fact, it is so simple that we can scan a whole machine word for reductions at once, in about 23–27 operations (regardless of the size of the word<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>).</p>
<p>Itʼs simpler to start with a function that checks for one type of redex: in this case, <code>S</code> redexes (because they represent nontrivial evaluation). This can be done in ~12 operations.</p>
<pre class="c"><code>// All bits set
static const word word_max = ~0;
// Lower bit of each crumb
static const word lower = word_max / 0b11;

// Coalesce each nonzero crumb (pair of bits) into its lower bit.
word nonzeros(word crumbs) {
  return lower &amp; (crumbs | (crumbs &gt;&gt; 1));
}

// Calculate if there are any `S` redexes exclusively, since `I` and `K` are
// not really a problem for duplicated work. Assumes `leadingZeroBits = 3`
// (or that the word is well-formed).
word nontrivial_redexes(word crumbs) {
  word S;
  // Any nonzero crumb means that the
  // next 3 crumbs cannot be `S` redexes
  S = crumbs &gt;&gt; 2 | crumbs &gt;&gt; 4 | crumbs &gt;&gt; 6;
  // Any any crumb that is not `0b11 = 0q3`
  // cannot be an `S` redex
  S |= crumbs ^ (0b11 * lower);
  // The redexes are then the crumbs where
  // this `S` is zero, so we coalesce them
  // and we give them the value `0b11 = 0q3`
  return ~(0b11 * nonzeros(S));
}</code></pre>
<p>Triplicating this lets us share some work and brings out the patterns:</p>
<pre class="c"><code>static word redexes(u8 leadingZeroBits, word crumbs) {
  word I, K, S;
  I = 0 | crumbs &gt;&gt; 2;
  K = I | crumbs &gt;&gt; 4;
  S = K | crumbs &gt;&gt; 6;
  switch (leadingZeroBits &gt;&gt; 1) {
    case 0:
      I |= ~(word_max &gt;&gt; 2);
      K |= ~(word_max &gt;&gt; 4);
      S |= ~(word_max &gt;&gt; 6);
      break;
    case 1:
      K |= ~(word_max &gt;&gt; 2);
      S |= ~(word_max &gt;&gt; 4);
      break;
    case 2:
      S |= ~(word_max &gt;&gt; 2);
      break;
    default:
      break;
  }
  S |= crumbs ^ (0b11 * lower);
  K |= crumbs ^ (0b10 * lower);
  I |= crumbs ^ (0b01 * lower);
  word ruled_out = (I | I &gt;&gt; 1) &amp; (K | K &gt;&gt; 1) &amp; (S | S &gt;&gt; 1);
  return crumbs &amp; ~(0b11 * (lower &amp; ruled_out));
}</code></pre>
<h4 id="grammar">Grammar</h4>
<p>We also want to do some bithacking for the grammar of operators. Especially once weʼve identified a redex, we need to scan ahead to identify all of its arguments.</p>
<p>We traverse the <code>&lt;operand&gt;</code> grammar by keeping track of an expected number of remaining operands. Each <code class="st">0</code> crumb adds one, and each nonzero crumb (<code class="st">1</code>, <code class="st">2</code>, or <code class="st">3</code>) subtracts one.</p>
<p>The bithacking to keep track of this is really efficient, just 6 operations:</p>
<pre class="c"><code>// Number of bits in a word
static const word word_size = 8*sizeof(word);
// Number of *crumbs* in a word
static const word word_crumbs = word_size / 2;


s8 deltaExpecting(word crumbs) {
  return 2 * popcnt(nonzeros(crumbs)) - word_crumbs;
}</code></pre>
<p><code class="c">word nonzeros(word)</code> is above. <code class="c">word popcnt(word)</code> is short for “population count”: the number of bits that are <code class="dv">1</code> in the word, also known as the <a href="https://en.wikipedia.org/wiki/Hamming_weight">Hamming weight</a>.</p>
<div class="Warning">
<p>Note that this might be backwards from what you expect: <code class="c">s8 deltaExpecting(word crumbs)</code> is expected to be <em>subtracted</em> from expecting: <code class="c">expecting -= deltaExpecting(word);</code> This is so that it is easier to compare them as unsigned numbers.</p>
</div>
<p>The next challenge is to identify where inside a word does the expected number of remaining operands drop to zero: when is the expression <em>complete</em>.</p>
<p>There are sufficient conditions to <em>not</em> be a complete expression: after leading zeros, the value of <code>expecting</code> is <code class="c">expecting + #leading0s</code>, so if the population count of the word overall is less than that, it never reaches zero.</p>
<p>We could technically do a kind of binary search, and/or skip through contiguous zeros, but I have not implemented that yet.</p>
<pre class="c"><code>u8 reachesZero(word expecting, word crumbs) {
  word _nonzeros = nonzeros(crumbs);

  if (expecting + (clz(_nonzeros) &gt;&gt; 1) &gt; popcnt(_nonzeros))
    return 0;

  u8 bit = word_size - 2;
  while (expecting += (0b1 &amp; (_nonzeros &gt;&gt; bit) ? -1 : 1)) {
    if (!bit) return 0;
    bit -= 2;
  }
  return word_size - bit;
}</code></pre>
<p>We combine these to traverse through a whole crumbstring, for example.</p>
<pre class="c"><code>// Calculate the length of the first operand of the passed crumbstring, which is
// more efficient if `known_words != 0` is passed (otherwise it has to examine
// each crumb).
ptrbit ptrbitlength(const word* crumbstring, word known_words) {
  word i = 0; word exp = 1; u8 offset = 0;
  // Quickly scan through `known_words - 1`, using just
  // `deltaExpecting` and not `reachesZero`
  while (i &lt; known_words - 1) {
    exp -= deltaExpecting(crumbstring[i++]);
    assert(exp != 0);
  }
  // Fall through, in case `known_words` was too short.
  // (This is used in `ap_heap_cat`.)
  while (!offset) {
    // See if it reaches zero during the current word
    offset = reachesZero(exp, crumbstring[i]);
    if (!offset) {
      // If not, we need to continue with the next word
      // and adjust the expected number of operands
      exp -= deltaExpecting(crumbstring[i++]);
      assert(exp != 0);
      continue;
    }
  }
  // It needs to be even since it is a bit index of a crumb
  assert((offset &amp; 1) == 0);
  // `i` denotes the index of the word that reached zero
  return (ptrbit) { .ptr = sizeof(word) * i, .bit = offset };
}

// Length of an operand in bits in a crumbstring.
word bitlength(const word* crumbstring, word known_words) {
  return 2 * ptrbit2crumbs(ptrbitlength(crumbstring, known_words));
}</code></pre>
<h2 id="wasm">WASM</h2>
<p>So I mentioned that I originally wanted to target WASM (WebAssembly), and write it by hand to boot. One of the main reasons for this choice was that I like web programming, and I use PureScript for my blog, so it makes sense to try out WASM and see if it really is as performant as it says it is. Plus it is a nice sandboxed format that can be run anywhere.</p>
<h3 id="wasm-by-hand">WASM by hand</h3>
<p>I wrote most of the first naïve evaluator by hand, in the standardized WebAssembly Text format (WAT). I actually got it working at least somewhat: it was able to handle simple reductions just fine, but I couldnʼt get it to handle the factorial function I wanted to “prove” it with. Debugging it was pretty painful, and it was hard to look back at it and want to jump back in.</p>
<p>And there was no way I was going to implement a real evaluator instead of the naïve evaluator, which really did operate on crumbstrings:</p>
<ul>
<li>it would search through the string from left-to-right, copying irreducible parts;</li>
<li>then it would find a redex, parse its arguments off of the crumbstring,</li>
<li>it would then reassemble the crumbstring with the redex evaluated: copying the arguments from the input to the new positions in the output;</li>
<li>finally, it would finish copying the input to the output, and then memcpy the output back over the input.</li>
</ul>
<p>Yeah. Incredible slow for large reductions, but pretty fast for small ones.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h3 id="to-the-c">To the C!</h3>
<p>It turns out that porting it to C wasnʼt too difficult. I found and fixed a couple bugs along the way: soon enough, it was working just as well as the previous one did. And after a bit more debugging I even got the factorial function working, a huge success!</p>
<p>I honestly didnʼt bother trying to find the bugs back in the WASM: some would have been obvious, but others were just mysteriously fixed and I was okay with that.</p>
<p>And running it in C was barely a compromise: the interface of the WASM module changed, since clang, but I was able to keep it bare-bones in other ways: no stdlib, no malloc, just clang/LLVM builtins.</p>
<p>I did that with the help of this blog post (beautiful blog layout btw): <a href="https://surma.dev/things/c-to-webassembly/">“Compiling C to WebAssembly without Emscripten”</a>. The basic command is <code class="sh">clang --target=wasm32 -nostdlib</code>, with some tweaks along the way.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> This gets you from C to LLVM to WASM about as lightweight and minimally as possible: you have pretty good control over the instructions you are writing, and you benefit from the C typechecking (especially structs!) and LLVM optimizations (like inlining and constant folding).</p>
<p>It passed the basic tests I threw at it, but performance of the factorial function dropped off steeply, due to all of the copying and inefficient evaluation:</p>
<table style="width:97%;">
<colgroup>
<col style="width: 35%">
<col style="width: 24%">
<col style="width: 10%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Test</th>
<th style="text-align: right;">Total&nbsp;time</th>
<th style="text-align: left;">Tests</th>
<th style="text-align: right;">Ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code class="nowrap">factorial(0)</code></td>
<td style="text-align: right;">6.21ms</td>
<td style="text-align: left;">x18</td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code class="nowrap">factorial(1)</code></td>
<td style="text-align: right;">21.94ms</td>
<td style="text-align: left;">x18</td>
<td style="text-align: right;">3.5x&nbsp;longer</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code class="nowrap">factorial(2)</code></td>
<td style="text-align: right;">354.50ms</td>
<td style="text-align: left;">x18</td>
<td style="text-align: right;">16.2x&nbsp;longer</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code class="nowrap">factorial(3)</code></td>
<td style="text-align: right;">462.44ms</td>
<td style="text-align: left;">x1</td>
<td style="text-align: right;">23.5x&nbsp;longer</td>
</tr>
</tbody>
</table>
<p><code>factorial(4)</code> fails to evaluate properly, apparently, and I do not feel like debugging it, but it took over 15 seconds to reach the wrong answer, which was a fairly small expression, so it was probably indicative of the rough runtime.</p>
<p><em>insert acknowledgement that these numbers do not deserve this level of reported precision</em></p>
<h4 id="aside-church-numerals-and-factorials">Aside: Church numerals and factorials</h4>
<p>If you are curious, here is an encoding of the factorial function in Quapteryx:</p>
<pre class="st wrap"><code>00030200300322003220030200330200300322003222003020030203003003003003220202032022032030030232003020033020030200302030200330203203020030200330222003020033020030200302030200302030032220300322222</code></pre>
<p>This is adapted from <a href="https://crypto.stanford.edu/~blynn/lambda/sk.html">“A Combinatory Compiler”</a> by Ben Lynn, which also compiles combinator calculus to WASM, but in a different way!</p>
<p>The normal form of Church-encoded natural numbers look like <code class="st">032</code>, <code class="st">0030030232032</code>, <code class="st">00300302320030030232032</code>, and so on, or <code class="python">n*"0030030232" + "032"</code>. This is <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mi>B</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo stretchy="false">(</mo><mi>S</mi><mi>B</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(SB(...(SB(SK))))</annotation></semantics></math></span>, where <code class="st">0030232</code> is the encoding of the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span> combinator: function composition.</p>
<p>That is, once you apply an argument <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span> to it, it reduces to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>f</mi><mo stretchy="false">(</mo><mi>B</mi><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi>B</mi><mi>f</mi><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Bf(Bf(...Bf(I)))</annotation></semantics></math></span>, or the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>-fold composition of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span>.</p>
<p><strong><em>However</em></strong>, you need to be careful: just because the expression is evaluated, doesnʼt mean that the Church number is in normal form! Because of the lack of eta-equivalence in this implementation of combinator calculus, it will evaluate to an expression with the same behavior but spelled a different way in the combinators.</p>
<p>For example, the normal form of <code>factorial(0)</code> is <code class="st">0032032</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi></mrow><annotation encoding="application/x-tex">(SK)(SK) \approx_\eta I</annotation></semantics></math></span>, not <code class="st">0030030232032</code> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mi>B</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(SB)(SK)</annotation></semantics></math></span>. The normal form of <code>factorial(1)</code> is 3359 crumbs <em>long</em>, <code>factorial(2)</code> is 2573 crumbs long (not sure why it is shorter), <code>factorial(3)</code> is 3559 crumbs long, and the rest grow comparatively slowly from there.</p>
<p>Thus my tests went through various irreducible values of <code>m</code> and <code>n</code> to evaluate <code>factorial(3)(m)(n)</code> and ensure that it evaluated to <code>0m0m0m0m0m0mn</code> each time, and so on.</p>
<div class="centered">
<p><em>Read on at <a href="https://blog.veritates.love/quapteryx4.html">Quapteryx Part IV: Quapteryx Takes Flight</a>.</em></p>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>so in theory this could operate on vector registers, though I donʼt know yet whether that would lead to any speedups!<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>I didnʼt bother to measure its performance exactly, since it was buried in JavaScript test helpers that surely dominated the evaluation time by doing their own string parsing.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>I ran into strange bugs without <code>-Wl,--export-all</code>, so I guess you kind of have to use that. It looked like the optimizer was assuming that the global arrays were zeroed out.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Ojo: a Bitflipped Jot, and a Real Flop</title>
<pubDate>Sat, 10 May 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/quapteryx2.html</guid>
<description><![CDATA[<div class="centered">
<p><em>See <a href="https://blog.veritates.love/quapteryx1.html">Quapteryx Part I: On the SKI Combinator Calculus</a> for an introduction.</em></p>
</div>
<h2 id="iota-jot-unlambda">Iota, Jot, Unlambda</h2>
<p>We ended with the iota combinator last time. The language Iota is just the language of the iota combinator and function application, expressed in a prefix manner:</p>
<pre class="bat"><code>iota ::= "1" | "0" iota iota</code></pre>
<pre class="haskell"><code>data Iota = Iota | App Iota Iota

iota2SKI :: Iota -&gt; SKI
iota2SKI (App f x) = f :@ x
iota2SKI Iota = ((S:@((S:@((S:@K):@K)):@(K:@S))):@(K:@K))</code></pre>
<p>Itʼs, uh, <em>very</em> difficult to implement an evaluator for Iota directly, much better to just translate it to SK calculus and evaluate it there. More on that later!</p>
<h3 id="prefix-parens">Prefix Parens</h3>
<p>So Iota gets cute with using <code class="st">1</code> and <code class="st">0</code>, but we should understand <code class="st">0</code> as a prefix application marker.</p>
<p><a href="https://en.wikipedia.org/wiki/Unlambda">Unlambda</a> uses the backtick operator <code class="op">`</code> for this purpose. It will be useful sometimes to use this for clarity. (Ironic, talking about clarity with Unlambda.)</p>
<p>Here is another way to think of it: <code class="st">0</code> or <code class="op">`</code> are <em>left</em> parentheses, <strong>if</strong> you print every reasonable parenthesis and not just the ones required for disambiguation.</p>
<p>That is, if you have a minimal printer (not a pretty printer) like this:</p>
<pre class="haskell"><code>print :: Iota -&gt; Text
print Iota = "ι"
print (App f x) = "(" &lt;&gt; print f &lt;&gt; print x &lt;&gt; ")"</code></pre>
<p>Then you get to Iota notation by replacing every <code>(</code> with <code class="st">0</code>, every <code>ι</code> with <code class="st">1</code>, and deleting every <code>)</code>.</p>
<p>Trailing parentheses are redundant in this notation, because each open parenthesis is followed by exactly two operands, and the leaves are single characters.</p>
<h3 id="jot">Jot</h3>
<p>Although Iota gets cute with using <code class="st">1</code> and <code class="st">0</code>, not every bitstring is a valid Iota program: only well-formed bitstrings are (<span data-t="" data-widget="">i.e.</span>, where every <code class="st">0</code> is followed by two operands).</p>
<p>Jot is a language where <em>every</em> bitstring is a valid program.</p>
<p>However, I wonʼt show you Jot! Everything feels backwards about Jot. Instead weʼll talk about Ojo.</p>
<h3 id="ojo">Ojo</h3>
<p>Ojo is bitflipped Jot. I named it that partly because it <em>looks</em> like a bitflipped Jot: the vertical letters are replaced with oʼs, and the o is replaced with a vertical letter. Also because iota “ι” is the equivalent of the letter “i”, which sounds like “eye” in English, which means “ojo” in Spanish… too cute to resist.</p>
<p>Anyways, Ojo is defined on <em>all</em> bitstrings, and is translated to the SK calculus via a function that we write as brackets (… itʼs a mathematician/logician thing, it means “semantic translation of the thing inside”).</p>
<pre class="bat"><code>ojo ::= "" | ojo "0" | ojo "1"</code></pre>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mo>≈</mo><mi>η</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>I</mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mi>S</mi><mo stretchy="false">)</mo><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">≜</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">[</mo><mi>w</mi><mn>0</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>≜</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mo>=</mo><mi>β</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>B</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{llll}
[]   &amp;\triangleq (SK)K     &amp;\approx_\eta &amp; I \\
[w1] &amp;\triangleq (([w])S)K &amp;\triangleq   &amp; \iota([w]) \\
[w0] &amp;\triangleq S(K([w])) &amp;=_\beta      &amp; B([w]) \\
\end{array}
</annotation></semantics></math></span></p>
<p>Here, the right column is the semantic idea of each thing. Itʼs pretty funny because each bit we take off of the <em>right</em> can be thought of as a <em>prefix</em> function, applied to the rest of the translation.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>In Haskell,</p>
<pre class="haskell"><code>data Ojo = Blank | And0 Ojo | And1 Ojo

ojo2SKI :: Ojo -&gt; SKI
ojo2SKI Blank = I
ojo2SKI (And0 w) = ((ojo2SKI w) :@ S) :@ K
ojo2SKI (And1 w) = S :@ (K :@ (ojo2SKI w))

data Bit = Bit0 | Bit1

prefixFunction :: Bit -&gt; SKI
prefixFunction Bit0 = iota2SKI Iota
prefixFunction Bit1 = (S:@(K:@S)):@K -- B = S(KS)K</code></pre>
<p>Anyways, I really think this is the way that Ojo should be encoded.</p>
<p>My syntactic arguments for this choice are:</p>
<ul>
<li><code class="st">1</code> represents iota nicely!</li>
<li>and <code class="st">0</code> resembles the composition operator <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∘</mo></mrow><annotation encoding="application/x-tex">\circ</annotation></semantics></math></span>, which fits because thatʼs what <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span> is, after all. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo stretchy="false">(</mo><mi>f</mi><mo>∘</mo><mi>g</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">≜</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>B</mi><mi>f</mi><mi>g</mi><mi>x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mo>=</mo><mi>β</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
  \begin{array}{llll}
  (f \circ g)(x) &amp;\triangleq&amp; f(g(x)),\\
  Bfgx &amp;=_\beta&amp; f(g(x)).
  \end{array}
</annotation></semantics></math></span></li>
</ul>
<p>And my semantic points are:</p>
<ul>
<li>Extra zeros on the front are eta-irrelevant, so it gets us closer to our goal of every natural number being a program,</li>
<li>and <code class="st">0</code> in Ojo now corresponds to <code class="st">0</code> in Iota,</li>
</ul>
<p>But youʼll have to read the next section to see the justifications for these!</p>
<h2 id="mechanics-of-ojo">Mechanics of Ojo</h2>
<h3 id="leading-zeros">Leading zeros</h3>
<p>It turns out that leading zeros in Ojo are basically irrelvant.</p>
<p>If you reduce strictly according to the SKI beta reduction rules, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>I</mi><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">BI =_\beta S(K(I))</annotation></semantics></math></span> does not reduce any further, and you need to get as far as two extra arguments before it reduces to parity with <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>I</mi><mi>x</mi><mi>y</mi><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">(</mo><mi>K</mi><mi>I</mi><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>x</mi><mi>y</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>I</mi><mi>x</mi><mi>y</mi><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">BIxy =_\beta (KIy)(xy) =_\beta Ixy =_\beta xy</annotation></semantics></math></span>.</p>
<p>(This is what eta-equivalence means, btw: two expressions <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span> are eta-equivalent (<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><msub><mo>≈</mo><mi>η</mi></msub><mi>g</mi></mrow><annotation encoding="application/x-tex">f \approx_\eta g</annotation></semantics></math></span>) if they “behave the same”: there is some number of arguments <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>, such that <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><msub><mi>a</mi><mn>1</mn></msub><msub><mi>a</mi><mn>2</mn></msub><mo>…</mo><msub><mi>a</mi><mi>n</mi></msub><msub><mo>=</mo><mi>β</mi></msub><mi>g</mi><msub><mi>a</mi><mn>1</mn></msub><msub><mi>a</mi><mn>2</mn></msub><mo>…</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">f a_1 a_2 \dots a_n =_\beta g a_1 a_2 \dots a_n</annotation></semantics></math></span> reduce the same no matter what <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>a</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">a_1, a_2, \dots, a_n</annotation></semantics></math></span> are.)</p>
<p>To be sure, it is a bit questionable to rely on eta-equivalence here. We arenʼt going to make a system that fully respects eta-equivalence, itʼs mostly about beta reductions.</p>
<p>But itʼs true <em>in theory</em>, and thatʼs important at least sometimes!</p>
<h3 id="the-stack">The “Stack”</h3>
<p>I claimed that <code class="st">0</code> acts in Ojo like it does in Iota, but this is surprising: <code class="st">0</code> is translated from the end in Ojo and maybe be followed by anything, whereas in Iota it is a prefix that enforces a well-formed parse structure.</p>
<p>Explaining this is a little harder, because it is actually muddled by Ojo/Jot. But here is an attempt:</p>
<p>I claim that there is a bitstring <code>&lt;ι&gt;</code> such that if you take a valid Iota string and replace every <code class="st">1</code> with <code>&lt;ι&gt;</code> (and keep all the <code class="st">0</code>s the same!), then it is a Iota string that is beta–eta equivalent to the original.</p>
<p>Unfortunately, the first annoyance of Ojo is that, even though iota is fundamental to its construction, itʼs hard to <em>get</em> iota on this metaphorical stack: the encoding of <code>&lt;ι&gt;</code> is very complicated.</p>
<p>One such encoding is <code class="st">00000001110000000111001010000110000011100001100011</code>. Augh! Itʼs 50 bits! (… this might even be minimal, Iʼm not quite sure.)</p>
<p>We can annotate what is going on here, using the Unlambda backtick for clarity:</p>
<pre><code>ι = S(SI(KS))(KK)
00000001110000000111001010000110000011100001100011
``S-------``S-------I----`K----S-------`K----K----
((S       ((S       I)   (K    S)))    (K    K))</code></pre>
<p>As you can see, the encoding of each <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> on the stack is 8 bits, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> is 5 bits: it is incredibly inefficient. These are related to the iterated iota we talked about already, and you could continue it for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> to get an encoding with 14 bits, but it is much more efficient to just do <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo>=</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I = (SK)(SK)</annotation></semantics></math></span> in 5 bits (which behaves the same as <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>K</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">SKK</annotation></semantics></math></span>).</p>
<p>Hereʼs a Haskell program, although it is a little weird:</p>
<pre class="haskell"><code>iota2ojo :: Iota -&gt; Ojo
iota2ojo root = go root Blank
  where
    go :: Iota -&gt; (Ojo -&gt; Ojo)
    go (App x y) = And0 &gt;&gt;&gt; iota2ojo x &gt;&gt;&gt; iota2ojo y
    go Iota =
      -- 00000001110000000111001010000110000011100001100011
      And0 &gt;&gt;&gt; And0 &gt;&gt;&gt; ... &gt;&gt;&gt; And0 &gt;&gt;&gt; And1 &gt;&gt;&gt; And1</code></pre>
<p>Anyways, you might be starting to see the pattern here: <code class="st">1</code> pushes two items onto the metaphorical argument stack, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>, and <code class="st">0</code> is responsible for popping two items off of the stack, applying them together, and pushing that back onto the stack. <code class="st">1</code> is net 2 items, and <code class="st">0</code> is net −1 items.</p>
<p>The annoyance that <code class="st">1</code> pushes <em>two</em> items on the stack is honestly a dealbreaker for anything involving Ojo. Everything is much simpler to explain in Quapteryx, where each nonzero quaternary digit pushes exactly one of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>, or <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> onto the stack, and the zero digit behaves the same as Ojo.</p>
<h3 id="but-but-but">But but but …</h3>
<p>So this is weird because on the one hand, zeros donʼt matter, and on the other hand, they are the glue holding everything together.</p>
<div class="Key_Idea">
<p>There is a way to normalize any Ojo number/bitstring into an “operand” which behaves as one item on the metaphorical stack.</p>
</div>
<p>Relatedly, we want to demonstrate that it really is a combinatory calculus: we should be able to define function application!</p>
<div class="Key_Idea">
<p>If both <code class="st">X</code> and <code class="st">Y</code> are already well-formed operands, then <code class="st">0XY</code> is too, and represents their application.</p>
<p>But in general, the leading zeros of <code class="st">X</code> and <code class="st">Y</code> can be ignored, and then there is a precise amount of zeros to place between the two bitstrings to get it to work, based on the bits of <code class="st">Y</code>: <code>(2 * Y.#1s - Y.#0s) - 1</code>.</p>
<div class="Details" data-box-name="Annoying Details">
<p>The complicated bit is if there are two many zeros towards the end of the bitstring <code class="st">X</code> (a stack underflow, essentially). I wonʼt cover it exhaustively here, but basically you have to reify the <code class="st">0</code>s as <code class="st">B</code>s on the stack. Then the above works out.</p>
</div>
</div>
<h2 id="evaluation">Evaluation</h2>
<div class="Warning">
<p>These evaluation rules are a little bit fudged: they are up to beta–eta equivalence, but not in any consistent manner, just whatever happened to be convenient.</p>
</div>
<p>There are some bitstrings involving the identity combinator that we can just delete entirely, wherever we see it in the bitstring.</p>
<pre><code>[w000101] = [w]
[w000100011] = [w]
[w000000000011111] = [w]
[w000000001110001100011] = [w]</code></pre>
<p>To do more, we need to figure out how terms are encoded on the stack: a grammar of operands.</p>
<p>Since <code class="st">1</code> pushes two terms and <code class="st">0</code> decreases stack size by 1, then <code>&lt;P(n)&gt;</code> must satisfy the equation <code>n = 2 * #1s - #0s</code>, and furthermore the stack must not drop to zero (e.g.&nbsp;<code class="st">001</code> cannot be a trailing string).</p>
<pre><code>-- Push 1 onto the stack
-- `^0(1|00(?1)(?1)|0(?1)0(?1))$`
&lt;P1&gt; = '0' &lt;P2&gt;
-- Push 2 onto the stack (ambiguous grammar...?)
-- `^(1|00(?1)(?1)|0(?1)0(?1))$`
&lt;P2&gt; = '1' | '0' '0' &lt;P2&gt; &lt;P2&gt; | '0' &lt;P2&gt; '0' &lt;P2&gt;</code></pre>
<p>Next we need two helpers for splitting apart composite terms (an annoyance unique to Ojo/Jot):</p>
<pre><code>fst :: &lt;P2&gt; -&gt; &lt;P1&gt;
fst '1' = '00000111' -- S
fst ('0' &lt;fa:P2&gt; '0' &lt;gb:P2&gt;) = '0' &lt;fa:P2&gt;
fst ('0' '0' &lt;fa:P2&gt; &lt;bz:P2&gt;) = '0' '0' &lt;fa:P2&gt; (fst &lt;bz:P2&gt;)

snd :: &lt;P2&gt; -&gt; &lt;P1&gt;
snd '1' = '00011' -- K
snd ('0' &lt;fa:P2&gt; '0' &lt;gb:P2&gt;) = '0' &lt;gb:P2&gt;
snd ('0' '0' &lt;fa:P2&gt; &lt;bz:P2&gt;) = snd &lt;bz:P2&gt;</code></pre>
<p>So now we can finally tackle the classic beta reductions of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>. These are just sketch notes I took, nothing too formal.</p>
<pre><code>-- So now we can reduce `K` = fst
[w0000011] = \mn. [w](Kmn) = \mn. [w]m
[w0000011&lt;m:P1&gt;&lt;n:P1&gt;] = [w&lt;m:P1&gt;]
-- Split iota into `S K` and drop the `K`
-- [w00000111] = [w](KSK) = [w]S = [w00000111] -- oh.
-- Split iota into `S K` after `&lt;m:P1&gt;` and drop the `S`
[w0000011&lt;m:P1&gt;1] = [w&lt;m:P1&gt;]K = [w&lt;m:P1&gt;00011]
-- Split the annoying &lt;P2&gt; = 00&lt;P2&gt;&lt;P2&gt; case
[w000001100&lt;fa:P2&gt;&lt;bz:P2&gt;] = [w00&lt;fa:P2&gt;0000011&lt;bz:P2&gt;]

-- And we can reduce `KI` = `SK` = snd, which drops one from the stack
[w00001100101] = [w](KI) = [w0]KI = [w](SK) = [w01]
[w001&lt;m:P1&gt;] = [w]I = [w00101] -- not necessarily a reduction
[w0001&lt;mn:P2&gt;] = [w]n = [w&lt;snd mn:P1&gt;] -- not necessarily a reduction
-- Split iota into `S K` and drop the `S`
-- [w00011] = [w](SKSK) = [w]K = [w00011] -- oh.
-- [w0011] = [w](SKS)K = [w]IK = [w0010100011] -- &lt;P2&gt; -&gt; &lt;P1&gt;&lt;P1&gt;
-- Split the annoying &lt;P2&gt; = 00&lt;P2&gt;&lt;P2&gt; case
[w00100&lt;fa:P2&gt;&lt;bz:P2&gt;] = [w001&lt;bz:P2&gt;]

-- And `S`, I guess
[w00000000011111] = [w](SSKSK) = [w](SKS) = [w]I = [w00101]
[w000000000011111] = [w]
[w00000000111&lt;mn:P2&gt;&lt;o:P1&gt;]
  = [w](Smno) = [w]((mo)(no))
  = [w00&lt;fst mn:P1&gt;&lt;o:P1&gt;0&lt;snd mn:P1&gt;&lt;o:P1&gt;]
[w00000000111&lt;m:P1&gt;&lt;no:P2&gt;]
  = [w00&lt;m:P1&gt;&lt;snd no:P1&gt;0&lt;no:P2&gt;]
[w00000000111&lt;mn:P2&gt;&lt;op:P2&gt;]
  = [w](Smno)p = [w]((mo)(no))p
  = [w00&lt;fst mn:P1&gt;&lt;fst op:P1&gt;0&lt;snd mn:P1&gt;&lt;op:P2&gt;]</code></pre>
<h2 id="deficiencies">Deficiencies</h2>
<p>Anyways, uhh, by now you can see why Ojo/Jot arenʼt really worth being implemented.</p>
<p>The “reduction rules” are absolutely absurd and thereʼs no way to implement them performantly, they offer absolutely no insight.</p>
<p>The fact that <code class="st">1</code> pushes two things onto the stack complicates the grammar incredibly.</p>
<p>The fact that the iota is so hard to reproduce on the stack is also annoying.</p>
<p><em><span data-t="" data-widget="">&amp;c.</span> <span data-t="" data-widget="">&amp;c.</span></em></p>
<p><em>However</em>, the core ideas are sound – even attractive: every natural number is a program, use <code class="st">0</code> as prefix application, and reductions are possible by searching through the string with a grammar.</p>
<p>Quapteryx builds on these ideas for a really efficient implementation, hopefully.</p>
<div class="centered">
<p><em>Read on at <a href="https://blog.veritates.love/quapteryx2.html">Quapteryx Part III: Quaternary Combinators</a>.</em></p>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This is not exactly true, because it takes additional beta reductions to get from <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B([w])</annotation></semantics></math></span> to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mo stretchy="false">[</mo><mi>w</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(K([w]))</annotation></semantics></math></span>, but this is pretty irrelevant tbh, at the level of granularity we will be considering.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>On the SKI Combinator Calculus</title>
<pubDate>Sat, 10 May 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/quapteryx1.html</guid>
<description><![CDATA[<p>For a long time Iʼve been fascinated by the idea that every number could be a program, every file could be executable. There would be no decoding errors, no bad bits or bytes, it would just interpret everything equally – regardless of whether you intended it or not, really.</p>
<p>Sure thereʼs Gödel numberings of various systems, but they are pretty artificial, and they are usually not surjective: some numbers just arenʼt programs! Sorry computer.</p>
<div class="centered">
<p><em>Gödel numbering: an encoding only a mathematician could love.</em></p>
</div>
<p>Where Gödel numberings are ugly, the corresponding deal for finite set theory is elegant: I already made <a href="https://blog.veritates.love/hatstack.html">HatStack</a>, a stack-based language for hereditarily finite set theory, where every piece of data is just a natural number and these natural numbers <em>are</em> sets, bitwise.</p>
<p>It uses the <a href="https://en.wikipedia.org/wiki/Hereditarily_finite_set#Ackermann_coding">Ackermann coding</a>, whose premise is really simple: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \in y</annotation></semantics></math></span> just means that the bit numbered <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span> is set in the number <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msup><mn>2</mn><mi>x</mi></msup><mo><mi mathvariant="normal">&amp;</mi></mo><mi>y</mi><mo stretchy="false">)</mo><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">(2^x \band y) \ne 0</annotation></semantics></math></span>. Every set is just the bitfield of its children, who (as numbers) are just the bitfield of <em>their</em> children – hence, <em>hereditarily</em> finite:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><munder><mo>⋃</mo><mrow><mi>x</mi><mo>∈</mo><mi>y</mi></mrow></munder><mo stretchy="false">{</mo><mi>x</mi><mo stretchy="false">}</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>y</mi></mrow></munder><msup><mn>2</mn><mi>x</mi></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">y = \bigcup\limits_{x \in y} \{ x \} = \sum_{x \in y} 2^x.</annotation></semantics></math></span></p>
<p>But whatʼs the answer for programs? Say, for a nice lambda calculus? Is there a similar encoding that is surjective and has nice properties?</p>
<p>Well, Iʼve known for a long while that there was one proposed answer: Jot, and its parent language Iota.</p>
<p>Every few months I would open the wiki page on <a href="https://en.wikipedia.org/wiki/Iota_and_Jot#Jot">Jot</a>, reference it in some conversation of nerdery. A kind of restless fascination lingered in the background… But I never seriously engaged with it, until I nerdsniped myself one day.</p>
<p>I did a deep dive into Jot for several months, figuring out exactly what made it tick, before determining that it was way too unwieldy for my purposes.</p>
<p>Instead, I realized that I could make a really efficient evaluator using SKI calculus a little more directly, using a <em>qauternary</em> encoding (base 4) and calling in Quapteryx. I wanted to target WASM for several reasons, and I tried hand writing WASM (well, the textual format WAT), before deciding that that, too, was too unwieldy. So I translated my WASM to C by hand, fixed a few bugs and actually got it working, and then I scrapped it for an actually efficient evaluator.</p>
<p><a href="https://blog.veritates.love/quapteryx2.html">My journey into Jot</a> is the subject of the next chapter, and <a href="https://blog.veritates.love/quatperyx3.html">Quapteryx</a> is documented in the other chapters.</p>
<p>However, most readers will probably benefit from the background that occupies the rest of this chapter.</p>
<h2 id="ski-combinators">SKI Combinators</h2>
<p>SKI combinators are a distillation of the essence of untyped lambda calculus.</p>
<p>These are pure combinators: this means that they take a fixed number of arguments and return them applied to each other. Of these, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> is the identity combinator, the identity function we all know and love; <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> is the constant combinator that evaluates to its first argument; and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> is a little strange, but it is “lifted function application”, related to the <code class="haskell">&lt;*&gt;</code> operator of the <code class="haskell">Applicative (-&gt;)</code> instance in Haskell/PureScript: it shares an argument <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span> between its first two arguments <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span>, before applying their results together.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>I</mi><mi>x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mi>x</mi><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mi>x</mi><mi>y</mi><mi>z</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>y</mi><mi>z</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{ll}
Ix   &amp;=_\beta x \\
Kxy  &amp;=_\beta x \\
Sxyz &amp;=_\beta (xz)(yz) \\
\end{array}
</annotation></semantics></math></span></p>
<div class="Note">
<p>The identity combinator <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> is actually redundant here, since <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>K</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">SKy</annotation></semantics></math></span> has the exact same behavior: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>K</mi><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi></mrow><annotation encoding="application/x-tex">SK \approx_\eta I</annotation></semantics></math></span> because <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>K</mi><mi>y</mi><mi>z</mi><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">(</mo><mi>K</mi><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>y</mi><mi>z</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>K</mi><mi>z</mi><mo stretchy="false">(</mo><mi>y</mi><mi>z</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>z</mi><msub><mo>=</mo><mi>β</mi></msub><mi>I</mi><mi>z</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">SKyz =_\beta (Kz)(yz) =_\beta Kz(yz) =_\beta z =_\beta Iz.</annotation></semantics></math></span></p>
<p>We could omit the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> combinator, but it is useful for optimizations, keeps things tidy, and having the three combinators together makes things work out nicely in WASM/C, as you will see later.</p>
</div>
<div class="Warning">
<p>Donʼt take my comparison to <code class="haskell">&lt;*&gt;</code> too literally. The <code class="haskell">Applicative</code> instance for functions is very particular, it is <strong>typed</strong>, where the combinator calculus is very much <strong>untyped</strong>.</p>
<p>The type of <code>&lt;*&gt;</code> is <code class="haskell">(&lt;*&gt;) :: f (x -&gt; y) -&gt; f x -&gt; f y</code>, and specialized to functions, <code class="haskell">(i -&gt; x -&gt; y) -&gt; (i -&gt; x) -&gt; (i -&gt; y)</code>.</p>
<p>One way of explaining both <code class="haskell">&lt;*&gt;</code> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> is that they are “lifted” function application: in this case, lifted over functions itself.</p>
</div>
<details>
<summary>
Details on beta and eta equivalence
</summary>
<p>Note that the SK reduction rules are sufficient to have a Turing-complete combinator calculus, but they need to be expanded with some pretty weird rules to fully match the behavior of the lambda calculus.</p>
<p>From the Computer Science StackExchange, <a href="https://cs.stackexchange.com/questions/57361/combinator-equivalent-to-eta-conversion#57371">“Combinator equivalent to eta conversion”</a>, out of <em>The Lambda Calculus: Its Syntax and Semantics</em> by Henk Barendregt:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>4</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mspace width="2em"></mspace><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>5</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mspace width="2em"></mspace><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>6</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>K</mi><mi>K</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{ll}
A.1 &amp; K = S(S(KS)(S(KK)K))(K(SKK)) \\
A.2 &amp; S = S(S(KS)(S(K(S(KS)))(S(K(S(KK)))S)))(K(K(SKK))) \\
A.3 &amp; S(S(KS)(S(KK)(S(KS)K)))(KK)=S(KK) \\
A.4 &amp; S(KS)(S(KK)) = \\
    &amp; \qquad S(KK)(S(S(KS)(S(KK)(SKK)))(K(SKK))) \\
A.5 &amp; S(K(S(KS)))(S(KS)(S(KS))) = \\
    &amp; \qquad S(S(KS)(S(KK)(S(KS)(S(K(S(KS)))S))))(KS) \\
A.6 &amp; S(S(KS)K)(K(SKK)) = SKK
\end{array}
</annotation></semantics></math></span></p>
Where <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>1</mn><mtext>–</mtext><mi>A</mi><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">A.1\text{--}A.5</annotation></semantics></math></span> give a theory of beta equivalence isomorphic to lambda calculus, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mn>3</mn><mtext>–</mtext><mi>A</mi><mi mathvariant="normal">.</mi><mn>6</mn></mrow><annotation encoding="application/x-tex">A.3\text{--}A.6</annotation></semantics></math></span> give a theory of beta–eta equivalence isomorphic to lambda calculus with eta.
</details>
<p>As a Haskell data type,</p>
<pre class="haskell"><code>data SKI = S | K | I | SKI :@ SKI

-- Identity combinator
reduce (I :@ x) = x
-- Konstant combinator
reduce ((K :@ x) :@ y) = x
-- &lt;*&gt;-like combinator
reduce (((S :@ x) :@ y) :@ z) = (x :@ z) :@ (y :@ z)
-- Any other sequence does not reduce at the top
-- level, though it may reduce further down
reduce x = x</code></pre>
<p>There are <a href="https://www.angelfire.com/tx4/cus/combinator/birds.html">many other combinators</a>, a lot of which Raymond Smullyan gave colorful (bird!) names to in <em>To Mock a Mockingbird</em>.</p>
<div class="Note">
<p>“(Beta) reduction rules” are called that because they describe how one combinator “reduces” when applied to its arguments.</p>
<p>However this “reduction” is not always a reduction in size, and SKI combinators are Turing complete: some expressions do not reduce to a normal form, and may even grow infinitely large! [And it is <a href="https://en.wikipedia.org/wiki/Halting_problem">undecidable</a> which ones do reach a normal form.]</p>
</div>
<h2 id="basis-sets-for-combinator-calculus">Basis sets for combinator calculus</h2>
<div class="Bonus">
<p>To read more about the topic of this section, see the question <a href="https://cs.stackexchange.com/questions/57507/basis-sets-for-combinator-calculus">“Basis sets for combinator calculus”</a> on the Computer Science StackExchange.</p>
</div>
<p>The SK combinators form a minimal basis set: the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> combinator drops its second argument, and the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> combinator performs a couple functions including duplicating arguments (since <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span> appears twice) and changing their order (since <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span> occurs before <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span> once) and chaining functions, and these are enough to emulate any lambda calculus function.</p>
<p>Other combinators can also form minimal sets: the BCKW combinators isolate their functions more readily.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>B</mi><mi>x</mi><mi>y</mi><mi>z</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi><mo stretchy="false">(</mo><mi>y</mi><mi>z</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>C</mi><mi>x</mi><mi>y</mi><mi>z</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi><mi>z</mi><mi>y</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>K</mi><mi>x</mi><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>W</mi><mi>x</mi><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>x</mi><mi>y</mi><mi>y</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{ll}
Bxyz &amp;=_\beta x(yz) \\
Cxyz &amp;=_\beta xzy \\
Kxy  &amp;=_\beta x \\
Wxy  &amp;=_\beta xyy \\
\end{array}
</annotation></semantics></math></span></p>
<p>Here, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> is familiar, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span> performs the function of duplicating an argument and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span> swaps two arguments, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span> forms the function of chaining functions (composition): <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>x</mi><mi>y</mi><mo>=</mo><mi>x</mi><mo>∘</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">Bxy = x \circ y</annotation></semantics></math></span>.</p>
<p>Think about it like Boolean logic: you can take a set of a couple Boolean operators and recover every Boolean function.</p>
<p>But the big difference is that Boolean logic has one-point minimal sets: the “universal gates” NAND and NOR. Combinator calculus does not have this: apparently at least two “things” are necessary to get all the behavior we need.</p>
<h2 id="iota">Iota</h2>
<p>Enter the iota combinator <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi></mrow><annotation encoding="application/x-tex">\iota</annotation></semantics></math></span>. It is an <strong>improper</strong> combinator: it has a reduction rule but its reduction returns <em>other</em> combinators (not just its arguments).</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>ι</mi><mi>f</mi><msub><mo>=</mo><mi>β</mi></msub><mi>f</mi><mi>S</mi><mi>K</mi><mo>=</mo><mo stretchy="false">(</mo><mi>f</mi><mi>S</mi><mo stretchy="false">)</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">
\iota f =_\beta fSK = (fS)K
</annotation></semantics></math></span></p>
<p>In particular, it makes the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> combinators available to its “callback” <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span> (its lone argument).</p>
<div class="Details">
<p>This can, of course, be encoded in SK combinators. The idea of applying a callback with two arguments is captured by the <a href="https://en.wikipedia.org/wiki/Vireo">“Vireo”</a> combinator, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>x</mi><mi>y</mi><mi>z</mi><msub><mo>=</mo><mi>β</mi></msub><mi>z</mi><mi>x</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">Vxyz =_\beta zxy</annotation></semantics></math></span>, whose encoding is this monstrosity: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">((S(K((S((S(K((S(KS))K)))S))(KK))))((S(K(S((SK)K))))K)).</annotation></semantics></math></span> So <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi><mo>=</mo><mi>V</mi><mi>S</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">\iota = VSK</annotation></semantics></math></span>. But this reduces to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(S(SKK)(KS))(KK)</annotation></semantics></math></span>, so thatʼs a little better at least. And <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>K</mi><mi>K</mi><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi></mrow><annotation encoding="application/x-tex">SKK \approx_\eta I</annotation></semantics></math></span>, so <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi><mo>=</mo><mi>S</mi><mo stretchy="false">(</mo><mi>S</mi><mi>I</mi><mo stretchy="false">(</mo><mi>K</mi><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\iota = S(SI(KS))(KK)</annotation></semantics></math></span> if we let ourselves use that combinator.</p>
</div>
<p>There are other one-point bases, probably infinitely many, but this one is nice and small enough, and it is familiar since it relates to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>.</p>
<p>The iota combinator has nice properties: you recover <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span> easily as <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>S</mi><mi>K</mi><mi>K</mi><msub><mo>=</mo><mi>β</mi></msub><mo stretchy="false">(</mo><mi>S</mi><mi>K</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi></mrow><annotation encoding="application/x-tex">(\iota \iota) =_\beta SSKK =_\beta (SK)(KK) \approx_\eta I</annotation></semantics></math></span>. From there it forms a nice 5-cycle by iterating <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>ι</mi><mi mathvariant="normal">_</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\iota \_)</annotation></semantics></math></span>:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>K</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>K</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>≈</mo><mi>η</mi></msub><mi>I</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi><mi>S</mi><mi>K</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>K</mi><mi>S</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{lll}
\iota (\iota \iota) &amp;\approx_\eta ISK &amp;=_\beta SK \\
\iota (\iota (\iota \iota)) &amp;\approx_\eta ISKSK &amp;=_\beta K \\
\iota (\iota (\iota (\iota \iota))) &amp;\approx_\eta ISKSKSK &amp;=_\beta S \\
\iota (\iota (\iota (\iota (\iota \iota)))) &amp;\approx_\eta ISKSKSKSK &amp;=_\beta SSK \\
\iota (\iota (\iota (\iota (\iota (\iota \iota))))) &amp;\approx_\eta ISKSKSKSKSK &amp;=_\beta SKS \\
\end{array}
</annotation></semantics></math></span></p>
<div class="Note">
<p>Okay, technically <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>K</mi><mo stretchy="false">(</mo><mi>K</mi><mi>K</mi><mo stretchy="false">)</mo><mo mathvariant="normal">≠</mo><mi>S</mi><mi>K</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">SK(KK) \ne SKS</annotation></semantics></math></span>, but they behave the same for all inputs: they are eta-equivalent! (This is part of why eta-equivalence is nice.)</p>
<p>So technically it does not form a 5-cycle until you start from <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">\iota (\iota \iota) =_\beta SK</annotation></semantics></math></span>, which after five iterations of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>ι</mi><mi mathvariant="normal">_</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\iota \_)</annotation></semantics></math></span> gets back to <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mo stretchy="false">(</mo><mi>ι</mi><mi>ι</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msub><mo>=</mo><mi>β</mi></msub><mi>S</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">\iota (\iota (\iota (\iota (\iota (\iota (\iota \iota)))))) =_\beta SK</annotation></semantics></math></span>.</p>
</div>
<p>Being an improper combinator is kind of a dealbreaker: you canʼt compute reductions of a language with just <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ι</mi></mrow><annotation encoding="application/x-tex">\iota</annotation></semantics></math></span>. You have to resort to inserting <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span> and evaluating with those.</p>
<p>… Or can you?</p>
<div class="centered">
<p><em>Read on at <a href="https://blog.veritates.love/quapteryx2.html">Quapteryx Part II: Ojo: a Bitflipped Jot, and a Real Flop</a> or jump to the good stuff at <a href="https://blog.veritates.love/quapteryx3.html">Quapteryx Part III: Quaternary Combinators</a> and beyond.</em></p>
</div>]]></description>
</item>
<item>
<title>Implementing FRP and Why</title>
<pubDate>Sat, 22 Feb 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/riverdragon_implementation.html</guid>
<description><![CDATA[<p><span style="display: block;text-align: center;font-size:1.2em">🐲 <em>whatʼs upstream?</em> 🌊</span></p>
<p>To explain <em>why</em> I wrote Riverdragon, we need to need to talk about what makes “<span data-t="" data-widget="">FRP</span>” <em>Functional</em> Reactive Programming, and the challenges that being purely functional imposes.</p>
<p>Of course, it is not all challenges: the sequencing of effects is a boon for maintainable code, it just means that you have to be more careful and deliberate about it.</p>
<div class="Key_Idea" data-box-name="tl;dr">
<p>The punchline of this article is in <a href="#consequences-of-isflowing">Consequences of <code class="ps">IsFlowing</code></a>, which I will copy here:</p>
<div class="Key_Idea">
<p>Whatʼs special about <code class="ps">River</code>? Well, like a <code class="ps">Fiber</code> represents a running <code class="ps">Aff</code> computation, a <code class="ps">River</code> represents a flowing event stream: besides its burst behavior (which is completely separate and we will get to later), a <code class="ps">River</code> maintains a list of subscribers and <strong>broadcasts the same value to all active subscribers</strong>.</p>
<p>This is important for two main reasons: it ensures that multiple subscriptions to the same <code class="ps">River</code> are seeing the same events, which is critical for maintaining a coherent display of DOM.</p>
<p>And it allows memoizing various functions, especially <code class="ps">&lt;$&gt;</code> and <code class="ps">filterMap</code>, so that the work they do can be shared between multiple subscribers automatically.</p>
</div>
<div class="Key_Idea">
<p>On the other hand, <code class="ps">Lake</code> is a <strong>description of how to create an event stream</strong>, not a flowing event stream itself.</p>
<p>It can be instantiated on demand, and depending on when exactly that happens, you might get different event streams: either due to minor timing differences, or just due to fundamentally different circumstances.</p>
<p>For example, one <em>very</em> common aspect that makes a <code class="ps">Stream</code> a <code class="ps">Lake</code> is that it maintains internal state between callbacks: even something as simple as counting a stream with <code class="ps">counter :: forall flow a. Stream flow a -&gt; Lake (a /\ Int)</code> introduces internal state that depends on exactly <em>when</em> you started subscribing to upstream.</p>
</div>
</div>
<p>This article starts by discussing <code class="ps">Aff</code> (similar to <code class="hs">IO</code> in Haskell) as a familiar example of a functional asynchronous monad with a result type <code class="ps">Fiber</code>, and then talks about how the distinction between flowing and not flowing streams is solidified in the design of <code class="ps">Riverdragon.River</code> (my <span data-t="" data-widget="">FRP</span> event implementation) and even in <code class="ps">Riverdragon.Roar</code> (a <span data-t="" data-widget="">FRP</span> front-end for Web Audio).</p>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 33%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">System</th>
<th style="text-align: left;">Not flowing</th>
<th style="text-align: left;">Flowing</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">aff (asynchronous effects)</td>
<td style="text-align: left;"><code class="ps">Aff</code>, <code class="ps">ParAff</code></td>
<td style="text-align: left;"><code class="ps">Fiber</code>, of a running <code class="ps">Aff</code> action</td>
</tr>
<tr class="even">
<td style="text-align: left;">River (event stream)</td>
<td style="text-align: left;"><code class="ps">Lake = Stream NotFlowing</code></td>
<td style="text-align: left;"><code class="ps">River = Stream Flowing</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Roar (audio graphs)</td>
<td style="text-align: left;"><code class="ps">Knob</code> à la <code class="js">AudioParam</code></td>
<td style="text-align: left;"><code class="ps">Roar</code>, output from an <code class="js">AudioNode</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">GHC (Haskell runtime)</td>
<td style="text-align: left;"><code class="hs">IO</code></td>
<td style="text-align: left;"><code class="hs">Async</code>, of a running <code class="hs">IO</code> action</td>
</tr>
</tbody>
</table>
<p>I want others to understand it as deeply as I do 💜</p>
<h2 id="a-point-of-comparison-aff-vs-fiber">A point of comparison: <a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Aff"><code class="ps">Aff</code></a> vs <a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Fiber"><code class="ps">Fiber</code></a></h2>
<p>Letʼs start at a familiar point in PureScriptʼs design space: with the <a href="https://pursuit.purescript.org/packages/purescript-aff/"><code class="ps">Aff</code></a> library, and regarding the distinction between <a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Aff"><code class="ps">Aff</code></a> and <a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Fiber"><code class="ps">Fiber</code></a>.</p>
<p><a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Aff"><code class="ps">Aff</code></a> is very common in PureScript: it is the main way that we carry out asynchronous, effectful computations. Of course there is <a href="https://pursuit.purescript.org/packages/purescript-effect/4.0.0/docs/Effect#t:Effect"><code class="ps">Effect</code></a>, which represents synchronous, effectful computations, and in JavaScript this is a particularly rigid restriction: there is no way<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to convert an asynchronous computation to a synchronous one. And <code class="ps">Effect</code>s cannot be interrupted by JavaScript code, so they are much simpler to deal with. Computations running in <code class="ps">Aff</code> may be interleaved with other things, they may be canceled while they are running, and other complexities.</p>
<p>But throughout this all lies the part that makes functional programming pure: <code class="ps">Effect</code> and <code class="ps">Aff</code> themselves are <em>not</em> running computations: instead, you should think of them as <em>descriptions</em> (from the programmer to the runtime) of <em>how to run</em> a particular computation.</p>
<p>Being values in a functional programming language, they may depend on values of variables in scope (since they are closures). And since they are effectful, their result may depend on other state: any and all state that JavaScript has access to. This includes local <code class="ps">Ref</code>s, <code class="js">localStorage</code>, other Web APIs like <code class="js">fetch()</code>, and so on.</p>
<div class="Bonus">
<p>You could make this a little more explicit by using a Free Monad over a base functor. The base functor describes all the actions you are allowed to take.</p>
<p>However, there are limitless actions you are allowed to take, and free monads are slow to interpreted. So <a href="https://pursuit.purescript.org/packages/purescript-effect/4.0.0/docs/Effect#t:Effect"><code class="ps">Effect</code></a> is represented as “any JavaScript function that accepts no arguments, and is allowed to have effects” (whereas functions <code class="ps">-&gt;</code> are any JavaScript function that accepts a single argument and is not allowed to have effects).</p>
<p><code class="ps">Aff</code> has its own representation in JavaScript (essentially an ADT), since it is actually managed by a <a href="https://github.com/purescript-contrib/purescript-aff/blob/main/src/Effect/Aff.js">lightweight runtime</a> that schedules the synchronous steps of the asynchronous computations to run interleaved and handles errors and such.</p>
</div>
<p>Of course, <code class="ps">Aff</code> is commonly used for representing async APIs in JavaScript, which mostly use <code class="js">Promise</code>s to represent their result. However, <code class="ps">Aff</code> is not analogous to <code class="js">Promise</code>! <code class="ps">Aff</code> is a <em>description</em> of a computation <em>to run</em>, <code class="js">Promise</code> is a way to await the result of an <em>already running</em><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> computation.</p>
<p>In fact, <a href="https://pursuit.purescript.org/packages/purescript-aff/8.0.0/docs/Effect.Aff#t:Fiber"><code class="ps">Fiber</code></a> in the <code>aff</code> library is the type most analogous to <code class="js">Promise</code>: it represents a way to await the result of an already running<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <code class="ps">Aff</code> computation.</p>
<p>Whereas <code class="js">Promise</code> is a bare bones API that barely scraped by the JavaScript standardization process, <code class="ps">Aff</code> is more fully featured, and <code class="ps">Fiber</code>s allow more control over the <code class="ps">Aff</code> they are spawned from:</p>
<ul>
<li><p>a <code class="ps">Fiber</code> can be started immediately, with <code class="ps">forkAff</code> or <code class="ps">launchAff</code> or <code class="ps">runAff</code> and so on</p></li>
<li><p>or a <code class="ps">Fiber</code> can be suspended until its result is demanded, with <code class="ps">suspendAff</code> or <code class="ps">launchSuspendedAff</code> or <code class="ps">runSuspendedAff</code></p></li>
<li><p>importantly, <code class="ps">Fiber</code> also allows <em>cancelling</em> the running computation with <code class="ps">killFiber</code> and waiting for the cancelation to complete</p>
<div class="Note">
<p>JS promises do not have any provisions for cancelling their computations, and thatʼs a major drawback of them in my opinion. Especially since it means that each individual API needs dedicated workarounds like <a href="https://developer.mozilla.org/en-US/docs/Web/API/AbortController/AbortController"><code class="js">AbortController</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal"><code class="js">AbortSignal</code></a> and ugh, why is it so overcomplicated.</p>
</div></li>
<li><p>finally, the aff API has a notion of supervising contexts</p></li>
</ul>
<p>However, besides these bonus details, <code class="ps">Aff</code> still runs on the callback model of JavaScript: just look at <code class="ps">makeAff</code> and <code class="ps">runAff</code>. (Even <code class="ps">Fiber</code> is <a href="https://github.com/purescript-contrib/purescript-aff/blob/v8.0.0/src/Effect/Aff.purs#L165-L173">a bunch of callbacks in a <code>newtype</code></a>.)</p>
<p>More-than-incidentally, <code class="ps">Aff</code> guarantees that its callback is only run once. This (and error handling) is the main difference between <code class="ps">Aff</code> and <code class="ps">Stream</code>s in <span data-t="" data-widget="">FRP</span>.</p>
<h2 id="in-riverdragon-frp-lake-versus-river-they-are-both-stream-_">In Riverdragon <span data-t="" data-widget="">FRP</span>: <code class="ps">Lake</code> versus <code class="ps">River</code> (they are both <code class="ps">Stream _</code>)</h2>
<div class="Note">
<p>This article assumes you are familiar with monads and applicatives and such.</p>
</div>
<p>The <a href="https://pursuit.purescript.org/packages/purescript-event/1.2.4/docs/FRP.Event">classic <span data-t="" data-widget="">FRP</span> library in PureScript</a> is a port of <a href="https://hackage.haskell.org/package/reactive-banana-1.3.2.0/docs/Reactive-Banana-Combinators.html">Haskellʼs reactive bananas</a>. <code class="ps">Event</code> vs <code class="ps">Behavior</code>, yeah. <code class="ps">Event</code> is a bad name, especially in JavaScript, because that already refers to a specific event that happened. I also donʼt like the idea that it is “just a list” (bleh). Itʼs clearly not! it is interactive and reactive and freshly evolving and yeah!</p>
<div class="Note">
<p>I do not have an analogue of <code class="ps">Behavior</code> yet. Maybe soon, but it is not so necessary. Mostly because <code class="ps">Stream</code>s (even <code class="ps">River</code>s!) are given full reign to push their current value to subscribers immediately.</p>
</div>
<p>Anyways, I wanted a different name, so I chose <code class="ps">Stream</code>. This is the river in Riverdragon (and the DOM is a dragon to deal with, rawr).</p>
<p><a href="https://github.com/paf31/purescript-event/blob/v1.2.4/src/FRP/Event.purs#L39-L39">The simplest encoding of an event stream</a> is the way it has always been done in PureScript:</p>
<pre class="purescript"><code>newtype Event a = Event
  ( (a -&gt; Effect Unit) -&gt;
    Effect (Effect Unit)
  )</code></pre>
<ul>
<li>It takes a callback <code class="purescript">(a -&gt; Effect Unit)</code> to call for each value that occurs in the stream, as it occurs. (Note that these are typically synchronous callbacks. This is unlike <code class="js">Promise</code>, which queues callbacks as <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTML_DOM_API/Microtask_guide">microtasks</a>!)</li>
<li>It performs some <code class="purescript">Effect</code>s to set up (install event listeners, register timers, create mutation observers, start any other number of asynchronous computations)
<ul>
<li>It may also call the callback synchronously! Like <code>pure</code> does, for example.</li>
</ul></li>
<li>And it returns a latent <code class="purescript">Effect Unit</code>, which the caller can run later to cancel the subscription (remove event listeners, cancel timers, and so on)</li>
</ul>
<p>It is conceptually simple and remarkably effective.</p>
<p>But something that always bothered me was the two ways to create an event:</p>
<ul>
<li><code class="purescript">create :: forall a. Effect { event :: Event a, push :: a -&gt; Effect Unit }</code>, which is run from the outside, if you will: events are pushed in from the outside and forwarded to all current subscribers</li>
<li>and <code class="purescript">makeEvent :: forall a. ((a -&gt; Effect Unit) -&gt; Effect (Effect Unit)) -&gt; Event a</code>, which sets up things for each subscriber</li>
</ul>
<p>It turns out that weʼre working with a similar distinction: <code class="ps">makeEvent</code> is like <code class="ps">Aff</code> (a description of how to start an event stream) and <code class="ps">create</code> is more like <code class="ps">Fiber</code>.</p>
<p>So I decided to reify this distinction in the type system: in Riverdragon, <code class="purescript">Stream :: IsFlowing -&gt; Type -&gt; Type</code> takes a type parameter to distinguish flowing streams (<code class="ps">type River = Stream Flowing</code>, like <code class="ps">Fiber</code>) from latent streams (<code class="ps">type Lake = Stream NotFlowing</code>, like <code class="ps">Aff</code>).</p>
<div class="Note">
<p>You could make <code class="ps">create</code> for <code class="ps">Aff</code> too if you wanted. It would operate with the condition that only the first call of <code class="ps">push</code> would have any effect: later calls would be ignored. (And in fact, if the <code class="ps">Fiber</code> was canceled, even the first <code class="ps">push</code> would be ignored.)</p>
</div>
<p>It turns out that, just like Typed, Pure Functional Programming offers a lot of clarity over procedural/imperative programming, this style of Functional Reactive Programming offers a lot more clarity even over normal “<span data-t="" data-widget="">FRP</span>”!</p>
<p><em>However</em>, before we get into that: we need to talk about initial values in streams.</p>
<h3 id="bursts-streams-that-start-with-an-initial-value-sometimes-multiple-effectfully">Bursts: Streams that start with an initial value (sometimes) (multiple?) (effectfully!)</h3>
<p>One of the funny things about this tradition of <span data-t="" data-widget="">FRP</span> is that a big deal is made out of <code class="ps">Behavior</code> <em>always</em> having a value, like <code class="ps">Time -&gt; a</code> would have. But this simply isnʼt true in practice either: for example, a JavaScript <code class="ps">Behavior</code> for mouse position doesn’t actually know where the mouse cursor is when the page loads (and this is not unique to browsers or JavaScript: a lot of APIs for peripherals rely on events in OSes).</p>
<p>And conversely, it is often <em>very very</em> useful for events to start with a default value: if a subscriber joins late (say, because an event happens which means you need to rerender some stuff in the DOM, and that stuff is itself dynamic), it is incredibly convenient if not outright necessary sometimes for that subscriber to be immediately notified of a “current” or “default” value of the event it is subscribing to, so it never runs dry and isnʼt left dangling while waiting for the next event.</p>
<p>Like, this was the whole promise of <span data-t="" data-widget="">FRP</span>: your values should be encapsulated in one place, and anything that depends on it should be able to rely on its value and be able to update in reaction to those events! If you need to plumb along default and current values outside of the <code class="ps">Stream</code>, youʼve lost the plot. It isnʼt about how well you can encode event callbacks, itʼs about the reactive values they represent.</p>
<p>So I allow an initial <em>burst</em> of events as a subscriber connects. And in fact I encode it explicitly in the model.</p>
<p>(There are even a bunch of combinators for controlling the behavior of bursts.)</p>
<h4 id="justifying-bursts-in-streams">Justifying bursts in streams</h4>
<p>How do I justify this special exception for initial “burst” events?</p>
<p>Well, itʼs not too difficult.</p>
<p>Our normal stream interface<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> would have the familiar methods: <code class="ps">Functor.&lt;$&gt;</code> for sure, <code class="ps">Apply.&lt;*&gt;</code> to join latest values from two events, and <code class="ps">Alt.&lt;|&gt;</code> to take events from whenever either of two streams fire. It just wouldnʼt have <code class="ps">Applicative.pure</code> to start with an initial value.</p>
<p>However, it is perfectly fine and cromulent to take the <code class="ps">Product</code> of two functors: this preserves <code class="ps">Functor</code>, <code class="ps">Apply</code>, and <code class="ps">Alt</code>. However it also gives us <code class="ps">Applicative.pure</code> now too.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>The specific other functor we are taking the product with is going to be a “burst” functor, like</p>
<pre class="purescript"><code>-- | Not allowed to call its callback immediately!
type BareStream = ...

-- | A burst effect that returns some values
type Burst a = Effect (Array a)
type Burst = Compose Effect Array

-- | Now we can combine them
type Stream = Product Burst BareStream</code></pre>
<p>And <code class="ps">Array</code> already has well-defined <code class="ps">Apply.&lt;*&gt;</code> behavior (take the Cartesian product of entries!), and it gives us <code class="ps">Applicative.pure = singleton</code>. And these both lift fine through <code class="ps">Compose Effect</code>, since <code>Effect</code> also has <code class="ps">Applicative</code> and this <code class="ps">Applicative</code> can be used to lift <code class="ps">Alt Array</code> through.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>So yeah, we should be justified in having all of the nice interfaces we want on our actual <code>Stream</code> type, accounting for burst.</p>
<h3 id="consequences-of-isflowing">Consequences of <code class="ps">IsFlowing</code></h3>
<p>Okay, now we can get back to the distinction between <code class="ps">River</code> and <code class="ps">Lake</code> and why it is so important!</p>
<p>As a refresher, <code class="ps">FRP.Event</code> had two ways to create events, <code class="ps">create</code> and <code class="ps">makeEvent</code>. Do you remember which was which?&nbsp;… yeaahh, thought so.</p>
<p>In Riverdragon now, we have two similar methods which are clearer about their roles:</p>
<ul>
<li><code class="purescript">createRiver :: forall a. Effect { destroy :: Effect Unit, send :: a -&gt; Effect Unit, stream :: River a }</code> which is just like <code class="ps">FRP.Event.create</code> but with the addition of a <code class="ps">destroy</code> method which informs subscribers that no more values will be sent (End of Stream, or EOS).
<ul>
<li><code class="ps">createRiverStore</code> adds a <code class="ps">Maybe a</code> parameter (used to configure an initial value, optional) and creates a river that stores its last value: when a new subscriber joins, it receives this most recent value immediately. There are other behaviors you can envision (<span data-t="" data-widget="">e.g.</span> you could track the whole history and replay it), but this is by far the most common.</li>
</ul></li>
<li>and <code class="purescript">makeLake :: forall a. ((a -&gt; Effect Unit) -&gt; Effect (Effect Unit)) -&gt; Lake a</code>, which is exactly like <code class="ps">FRP.Event.makeEvent</code>.
<ul>
<li>following the tradition of using primes to denote altered versions of functions (usually just a little more or less complex), <code class="ps">makeLake'</code> also allows gives a callback to indicate EOS (End of Stream)</li>
</ul></li>
</ul>
<p>These form the prototypical <code class="ps">River</code> and <code class="ps">Lake</code>.</p>
<div class="Key_Idea">
<p>Whatʼs special about <code class="ps">River</code>? Well, like a <code class="ps">Fiber</code> represents a running <code class="ps">Aff</code> computation, a <code class="ps">River</code> represents a flowing event stream: besides its burst behavior (which is completely separate and we will get to later), a <code class="ps">River</code> maintains a list of subscribers and <strong>broadcasts the same value to all active subscribers</strong>.</p>
<p>This is important for two main reasons: it ensures that multiple subscriptions to the same <code class="ps">River</code> are seeing the same events, which is critical for maintaining a coherent display of DOM.</p>
<p>And it allows memoizing various functions, especially <code class="ps">&lt;$&gt;</code> and <code class="ps">filterMap</code>, so that the work they do can be shared between multiple subscribers automatically.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
</div>
<div class="Key_Idea">
<p>On the other hand, <code class="ps">Lake</code> is a <strong>description of how to create an event stream</strong>, not a flowing event stream itself.</p>
<p>It can be instantiated on demand, and depending on when exactly that happens, you might get different event streams: either due to minor timing differences, or just due to fundamentally different circumstances.</p>
<p>For example, one <em>very</em> common aspect that makes a <code class="ps">Stream</code> a <code class="ps">Lake</code> is that it maintains internal state between callbacks: even something as simple as counting a stream with <code class="ps">counter :: forall flow a. Stream flow a -&gt; Lake (a /\ Int)</code> introduces internal state that depends on exactly <em>when</em> you started subscribing to upstream.</p>
</div>
<h3 id="improved-representation">Improved Representation</h3>
<p>The internal representation got more complicated. The good news is that the surface API does not really need to reflect this complexity: it is more about internal bookkeeping and maintaining low friction inside the machinery, which can all be smoothed over at the interface to the outside world.</p>
<pre class="purescript"><code>data Stream (flow :: IsFlowing) a = Stream IsFlowing
  ( { receive :: a -!&gt; Unit, commit :: Id -!&gt; Unit, destroyed :: Allocar Unit } -&amp;&gt;
    { burst :: Array a, sources :: Array Id, unsubscribe :: Allocar Unit }
  )</code></pre>
<p>We track <code class="ps">IsFlowing</code> at the value level explicitly for two reasons: (1) it is good for keeping the types unconstrained by typeclasses, and (2) it is sometimes convenient/necessary to lie about it.</p>
<p>As mentioned above, explicitly representing burst events is good. Particularly because it eliminates some nasty edge cases (“what if the subscriber unsubscribes during the burst?”). And yeah, if you use <code class="ps">makeLake</code> in a way that calls the callback during subscription, it gets collated into the burst of the <code class="ps">Stream</code>, and vice-versa, if you <code class="ps">subscribe</code>, you receive the burst events immediately.</p>
<p>And there is the <code class="ps">destroyed</code> callback for End of Stream.</p>
<p>The <code class="ps">commit</code> callback and <code class="ps">sources</code> return are the interesting part for <a href="#eliminating-events-resulting-from-transient-internal-states">the next section</a>! Again, they are not something that consumers care about, they are just internally tracked.</p>
<h3 id="eliminating-events-resulting-from-transient-internal-states">Eliminating events resulting from transient internal states</h3>
<div class="Example" data-box-name="Thought Experiment">
<p>Consider this: <code class="purescript">output = (+) &lt;$&gt; input &lt;*&gt; input</code>, where <code class="purescript">input :: River Int</code>.</p>
<p>First you push the value <code class="ps">1</code> through the <code class="ps">input</code> stream. Initially the applicative has no value for <code class="ps">input</code>, so when the left subscription is called it just stores the value <code class="ps">1</code>, and only when the right subscription is called is it able to output the value <code class="ps">1 + 1 = 2</code>.</p>
<p>So far so good.</p>
<p>What happens when <code class="ps">input</code> changes from <code class="ps">1</code> to <code class="ps">2</code>?</p>
<p>Well, in naïve implementations of <span data-t="" data-widget="">FRP</span>, you end up with a problem:</p>
<p>when the left subscription is called with <code class="ps">2</code> now, it already has a value for the right subscription: <code class="ps">1</code>! so it happily outputs <code class="ps">3</code>. whoa?!</p>
<p>but wait, we still have to call the right subscription: okay now it sees <code class="ps">2</code>, and the stored value on the left is also <code class="ps">2</code>, so we output <code class="ps">4</code> finally.</p>
<p>Pushing the events <code class="ps">1</code> and <code class="ps">2</code> through the <code class="ps">input</code> event stream produced an event stream with events <code class="ps">2</code>, <code style="color: #ff004d">3</code>, and <code class="ps">4</code>.</p>
<p>So apparently <code class="ps">i + i</code> does not equal <code class="ps">(pure) 2 * i</code> in naïve <span data-t="" data-widget="">FRP</span> land!</p>
</div>
<p>This contrived example is the kernel of a lot of bugs that can manifest, especially in interactive UIs. Say you want to record changes to various parameters derived from user input: under this model, each user event may send multiple updates, it would be a mess!</p>
<p>You might argue: why not introduce a new operator that ignores events from the left and only takes events from the right? This is possible, and in fact a good idea: it exists as <code class="ps">(+) &lt;$&gt; input &lt;?*&gt; input</code> in <code class="ps">Riverdragon.River</code>.</p>
<p>But it doesnʼt actually solve the problem! In general, it is basically impossible for <span data-t="" data-widget="">FRP</span> programmers to track exactly where values came from, and to partition out interactions of the upstreams that contributed to each event in order to do this kind of deduplication. And again, we came here based on the promise that we would be working with <em>reactive values</em>, not to deal with the mechanics of event subscriptions.</p>
<h4 id="non-solutions">Non-solutions</h4>
<p>A very simple approach would be to delay events, by say a frame, and only take the latest value of events. This is probably okay for some solutions, maybe even desirable, but it is far from a systematic solution.</p>
<p>Max/MSP has a convention that events always move <a href="https://docs.cycling74.com/legacy/max8/tutorials/basicchapter05">right to left</a>, and it is the leftmost inlet that triggers an output event in most cases. Again, this is a workable solution, but a non-starter for us.</p>
<p>However, I knew it was possible to <em>just do it</em> because I had <strong>done</strong> it before:</p>
<pre class="purescript"><code>-- | Filter out events from one source from a larger event. That is, given
-- | events `e1` and `e2`, the following equation ought to hold:
-- |
-- | ```purescript
-- | notFrom e1 (e1 &lt;|&gt; e2) = e2 = notFrom e1 (e2 &lt;|&gt; e1)
-- | ```
-- |
-- | This relies on the events being well-behaved, mostly that they broadcast
-- | the same event to all of their subscribers in order of subscription.
notFrom :: forall a. Eq a =&gt; Event a -&gt; Event a -&gt; Event a
notFrom suspect downstream =
  -- Subscribe to `downstream` first, so events coming from `suspect` will
  -- come in later and take precedence on the left side of `sampleOn_`
  let instigator = Just &lt;$&gt; downstream &lt;|&gt; Nothing &lt;$ suspect
  -- Only respond to events from downstream, of course, but with the above
  -- filtering
  in filterMap identity (sampleOnRight_ instigator downstream)</code></pre>
<p>It turns out that this comment, almost 3 years ago, contained the kernel of the idea of a <code class="ps">River</code>: “events [that] broadcast the same event to all of their subscribers (in order of subscription)”. It just took refining the idea and codifying it thoroughly into the <span data-t="" data-widget="">FRP</span> system.</p>
<p>Another suggestion that the idea should be possible: if you had a centralized view of the entire <span data-t="" data-widget="">FRP</span> graph (say, like a graphical editor, like Max/MSP), of what source events there are and how they are connected to other nodes, you could perform the deduplication in a very systematic way: either moving values through it as a wave front, or ensuring that events are pushed synchronously but only accounted for when their downstreams have caught up.</p>
<p>This is the idea we want to mimic, but in a decentralized way, where streams and their subscriptions are still just anarchic functions that are called whenever.</p>
<h4 id="solving-transient-events">Solving transient events</h4>
<p>So how do we pull it off in Riverdragon?</p>
<p>Well, you could read the source of <code class="ps">combineStreams</code> (the helper that is used for all of <code class="ps">&lt;*&gt;</code>, <code class="ps">&lt;*?&gt;</code>, and friends).</p>
<details class="Details">
<summary>
Source of <code class="ps">combineStreams</code>
</summary>
<pre class="purescript"><code>-- | Combine streams according to selection logic, where each side can reject
-- | having its update result in a downstream event (note that it still updates
-- | the latest value internally!).
combineStreams ::
  forall flow a b c.
  These (a -&gt; Boolean) (b -&gt; Boolean) -&gt;
  (a -&gt; b -&gt; c) -&gt;
  Stream flow a -&gt; Stream flow b -&gt; Stream flow c
combineStreams logic comb (Stream t1 e1) (Stream t2 e2) = Stream (t1 &lt;&gt; t2) \cbs -&gt; do
  -- only run the upstream destroyer once both have been destroyed
  destroyed &lt;- threshold 2 cbs.destroyed
  lastValues &lt;- prealloc2 Nothing Nothing
  needsPush &lt;- prealloc false
  sourcesR &lt;- prealloc Set.empty
  let
    cbL a = do
      lastValues.setL (Just a)
      needsPush.set true
      pure unit
    commitL id = do
      n &lt;- needsPush.get
      l &lt;- if n then fst &lt;$&gt; lastValues.get else pure Nothing
      Tuple shouldCommit shouldPush &lt;- case logic of
        -- It is always our responsibility to commit
        This p -&gt; pure $ Tuple true $ map p l == Just true
        -- Never commit
        That _ -&gt; pure $ Tuple false false
        -- Only commit if this source is unique to us
        Both p _ -&gt; do
          shouldCommit &lt;- not Set.member id &lt;$&gt; sourcesR.get
          pure $ Tuple shouldCommit $ map p l == Just true
      when shouldCommit do
        commit id shouldPush
    cbR b = do
      lastValues.setR (Just b)
      needsPush.set true
      pure unit
    commitR id = do
      n &lt;- needsPush.get
      r &lt;- if n then snd &lt;$&gt; lastValues.get else pure Nothing
      Tuple shouldCommit shouldPush &lt;- case logic of
        -- Never commit
        This _ -&gt; pure $ Tuple false false
        -- Always commit
        That p -&gt; pure $ Tuple true $ map p r == Just true
        Both _ p -&gt; pure $ Tuple true $ map p r == Just true
      when shouldCommit do
        commit id shouldPush

    commit id shouldPush = do
      when shouldPush do
        Tuple a b &lt;- lastValues.get
        case lift2 comb a b of
          Just c -&gt; cbs.receive c
          -- Have not received a value on both sides
          _ -&gt; pure unit
      cbs.commit id
  -- and only count each destructor once (just in case)
  cbs1 &lt;- cbs { receive = cbL, commit = commitL, destroyed = _ } &lt;$&gt; cleanup destroyed
  cbs2 &lt;- cbs { receive = cbR, commit = commitR, destroyed = _ } &lt;$&gt; cleanup destroyed
  -- subscribe to upstream
  r1 &lt;- e1 cbs1
  r2 &lt;- e2 cbs2
  sourcesR.set (Set.fromFoldable r2.sources)
  -- initialize from the burst
  lastValues.setL (Array.last r1.burst)
  lastValues.setR (Array.last r2.burst)
  pure
    -- TODO: burst logic?
    { burst: lift2 comb r1.burst r2.burst
    , sources: bifoldMap (const r1.sources) (const r2.sources) logic
    , unsubscribe: r1.unsubscribe &lt;&gt; r2.unsubscribe
    }</code></pre>
</details>
<p>But donʼt read that. The implementation got much much longer than I wanted&nbsp;…</p>
<p>Anyways, the main idea is that each event declares a list of “source IDs” that it will emit events from. Each event is sent first via <code class="purescript">receive :: a -!&gt; Unit</code> then via <code class="purescript">commit :: Id -!&gt; Unit</code>.</p>
<p>Importantly, the upstream gets to call them immediately, in order: <code class="purescript">cbs.receive a &lt;* cbs.commit id</code>. Because all of the callbacks happen synchronously, between <code class="purescript">cbs.receive a</code> and <code class="purescript">cbs.commit id</code>, all of the subscribers have been called and notified: thus we already know the right time to push the <em>real</em> events through the <span data-t="" data-widget="">FRP</span> graph, with <code class="purescript">cbs.commit id</code>.</p>
<p>Then the job of <code class="ps">combineStreams</code>/<code class="ps">&lt;*&gt;</code> is to maintain the most recent values and listen for the correct <code>commit</code> event to send its own updated value out (a <code class="ps">receive</code> call), and then pass on the <code>commit</code> event too. (Technically <code class="ps">&lt;*&gt;</code> just needs to listen to <code>commit</code> on one or the other side, for IDs that are shared, but <code class="ps">combineStreams</code> needs more logic due to how generic it is.)</p>
<p>The mechanism reveals the invariant: a source ID denotes an event stream that may push its own events into the <span data-t="" data-widget="">FRP</span> graph, synchronously. So if you have one stream that delays events from another stream, it needs its own source ID for those delayed events, even though they have the same values as events from an existing source ID.</p>
<p>It is also very important that streams that may filter out events still must pass their commit events through, since they still count as sources. This includes <code class="ps">&lt;*&gt;</code>, since it is not guaranteed to have an initial value from either side! These are equivalent streams: <code class="ps">empty &lt;*&gt; upstream</code> and <code class="ps">filter (const false) upstream</code> and they both push <code class="ps">commit</code> events through from <code class="ps">upstream</code>, but to outside observers, they act like <code class="ps">empty</code> since they never send a value.</p>
<p>Another important fussy little detail is that source IDs cannot be declared up-front, only after subscription. This is maybe the main divergence from the idealized “<span data-t="" data-widget="">FRP</span> graph is just a data structure” view, which would have static source IDs up front.</p>
<h4 id="case-studies">Case Studies</h4>
<h5 id="global-reactive-values-like-device-pixel-ratio">Global reactive values like device pixel ratio</h5>
<p>Alba pointed me to this recipe on MDN for <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio#monitoring_screen_resolution_or_zoom_level_changes">watching changes to <code class="js">devicePixelRatio</code></a>, so I quickly implemented it in <code class="ps">Riverdragon.River.Beyond</code>.</p>
<pre class="javascript"><code>export const _devicePixelRatio = {
  now: () =&gt; window.devicePixelRatio,
  subscribe: cb =&gt; () =&gt; {
    let active = true;
    let rolling = () =&gt; {};
    const untilNext = cb =&gt; {
      const mediaQueried = window.matchMedia(`(resolution: ${window.devicePixelRatio}dppx)`);
      mediaQueried.addEventListener('change', cb);
      rolling = () =&gt; mediaQueried.removeEventListener('change', cb);
    };
    const onChange = () =&gt; {
      rolling();
      if (!active) return;
      cb(window.devicePixelRatio)();
      untilNext(onChange);
    }
    untilNext(onChange);
    return () =&gt; { active=false; rolling() };
  },
};</code></pre>
<pre class="purescript"><code>foreign import _devicePixelRatio ::
  { now :: Allocar Number
  , subscribe :: (Number -&gt; Allocar Unit) -&gt; Allocar (Allocar Unit)
  }

devicePixelRatio :: River Number
devicePixelRatio = River.mayMemoize $ River.unsafeRiver $ makeLake \cb -&gt; do
  cb =&lt;&lt; _devicePixelRatio.now
  _devicePixelRatio.subscribe cb</code></pre>
<p>The reason it is a river is because it is a single global value that we are listening to: all subscribers see the same events. But the call to <code class="ps">River.mayMemoize</code> is the real magic there, it</p>
<ul>
<li>ensures that we only subscribe to one media query at a time<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>,</li>
<li>allowing the events to take place as a single source within&nbsp;the FRP graph, so we can remove the transient events</li>
</ul>
<p>Without <code class="ps">River.mayMemoize</code> there, this snippet would produce transient events showing nonsense like “1.5789473684210527 = 1.3333333333333333” (as the user zooms in from <code>1.33</code> to <code>1.57</code>):</p>
<pre class="purescript"><code>D.ol[] $ D.Appending $ dam ado
  l &lt;- devicePixelRatio
  r &lt;- devicePixelRatio
  in D.li[] $ D.show l &lt;&gt; D.text " = " &lt;&gt; D.show r</code></pre>
<p>You can paste that expression at <a href="https://blog.veritates.love/live_frp.html">Live FRP DOM Coding</a>.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<h3 id="benefits-of-isflowing">Benefits of <code class="ps">IsFlowing</code></h3>
<p>The main benefit of <code class="ps">IsFlowing</code> is that multiple subscribers know they are seeing the same values at, well, similar points in time (not exactly the same, but synchronously close together). (And again, the instantiation of a <code class="ps">Lake</code> to a <code class="ps">River</code> produces a burst which it is valuable to capture explicitly.)</p>
<p>One of the things that this elucidated for me was the signature of <code class="ps">fix</code>, which has always been mystifying.</p>
<pre class="purescript"><code>fix :: forall o i. (Event i -&gt; { input :: Event i, output :: Event o }) -&gt; Event o

fix :: forall o i. (River i -&gt; { loopback :: Stream _ i, output :: Stream _ o }) -&gt; Lake o</code></pre>
<p>Now the types almost tell the story: the output is a <code class="ps">Lake</code> since it is created on demand (and indeed, its state will depend on when you subscribe to it). You then receive a loopback stream which is already running: you get to mix in your own events that youʼre bringing it to produce the loopback stream you want to see and the stream of output events that downstream subscribers will see, and these two streams can be <code class="ps">Lake</code>s since they are only subscribed to once (and then forwarded to other subscribers).</p>
<p><code class="ps">fix</code> is actually a really important primitive and could be used to implement such staples as <code class="ps">foldStream</code> and <code class="ps">statefulStream</code>, though they are implemented on their own<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<p><code class="ps">singleShot</code> is a funny one: it is conceputally very simple as it is just a stream that destroys itself after a single event&nbsp;… but even it turns any stream into a <code class="ps">Lake</code>, for it matters when the observer starts watching for events.</p>
<p>Outside of the typeclass-provided combinators (<code class="ps">Applicative</code>, <code class="ps">Alt</code>, and <code class="ps">Filterable</code>), just about the only combinator that preserves <code class="ps">Flowing</code> streams is <code class="ps">delay</code>, and itʼs on thin ice. Notably, <code class="ps">delay</code> has a different weird aspect that it generates a new stream ID, because its events are not synchronous with upstream.</p>
<h3 id="benign-allocation-like-effects-allocar">Benign (allocation-like) effects <code class="ps">Allocar</code></h3>
<p><code class="ps">Allocar</code> really exists as a result of <code class="ps">instantiate</code>, a function which turns a <code class="ps">Lake</code> into a <code class="ps">River</code>, and its twin <code class="ps">withInstantiated</code>. In truth, it is executing effects: not only does it need to set up a new <code class="ps">River</code> to proxy events from upstream to all downstream subscribers, but it needs to subscribe to the upstream <code class="ps">Lake</code> which is technically effectful: it <em>shouldnʼt</em> do anything weird, but it technically could.</p>
<p>In fact, if you think about the analogy of a pure <span data-t="" data-widget="">FRP</span> graph: the graph can exist on its own as a pure data structure, like <code class="ps">Aff</code> is a pure description of how to theoretically run a computation. Itʼs only in the process of actually <em>subscribing</em> to nodes in the <span data-t="" data-widget="">FRP</span> graph that it becomes a monster capable of producing effects on the outside world. So in theory, all <code class="ps">instantiate</code> should be doing is allocating a reference to a new node in the graph and wiring it up. (In fact: consider how it works exactly this way for Web Audio Nodes! Nothing <em>really</em> happens until a node producing audio is connected to an <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioDestinationNode"><code class="js">AudioDestinationNode</code></a>: everything else would just be internal state ticking away.)</p>
<p><code class="ps">Allocar</code>, then, is for the “glue” effects that take place <em>inside</em> the <span data-t="" data-widget="">FRP</span> graph and donʼt affect the outside world themselves. Lightly scoped effects of allocations, bookkeeping, and other preparations.</p>
<p>This is important in transforming <code class="ps">instantiate</code> (the direct representation as an effect) to <code class="ps">withInstantiated</code>, which performs the effect as a <code class="ps">Lake</code>. Because a <code class="ps">Lake</code> is already allocating stuff for its subscriber, it makes sense that it should be able to easily allocate similar resources, and bring subscriptions to other streams along for the ride.</p>
<p>So how would I define <code class="ps">Allocar</code>?</p>
<p>The prototypical example of a benign effect would be <code class="ps">Ref.new</code>. It allocates a mutable cell (really just a JavaScript object) which is effectful only because it has a distinct referential identity, not because any other code in the world cares about this new <code class="ps">Ref</code>.</p>
<p>But even things like <code class="ps">addEventListener</code> are (for the most part<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>) benign: their effects are scoped to the caller and not visible to outside observers, inasmuch as the callback behaves that way.</p>
<p>If it was just about things like <code class="ps">Ref</code>s, in theory you could use <code class="ps">ST</code> to scope the effects in a safe way. But how would you scope <code class="ps">ST</code> to a region, when the region is&nbsp;… the entire <span data-t="" data-widget="">FRP</span> graph? (Technically you could, but it is very much not worth it.)</p>
<p>Even doing as much as making <code class="ps">Allocar</code> a newtype instead of a type synonym would cause so much friction to make it unbearable.</p>
<p>Note that in the first case, the <code class="ps">Ref</code> has no need for explicit resource management: being garbage collected by the JavaScript VM is enough. But <code class="ps">addEventListener</code> needs to be paired with<code class="ps">removeEventListener</code> explicitly. So the lite rule is that anything that runs in <code class="ps">Allocar</code> should be (able to be) paired with a destructor, but formalizing this in a proper monad (like <code class="ps">ScoreM</code>) is also an uphill battle with diminishing returns.</p>
<div class="Bonus">
<p>Why the name “allocar”?</p>
<p>Well I wanted something softer than “allocate”, and I could have gone with like an Italian “<span lang="it">allogare</span>” but then Iʼm not actually saving any characters, and it turns out that “<span lang="es">alocar</span>” does not exist in Spanish either? they seem to use “<span lang="es">asignar</span>”. so idk. Itʼs just a made up word!</p>
<p>Also I used the symbol <code class="ps">&amp;</code> for some of the operators as a nod to the address pointer symbol.</p>
</div>
<h4 id="oop-but-done-better"><span data-t="" data-widget="">OOP</span> but done better</h4>
<p><code class="ps">Riverdragon.River.Bed</code> is my attempt at creating a library to make working with <code class="ps">Allocar</code> (and <code class="ps">Effect</code>!) pretty pleasant. From the module header:</p>
<blockquote>
<p>This module is all about helpers for managing the lifecycles of variables with various semantics (replacement, accumulation, thresholds, and so on).</p>
<p>It is sort of “<span data-t="" data-widget="">OOP</span> but done better”: each allocation of a variable runs in <code class="ps">Allocar</code> and returns a bunch of instantiated methods encapsulated in a record. It offers great abstraction, no manual handling of refs and such.</p>
<p>It actually does a decent job of being inlined by the backend-optimizer, with some help from inlining directives. It does not quite <em>look</em> like something a dev would write (there are spurious constant declarations), but it should perform similarly or identically.</p>
<p>It is just really cute and nice and convenient!</p>
</blockquote>
<p>One of the main ideas is that I donʼt <em>want</em> to use mutable variables: you can do anything to mutable variables, who knows whatʼs happening! Instead I want to create self-contained APIs that capture total behaviors on their own.</p>
<p>(The worst part of it is just the naming. I was unhappy with the inconsistent naming of <code class="ps">STRef</code> vs <code class="ps">Ref</code> versus other things. But Iʼm not sure I did much of a better job of it myself, yet.)</p>
<p>Some highlights:</p>
<ul>
<li><code class="ps">accumulator</code> is a staple that just keeps accumulating values from a monoid with <code class="ps">.put</code>, until you call <code class="ps">.reset</code> to pop out what you have and start anew, or nondestructively <code class="ps">.get</code> what you have. So you get the nice guarantee that you are always mutating it by accumulation, you canʼt accidentally ignore the previous value of the variable. (Unless you purposefully ignore it with <code class="ps">.reset</code> and then <code class="ps">.put</code>.)</li>
<li><code class="ps">postHocDestructors</code> lets you <code class="ps">.track</code> destructors from other resources to call later, or, if it was already destroyed, call them immediately. This is important when allocating resources asynchronously, like <code class="js">AudioWorklet</code>s
<ul>
<li><code class="ps">cleanup</code> it its little sibling, who just makes sure that a destructor effect is only called once. Again, it is effectful to make the reference to the “new” destructor, but it is super benign (and in some cases, may act like <code class="ps">pure</code>!).
<ul>
<li><code class="ps">threshold</code> if you donʼt want it to happen the first time, but on the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>th time.</li>
</ul></li>
</ul></li>
<li><code class="ps">rolling</code> is the opposite idea: instead of gathering destructors, it rotates them, calling the last destructor when a new destructor arrives for next time. Again, just a little object that encapsulates the right behavior, instead of having a mutable variable floating around that can be set to whatever new thing without any protocol! (Unfortunately, you often want a sort of bracketing behavior, where you tear-down before creating the new thing.)</li>
<li><code class="ps">diffingArraySet</code> lets you <code class="ps">.swap</code> in a new array and returns what was <code class="ps">added</code>, <code class="ps">removed</code>, or <code class="ps">still</code> present from the previous state (and can also be <code>destroy</code>ed to refuse further updates). This is used to keep track of audio connections! So an audio node input can subscribe to <code class="ps">Lake (Array Roar)</code> (a changing stream of simultaneous audio signals).</li>
<li><code class="ps">subscriptions</code> is a heavy-hitter that handles keeping track of subscribers and sending events to the current list of them (rather, it lets you traverse them) in order.</li>
<li><code class="ps">eventListener</code> is one that interfaces with a web API, just registers an event listener and returns the unsubscribe function: again, I consider it an <code class="ps">Allocar</code>-style effect, not a full-fledged <code class="ps">Effect</code>, because it hardly ever has outside effects.</li>
<li><code class="ps">runningAff</code> is like <code class="ps">launchAff &gt;== joinFiber</code> but more lightweight (in particular, it tries to only keep the settled value around, not any closures).</li>
</ul>
<p>The ultimate goal might be to make a monad (transformer) that manages effects, particularly for users of the <span data-t="" data-widget="">FRP</span> libraries, more than for implementing the <span data-t="" data-widget="">FRP</span> itself. But for now it has been more convenient to manually track destructors, and just provide the most convenient way to make sure they are called during teardown. It would just be annoying to have both styles side-by-side… <code class="ps">ScoreM</code>, for building audio graphs, is a step in the right direction: it maintains <code class="ps">destroy :: Dual (Effect Unit)</code> for calling destructors in reverse order, and <code class="ps">ready :: ParAff Unit</code> for running effects when the rest of the audio graph is ready and waiting for everything to be up and running.</p>
<h2 id="web-audio-in-frp-roar-and-knob">Web Audio in <span data-t="" data-widget="">FRP</span>: <code class="ps">Roar</code> and <code class="ps">Knob</code></h2>
<p>So I started working on adding Web Audio support to Riverdragon, naming it <code class="ps">Riverdragon.Roar</code>, and I realized that this same distinction pops up!</p>
<p><code class="ps">Knob</code><a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> is a <em>slightly</em> nicer interface for <code class="ps">AudioParam</code>. Unfortunately, there is just no great interface for them (partly for understandable reasons, partly for <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1308431">really really unfortunate reasons</a>).</p>
<p>So the deal is that an <code class="ps">AudioParam</code> has two main things that can contribute to it: besides a default value, there are various audio parameter commands that create a timeline, and this is <em>summed</em> with contribution from connected audio nodes.</p>
<ul>
<li>Parameters of <code>defaultValue</code>, <code>minValue</code>, and <code>maxValue</code>, set by the parameter node.</li>
<li>Audio timeline, controlled by the various commands.
<ul>
<li>This is hidden state! You may command the timeline, but you canʼt directly access it. Grrr.</li>
<li>This means that you kind of have to wrap the API, track the commands, simulate them… it is just not worth it.</li>
</ul></li>
<li>Connected audio inputs.</li>
</ul>
<div class="Details" data-box-name="Side note">
<p>The A-Rate (Audio Rate?) versus K-Rate (Kontrol Rate?) is mostly irrelevant, except for performance and algorithmic limitations.</p>
</div>
<p>Connecting audio inputs to audio parameters is both very important, because it allows precise and arbitrary control of audio parameters at audio rate, and also very annoying: it means you cannot predict the value of an audio parameter at a point in time, in general, because that would require simulating audio arbitrarily far out into the future, and for stateful audio like reverb or even just lowpass filters, that would be a nightmare.</p>
<p>Anyways, this means that you can convert an audio signal into an audio parameter, using <code class="js">AudioNode.prototype.connect(audioParam, outputIndex)</code> (you canʼt use the three-argument method – ask me how I know!), and <code class="js">ConstantSourceNode</code> is the perfect tool for converting an audio parameter into an audio signal.</p>
<p>Hopefully you can see where this is going:</p>
<div class="Key_Idea">
<p>A <code class="ps">Knob</code> is a <em>description</em> of how to control an audio parameter or audio signal.</p>
<p>A <code class="ps">Roar</code> is an actual running audio signal, which is particularly important for being sample-accurate now.</p>
<p>And also because <code class="ps">Knob</code> can incorporate feedback&nbsp;… havenʼt quite figured out how that is supposed to work exactly. Partly because <code class="js">AudioParam</code> is just an unpleasant interface to work around. But the feedback isnʼt “real” until it is reified to a particular <code class="js">AudioParam</code> at a point in time.</p>
</div>
<p>TODO: bake the audio graph into the <span data-t="" data-widget="">FRP</span> graph? idk, maybe stuff to do around destroying streams and such.</p>
<h3 id="rant-on-the-deficiencies-of-audioparams">Rant on the deficiencies of <code class="js">AudioParam</code>s</h3>
<p>Really one of the biggest problems of AudioParam is that it is a “do anything” class with ~7 different ways to schedule values on the timeline – one of which is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1308431">not implemented in Firefox</a>! and it is not clear if the others are properly implemented, because there just isn’t a good spec for how these things should all cohere (they donʼt.)</p>
<p>And I guess that the <code class="js">.value</code> of an <code class="js">AudioParam</code> does not depend on the audio signals feeding into it? That seems wrong… but Iʼm not sure if either answer is <em>good</em>, per se.</p>
<p>The solution, as always, is to express coherent thoughts first, and then compose those atomic behaviors into a more nuanced picture.</p>
<p>For example, an ADSR is a coherent thought. Sure, there is still behavior and edge cases to specify. but it is driven by a series of rising and falling events, and it responds to those with preset attack, decay, sustain, and release curves. Or rather, not preset curves, but preset <em>behaviors</em> at those intervals (the exact curve may depend on the value at a point in time).</p>
<p>For example, if you wanted an ADSR in cents (hundreths of a semitone of pitch), you could later map it to frequency with an exponential function. (Fortunately the Web API doesn’t require this, and it allows you to specify cents beside frequency in the relevant places)</p>
<p>So the goal of the front-end of <code class="ps">Riverdragon.Roar.Knob</code> is to express these coherent behaviors in single functions, and then figure out how to implement them. (Right now it is limited to very simple behaviors like ADSR, linear interpolation, exponential decay&nbsp;… and they arenʼt even correct yet, there are glitches in the linear stuff.)</p>
<h2 id="differences">Differences</h2>
<p>First of all it is worth explaining why <code class="ps">Effect</code> does not fit into this flowing-and-not-flowing model.</p>
<p>At runtime, <code class="ps">Effect</code> is a synchronous (and effectful) JavaScript function. As such, control flow proceeds by calling it, and then it either exits with a return value, or throws an error (which may or may not be handled by a <code class="js">catch</code> in some caller). This means that it cannot be interrupted by means within JavaScript: the JavaScript execution context itself may pause and resume later, it may crash due to out of memory or other OS limits or signals, but there is no JavaScript API to interrupt it, no way for other code to interact with a pending result that is not already async (through web workers or worklets or so on). So that is why there is no <code class="ps">Fiber</code> equivalent for <code class="ps">Effect</code>.</p>
<p>Next, the main difference between <code class="ps">Aff</code>/<code class="ps">Fiber</code> and <code class="ps">Stream</code> (<code class="ps">River</code>/<code class="ps">Lake</code>) (both based on the callback model) is of course that <code class="ps">Stream</code> allows calling the callback multiple times and a <code class="ps">Fiber</code> only resolves one. <code class="ps">Aff</code> is also more tailored to <em>being a computation</em>, instead of representing interfaces between independent running things: it has supervision contexts and more detailed error handling (although no polymorphic errors yet, darn). <code class="ps">Stream</code> only has the concession that it allows an End of Stream notification: if you really wanted to represent an error you could use <code class="ps">Stream _ (Either Error yourData)</code> and send a <code class="ps">Left</code> error right before EOS.</p>
<p><code class="ps">Roar</code> and <code class="ps">Knob</code> are obviously distinct in representing audio data, which is far too much data to process in this model of JavaScript, which is particularly expensive to compute because of all of the callbacks and context switching (and general indirection of PureScript as compiled to JavaScript). So instead, it just represents audio nodes and high level commands, and delegates to Web Audio to handle the computation. Internally, the Web Audio framework uses an audio quantum of 128 samples (each sample is a 32-bit float) and passes those quanta around within the audio graph in an optimized and synchronized manner. Itʼs very cool actually, just a bit frustrating that the API isnʼt nicer to work with, and the necessity of using AudioWorklets.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>at least in the browser – technically in node.js there are ways<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>or completed<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>or completed, or suspended<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>You could call it <code>BareStream</code> I guess<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Okay, maybe this means that they are sort of twisted together? Or maybe it is more like <code>Coproduct Identity (Product _ BareStream)</code>. Idk, not actually important!<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Okay so for those keeping score at home: we are up to something like <code>Coproduct Identity (Product (Compose Effect ArrayButNotSingleton) BareStream)</code>, if we were to want to derive the construction through algebraic newtypes, essentially.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Of course this is a tradeoff, and for lots of simple functions there is more overhead to setting up a new <code class="ps">River</code> than for calculating it for multiple subscribers.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>possibly better for efficiency?<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Yeah, thatʼs all the code you need to try it out! it gets templated into a full module with a header, imports, declarations, and so on<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>for efficiency? idk<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>There are some weird exceptions where having particular event listeners on DOM elements makes them be clickable on iOS, or <code class="js">MessagePort</code>s are buffered until <code class="js">.onmessage</code> is set <em>or</em> <code class="js">.start()</code> is called<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>(Suggestions for cuter dragon names for <code class="ps">Knob</code>?)<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Perfect Vector Graphics for a QR code</title>
<pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/svgqr.html</guid>
<description><![CDATA[<p>You would think that SVG would be a perfect medium for rendering QR codes (or other 2D matrix codes): it is perfectly scalable so the renderer can decide how best to render it at each resolution, thereʼs no need to mess around with hints like <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/image-rendering"><code class="css">image-rendering: pixelated;</code></a>, and so there should be no compromises, right? Right??</p>
<p>Well the quality of SVG renderers really varies, and iOS was having trouble rendering the SVGs for the complex, large QR codes I was using (nearly max size). Specifically, it was failing to render adjacent black modules<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> of the QR code as contiguous blocks of rendered pixels: in fact, entire rows and columns “between” the modules were consistently white all the way across, but only a single screen pixel in width. (Some form of this problem appeared at every zoom level I tried.)</p>
<p>Presumably this is due to some rounding assumptions the renderer made when dealing with many objects that had fill but no stroke. After all, I had chosen the simplest method of <em>generating</em> the SVG: each module became a <code class="dimension">1x1</code> filled rectangle in the SVG, which was then sized to fit on the screen. Again, one would naïvely think that having it on integer coordinates in the SVG coordinate space may help a renderer realize they were adjacent, certainly there were no floating point problems before scaling, but for whatever reason, this did not in fact help.</p>
<p>So in the end, maybe it wasnʼt so surprising that we are obligated to help the renderer along.</p>
<p>How best to do this?</p>
<p>Well, the answer (and about the only thing we can try) is to teach the renderer that there are no gaps between adjacent modules. We need to render adjacent modules as a single SVG path, and modules adjacent to those, and so on: the <a href="https://en.wikipedia.org/wiki/Connected_component_(graph_theory)"><em>connected components</em></a> of the QR code.</p>
<p>So there are two core steps: finding the connected components of the matrix, and rendering each component into the SVG as a single path.</p>
<p>As one example, the recognition and locating features of the QR code are nested squares, so each inner square and each outer square will now be a single path each, forcing the renderer to render all of their modules contiguously, helping ensure there are no glitchy gaps. Other patterns are essentially random, and in fact are meant to be somewhat unpredictable<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div>
<noscript>
<img src="assets/images/qr_demo1.svg">
</noscript>
<div id="demo_qr" class="fit" data-qr="https://webrtc-over-qr.veritates.love">

</div>
<div class="scriptful">
<label class="input-wrapper" style="width: 100%"> <span>QR text</span> <input id="demo_input" class="code" style="width: 100%; box-sizing: border-box; text-overflow: ellipsis" value="https://webrtc-over-qr.veritates.love"> </label> <label class="input-wrapper"> <span>Margin</span> <input id="demo_margin" class="code" style="width: 50px" type="number" min="0" max="4" value="1"> </label> <label> <input id="demo_debug" type="checkbox" checked=""> <span>Debug</span> </label> <label> <input name="demo_ecc" type="radio" checked="" value="L"> <span>L</span> </label> <label> <input name="demo_ecc" type="radio" value="M"> <span>M</span> </label> <label> <input name="demo_ecc" type="radio" value="Q"> <span>Q</span> </label> <label> <input name="demo_ecc" type="radio" value="H"> <span>H</span> </label>
<div style="display: flex; justify-content: space-around; margin-top: 1em">
<div>
Components: <span data-output="components.length">57</span>
</div>
<div>
Version: <span data-output="version.versionNumber">3</span>
</div>
<div>
Codewords: <span data-output="version.totalCodewords">70</span>
</div>
<div>
Mask pattern: <span data-output="maskPattern">7</span>
</div>
<div>
[<a id="demo_download" download="QR.svg">Download</a>]
</div>
</div>
</div>
</div>
<script src="assets/js/zxing.min.js"></script>
<script src="assets/js/moreqr.js"></script>
<script>
  "use strict";
  window.addEventListener('DOMContentLoaded', function() {
    Ve.forQuery('[data-qr]', (e) => {
      MoreQR.debug = true;
      const matrix = ZXing.QRCodeEncoder.encode(e.dataset.qr, ZXing.QRCodeDecoderErrorCorrectionLevel.L).getMatrix();
      const components = MoreQR.matrix2components(matrix);
      const paths = components.map(MoreQR.component2path);
      const margin = 4;
      const viewBox = `${-margin} ${-margin} ${matrix.getWidth()+2*margin} ${matrix.getHeight()+2*margin}`;
      const svg = Ve.SVG.svg.qrcode(
        { attrs: { viewBox } },
        paths,
      );
      if (e.dataset.viewbox) svg.attrs.viewBox = e.dataset.viewbox;
      e.clearChildren(); // from verity.js <3
      e.appendChild(svg);
    });
    let debounce = 0, generation;
    function demo() {
      const now = Date.now();
      if (generation || now < debounce+200) {
        generation && clearTimeout(generation);
        generation = setTimeout(() => { generation = undefined; demo() }, 250);
        debounce = now;
        return;
      } else { debounce = now; generation = undefined; }
      const ecc = document.querySelector('[name=demo_ecc]:checked')?.value ?? 'L';
      MoreQR.debug = Ve.ById.demo_debug?.checked ?? true;
      const encoded = ZXing.QRCodeEncoder.encode(Ve.ById.demo_input.value, ZXing.QRCodeDecoderErrorCorrectionLevel[ecc]);
      const matrix = encoded.getMatrix();
      const components = MoreQR.matrix2components(matrix);
      const paths = components.map(MoreQR.component2path);
      console.log(Object.assign(encoded, { components }));
      const margin = Ve.ById.demo_margin?.value ?? 1;
      const viewBox = `${-margin} ${-margin} ${matrix.getWidth()+2*margin} ${matrix.getHeight()+2*margin}`;
      const svg = Ve.SVG.svg.qrcode(
        { attrs: { viewBox } },
        paths,
      );
      if (!MoreQR.debug) svg.style.background = 'white';
      Ve.ById.demo_qr.clearChildren();
      Ve.ById.demo_qr.appendChild(svg);
      // Download link
      const xml = new XMLSerializer().serializeToString(svg);
      const href = URL.createObjectURL(new Blob([xml], { type: 'image/svg+xml' }));
      Ve.ById.demo_download.href = href;
      // Outputs
      Ve.forQuery("[data-output]", e => {
        let data = encoded;
        for (const key of e.dataset.output.split(".")) data = data[key];
        e.textContent = String(data);
      });
    }
    Ve.ById.demo_input.oninput = demo;
    Ve.ById.demo_debug.oninput = demo;
    Ve.ById.demo_margin.oninput = demo;
    Ve.forQuery('[name=demo_ecc]', (e) => e.oninput = demo);
    demo();
  });
</script>
<style>
  div[data-qr] > svg {
    display: block;
    margin: auto;
    max-width: 100%;
    max-height: 100%;
  }
  div.fit > svg {
    max-width: min(100%, 100vw);
    max-height: min(100%, 100vh);
    max-width: min(100%, 100svw);
    max-height: min(100%, 100svh);
  }
  div.smol > svg {
    max-width: 100px;
    max-height: 100px;
  }
  div.medium > svg {
    max-width: 300px;
    max-height: 300px;
  }
  div[data-qr][data-viewbox] {
    margin: 20px;
  }
</style>
<noscript>
<style>.scriptful { display: none }</style>
</noscript>
<h2 id="calculate-connected-components">Calculate connected components</h2>
<p>Calculating the connected components is fairly straightforward, so I spent some time trying to optimize it.</p>
<p>Instead of operating cell-by-cell in the matrix, we process each row by detecting a run of black modules, which we will patch together to form the components. A component maps which row this takes place on with all of the runs in the component, and links back to the accumulated component.</p>
<p>To match up entries from each row, we scan across the previous row and look for columns that overlap with the current one: if <code class="js">[j_0, k_0]</code> is a run from the previous row, and <code class="js">[j_1, k_1]</code> is the run we are currently looking at, then they overlap when <code class="js">k_0 &gt; j_1 &amp;&amp; j_0 &lt; k_1</code>.</p>
<p>When we find an overlap, we add this new run into the connected component. However, it may also overlap with additional runs: if they do not already belong to the same connected component, we need to merge the connected components.</p>
<pre class="javascript"><code>MoreQR.matrix2components = function matrix2components(matrix) {
  const comps = []; // rows of horizontally connected components
  for (let i=0; i&lt;matrix.getWidth(); i++) {
    comps.push([]);
    let l = 0;
    for (let j=0, k; j&lt;matrix.getHeight(); j=k) {
      if (!matrix.get(i, j)) { k = j+1; continue }
      for (k=j; k&lt;matrix.getHeight() &amp;&amp; matrix.get(i, k); k++) {}
      const c = comps.at(-2); // previous row of horiz-connected components
      const len = c?.length;
      let f = {}; // found component, `f = { [i]: [[j,k,f], ...], ... }`
      // scan while the upper bound is less than the current lower bound
      while (l &lt; len &amp;&amp; c[l][1] &lt;= j) l++;
      if (l &lt; len &amp;&amp; c[l][0] &lt; k) {
        // grab the existing connected component
        f = c[l][2];
        // fuse it with other components that are also connected to `[j,k]`
        while (l+1 &lt; len &amp;&amp; c[l+1][0] &lt; k) {
          l++;
          const f2 = c[l][2];
          if (f2 === f) continue;
          // Copy everything over and update the references
          for (const row in f2) {
            (f[row] = f[row] || []).push(...f2[row]);
            for (const h of f2[row]) h[2] = f;
          }
        }
      }
      const t = [j, k, f]; // lower, upper (half-open), reference to its connected component
      (f[i] = f[i] || []).push(t); // add it to the connected component
      comps.at(-1).push(t);
    }
  }
  // Gather all the unique components!
  const components = [...new Set(comps.flatMap(row =&gt; row.map(t =&gt; t[2])))];
  return components;
}</code></pre>
<h2 id="draw-them">Draw them</h2>
<p>Once we have the modules of each component grouped together, we need to render it to an SVG element, using <code class="svg">&lt;path d="..."/&gt;</code> and four of the <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/d#path_commands">SVG path commands</a>:</p>
<ul>
<li><code>M</code> for move, to set the initial position</li>
<li><code>h</code> for relative horizontal movements</li>
<li><code>v</code> for relative vertical movements</li>
<li><code>Z</code> to close the path</li>
</ul>
<p>Like the naïve approach, we will use SVG elements with fill and no stroke, and very conveniently, SVG provides a way to cut out the interiors of connected components<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>: the default <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/fill-rule"><code class="svg">fill-rule="nonzero"</code></a> is sufficient to allow this cookie cutter approach.</p>
<p>For both horizontal and vertical movements, we <em>could</em> specify them as a bunch of single-module movements&nbsp;… but we might as well put in the effort to coalesce them, and this will generate a much smaller SVG source as well.</p>
<h3 id="outer-path">Outer Path</h3>
<p>The basic idea is that we will start at some point along the outside of the component, might as well be the leftmost module of the first row of the component. And then we will walk around the outside of the shape, tracing the outline and recording the steps to draw it along the way: the first step is horizontal to the right, then we will turn right so that we are moving down, and proceed apace.</p>
<p>You can think of it as operating like those cute little line-following robots, that zip around a path, making decisions based upon whether they bump into the left or right of a line. In this case, we want to be following a boundary between black and white modules, instead of a thin line.</p>
<p>A little bit of mathematical intuition (topology?) tells us that we will end up right back where we began, exactly when we finish the loop. That is, connected components have nice perimeters, and operating in discrete space makes it really easy for us.</p>
<p>So thereʼs a little bit of logic to implement it correctly, but the idea is very simple.</p>
<div class="Bonus">
<p>It turns out that the SVG representation of paths works very conveniently for this algorithm.</p>
<p>Sometimes there are weird edge cases and such when dealing with SVG paths. Like sometimes you just have odd code to handle the first or last item in the array. And <em>reversing</em> a path is a pain: you canʼt just reverse the commands, you have to know where they start and end to patch them (and deal with relative coordinates).</p>
<p>But here, since we are describing our algorithm as walking a path around the outside of the component, it corresponds quite nicely with the SVG draw commands which operate in that sense too.</p>
</div>
<h4 id="walking-variables">Walking variables</h4>
<p>These variables track where we are (and which direction we are facing) as we walk along the perimeter.</p>
<pre class="javascript"><code>// `i` for the first index: row (a.k.a. `y` in the SVG)
let i = +Object.keys(component)[0];
// `j` for the second index: column (a.k.a. `x` in the SVG)
let j = component[i][0][0];
// `d` for direction: what direction are we moving in (+i, -i, +j, -j)
let d = [0,1];</code></pre>
<p>Then for each step, we calculate some helper variables.</p>
<pre class="javascript"><code>// vertical or horizontal movement?
const v = +!!d[0];
// relative directions: `l` for left, `r` for right
const l = [-d[1],d[0]];
const r = [d[1],-d[0]];</code></pre>
<h4 id="center-vs-perimeter">Center vs perimeter</h4>
<p>The fussiest detail is that we consider modules as an integer grid based on their top left coordinate, but we want to trace around their perimeter. That is, the first module at <code>0,0</code> has a perimeter between <code>0,0</code> and <code>1,1</code>: as an SVG path, that is <code class="svg">&lt;path d="M0,0 h1 v1 h-1 Z"&gt;</code>. When we are tracing along the bottom, from <code>1,1</code> back to <code>0,1</code>, we want to make sure we are still inspecting the module at <code>0,0</code> in determining where to go next (in this case, move <code class="svg">h-1</code> and then turn the corner).</p>
<pre class="javascript"><code>// We want to inspect *this* point: because we are walking along the
// left edge of the outline, the center of the pixel we are
// inspecting is half a forward and half a right move away,
// and then we shift it by `-[0.5,0.5]` back to the integer grid
const c = [i+d[0]/2+r[0]/2-0.5, j+d[1]/2+r[1]/2-0.5];</code></pre>
<h4 id="movement-patterns">Movement patterns</h4>
<pre class="javascript"><code>// If the current cell is blank, we wrap around to the right to
// get back on track.
if (!grid[c]) {
  // Buffered line drawing
  if (i !== i0 || j !== j0) path += `hv`[v]+([j,i][v] - last);
  last = [i,j][v];
  // Turn to the right
  d = r;
// Otherwise we might want to swing out to the left, if there is a
// filled cell there.
} else if (grid[[c[0]+l[0], c[1]+l[1]]]) {
  // Buffered line drawing
  if (i !== i0 || j !== j0) path += `hv`[v]+([j,i][v] - last);
  last = [i,j][v];
  // Turn to the left
  d = l;
// Finally we proceed ahead. This is where we draw lines conceptually,
// although we buffer it so we are not stepping pixel by pixel.
} else {
  if (visited[[i,j,d]]) continue OUTER;
  visited[[i,j,d]] = true;
  const C = [i+d[0]/2+r[0]/2, j+d[1]/2+r[1]/2];
  i += d[0];
  j += d[1];
}</code></pre>
<div class="smol" data-qr="demo" data-viewbox="0 0 7 7">

</div>
<div class="smol" data-qr="https://webrtc-over-qr.veritates.love" data-viewbox="0 17 4 4">

</div>
<h3 id="inner-paths">Inner Paths</h3>
<p>This is where we get very lucky: we can reuse the same algorithm, and it even runs in the correct direction to make the default <code class="svg">fill-rule="nonzero"</code> work! (Otherwise we would have to use <code class="svg">fill-rule="evenodd"</code>, or reverse the algorithm for the inner paths.)</p>
<p>A sprinkle more of topological knowledge tells us that the connected component may have a series of holes punched out of it, but it is not infinitely nested: any further black modules inside will be considered a separate connected component.</p>
<p>So yeah, all that we really need to do is to find where holes start and trace around them like normal.</p>
<h4 id="detect-holes">Detect holes</h4>
<p>It is pretty simple to come up with spots that are missing from the interior of the connected component.</p>
<p>These arenʼt exactly the holes, though: several of them might belong to the same hole.</p>
<p>However!, since we are already walking the shape in order to turn it into a path, we just need to toss out duplicates: if we reach the same spot and direction along the way, weʼve already traced this hole and do not need to continue.</p>
<p>In the debug mode, we mark the candidate holes with circles. You can see that most holes end up along outside edges, and in this example, the three holes that are on the inside edge are redundant with each other.</p>
<div class="medium" data-qr="https://webrtc-over-qr.veritates.love" data-viewbox="19 11 10 18">

</div>
<pre class="javascript"><code>// We initialize the grid, indexed with `grid[[i,j]]`.
const grid = {};
// We also keep track of possible holes inside the connected component,
// which we need to punch out of the SVG path. This records places
// we should start looking for a hole, but these start points are
// likely to result in the same holes, or may even be on the exterior,
// where we were never going to draw anyways.
const holes = [];
// So to prune holes, we throw out a hole if we end up revisiting
// the same exact edge of the cell (i.e. same cell, same direction),
// since that is just retracing our steps at that point.
const visited = {};

// The connected component is of the form `{ [i]: [[j,k], ...], ... }`,
// where `i` is the row, `j` is the first column of a contiguous run,
// and `k` is past the last column of the run: that is, the cell of
// `grid[[i,j]]` is filled while `grid[[i,k]]` is blank.
//
// We also assume that its keys are sorted, since they are visited
// in order by the above algorithm at least.
const entries = Object.entries(component).map(([i,row]) =&gt; ([+i,row]));
for (const [i, row] of entries) {
  for (const run of row) {
    // Fill in the cells of the run, `run[0] &lt;= j &lt; run[1]`
    for (let j = run[0]; j &lt; run[1]; j++) {
      grid[[i,j]] = true;
    }
    // Look for potential holes: this is easy, because it just means
    // that we have more than one run in the row.
    if (run !== row.at(-1)) {
      // Trim off the first and last rows for efficiency, since we
      // know they are exposed to the air, so to speak.
      if (row !== entries.at(0)[1] &amp;&amp; row !== entries.at(-1)[1]) {
        // This is a location where the hole may start: ideally it is
        // the leftmost blank cell of the first row of the hole,
        // otherwise it will end up being a revisit of the same hole,
        // but we cannot really know that until we trace its contour.
        // And then `[1,0]` is the direction to move in.
        holes.push([i, run[1], [1,0]]);
      }
    }
  }
}
</code></pre>
<h4 id="draw-holes">Draw holes</h4>
<p>As mentioned, we can reuse the same drawing code for holes as for the outside contour. So the changes to support holes is mostly structural in the code: wrap it in another loop, abort the loop if we encounter a visited path, and collate all of the paths together.</p>
<pre class="javascript"><code>const paths = [];
OUTER: for (let startPoint of [[i,j,d], ...holes]) {
  [i,j,d] = startPoint;
  let path = `M`+[j,i];
  // walk along the contour until we are back at the start
  do {
    const v, l, r, c; // ... described previously
    if (!grid[c]) {
      if (i !== i0 || j !== j0) path += `hv`[v]+([j,i][v] - last);
      last = [i,j][v];
      d = r;
    } else if (grid[[c[0]+l[0], c[1]+l[1]]]) {
      if (i !== i0 || j !== j0) path += `hv`[v]+([j,i][v] - last);
      last = [i,j][v];
      d = l;
    } else {
      if (visited[[i,j,d]]) continue OUTER;
      visited[[i,j,d]] = true;
      i += d[0];
      j += d[1];
    }
  } while (i !== i0 || j !== j0);
  // If we did not revisit an edge and thus call `continue OUTER`,
  // then this path is valid and we will append it to the paths.
  paths.push(path+`Z`);
}
return Ve.SVG.path({ attrs: { d: paths.join('') }});</code></pre>
<h2 id="finishing-touches">Finishing touches</h2>
<p>To finish it out, we can compose it all together, using ZXing-JS to assemble the matrix that represents the QR code, turning it into a list of connected components, turning them into SVG paths, and plopping them in an SVG with a margin around it (“quiet zone”).</p>
<p>I additionally extract the XML, save it to a <code>blob:</code> URL, and render it as an <code class="html">&lt;img&gt;</code> tag. I think this makes it more efficient, but I donʼt really have any data to back that up, just a hope and a wish. But it keeps some data and nodes out of the DOM and hopefully allows the browser to render it more statically, not interactive at all.</p>
<pre class="javascript"><code>// Better SVG rendering! On some systems, especially iOS, the SVG rendering is
// not particularly great, and so the QR code can end up glitchy, with white
// pixels rendered in between contiguous modules. So we fix this by rendering
// an entire connected component as a single path, so that the rendering engine
// does not dare put white pixels in between them. Furthermore, we stuff it
// into an `&lt;img&gt;` tag instead of the `&lt;svg&gt;` to optimize the DOM, rendering?
function MoreQR(data, ...params) {
  // Generate the QR matrix as normal
  const matrix = ZXing.QRCodeEncoder.encode(data, ...params).getMatrix();

  // Get a list of the connected components in the QR code.
  const components = MoreQR.matrix2components(matrix);
  // Now we transform each connected component into an SVG path node
  const paths = components.map(MoreQR.component2path);

  // SVG parameters
  // Account for the margin (quiet zone)
  const margin = 4;
  const viewBox = `${-margin} ${-margin} ${matrix.getWidth()+2*margin} ${matrix.getHeight()+2*margin}`;

  // Stick it into an `&lt;svg&gt;` node
  const svg = Ve.SVG.svg.qrcode(
    { attrs: { viewBox } },
    paths,
  );
  // Render it to XML
  const xml = new XMLSerializer().serializeToString(svg);
  // Turn it into a `blob:` URL (to be nice to the DOM, hopefully)
  const src = URL.createObjectURL(new Blob([xml], { type: 'image/svg+xml' }));

  // And render it as an `&lt;img&gt;` tag!
  return Ve.HTML.img.qrcode({ src });
}</code></pre>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>A module is a pixel unit of the QR code, as opposed to the pixels used when rendering it to a screen.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>(look distinct from other features of the QR code)<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>so that we do not have to render white on top of the black modules to cancel them out – that just feels conceptually ugly<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>WebRTC over QR Connection Protocol</title>
<pubDate>Sun, 26 Jan 2025 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/webrtc_over_qr.html</guid>
<description><![CDATA[<p>Details on the connection protocol for <a href="https://webrtc-over-qr.veritates.love/">WebRTC over QR</a>. How is it even possible, and how could you use it too?</p>
<div class="Warning">
<p>See there for caveats and compatibility and so on.</p>
<p>Most notably: automatic connection only works on Chromium-based browsers and only for <span data-t="" data-widget="">LAN</span> connections.</p>
</div>
<h2 id="baseline-connection-initiation-happy-path">Baseline connection initiation (happy path ^^)</h2>
<p>This relies on a particular mechanic that only seems to be available in Chromium: the peer reflexive candidate<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> is available via <code class="js">RTCPeerConnection.prototype.getStats</code>, which exposes the <span data-t="" data-widget="">ICE</span> username fragment before the host JavaScript sets any answer <span data-t="" data-widget="">SDP</span>.</p>
<p>We use this as a side-channel to exfiltrate the fingerprint of the guest, which the host must set before the connection will be trusted. This allows for one-way connection establishment, whereas normal signaling processes need to be bidirectional.</p>
<p>Outside of this happy path, some data will need to be returned from the guest back to the host: always the fingerprint, and then candidate information for <span data-t="" data-widget="">WAN</span> connections (public <span data-t="" data-widget="">IP</span> and public port, as discovered via a <span data-t="" data-widget="">STUN</span> server).</p>
<p>Here are the steps for basic connection establishment:</p>
<ol>
<li><p>Host generates a password that the guest will set as its password for <span data-t="" data-widget="">ICE</span> (<code class="sdp">a=ice-pwd:$TEMPLATE_PASSWORD</code> in the <span data-t="" data-widget="">SDP</span>)</p>
<pre class="javascript"><code>const AGREED_UPON_PASSWORD = 'this-is-not-a-password+' + String(Math.random()).substring(2);</code></pre>
<div class="Note">
<p>Using <a href="https://developer.mozilla.org/en-US/docs/Web/API/Crypto/getRandomValues"><code class="js">crypto.getRandomValues</code></a> is recommended, but less cute.</p>
<p>Something like</p>
<pre class="javascript"><code>function randomHex() {
  return Array.from(crypto.getRandomValues(new Uint8Array(16)), x=&gt;x.toString(16).padStart(2,'0')).join("").toUpperCase();
}</code></pre>
</div></li>
<li><p>Host starts a peer connection and creates a data channel for it</p>
<pre class="javascript"><code>// Start creating a peer connection
var rtc = new RTCPeerConnection(options);

// As the host, we create a data channel immediately, so it is in the offer
var dc = rtc.createDataChannel('init', { reliable: true });</code></pre></li>
<li><p>Host creates an offer with all available candidates</p>
<pre class="javascript"><code>// Create an offer
var offer = undefined;
rtc.createOffer().then(async desc =&gt; {
  // We need to set it locally
  rtc.setLocalDescription(desc);
  // Bypass trickle ICE
  await new Promise(resolve =&gt; {
    rtc.onicegatheringstatechange = _ =&gt;
      rtc.iceGatheringState === 'complete' &amp;&amp; resolve();
  });
  // The SDP is now updated with ICE candidates
  offer = rtc.localDescription.sdp;
});</code></pre></li>
<li><p>Host generates the JavaScript for the guest, substituting in <code class="js">$TEMPLATE_*</code> variables (the content of the template is given in the following code snippets for the guest)</p>
<pre class="javascript"><code>const templateJS = `...`; // Obtain the guest template somehow
const guestJS = templateJS
  .replace('$TEMPLATE_OPTIONS', options ? `(${options})` : ``)
  .replace('$TEMPLATE_OFFER', "`"+offer+"`")
  .replace('$TEMPLATE_PASSWORD', "`"+AGREED_UPON_PASSWORD+"`");</code></pre></li>
<li><p>Next you have to transport the JavaScript to the guest, <span data-t="" data-widget="">e.g.</span> encode it as an <span data-t="" data-widget="">HTML</span> <code>data:</code> <span data-t="" data-widget="">URI</span> in a <span data-t="" data-widget="">QR</span> code, scan it with a <span data-t="" data-widget="">QR</span> reader that will give you that raw <span data-t="" data-widget="">URI</span>, and paste it into a compatible browser (<strong>not</strong> Firefox on iOS)</p></li>
<li><p>Guest starts setting up its own side of the peer connection</p>
<pre class="javascript" data-lang="Guest JS"><code>var rtc = new RTCPeerConnection($TEMPLATE_OPTIONS);</code></pre></li>
<li><p>Guest sets the offer using the <span data-t="" data-widget="">SDP</span> from the host (can be taken verbatim, maybe preprocessed a little bit by the host to trim candidates, useless information, or whatever)</p>
<pre class="javascript" data-lang="Guest JS"><code>rtc.setRemoteDescription({type:'offer',sdp:$TEMPLATE_OFFER})</code></pre></li>
<li><p>Guest creates its own answer <span data-t="" data-widget="">SDP</span>, and modifies it to exfiltrate the fingerprint and override the password</p>
<pre class="javascript" data-lang="Guest JS"><code>rtc.createAnswer().then({ sdp } =&gt; {
  // Extract the fingerprint from the SDP
  var fingerprint = /fingerprint:sha-256 (.+)/.exec(sdp)[1];
  // Exfiltrate it via `ice-ufrag`
  sdp = sdp.replace(/(a=ice-ufrag):.+/, '$1:'+btoa(fingerprint));
  // And replace `ice-pwd` with the password the host already knows about
  sdp = sdp.replace(/(a=ice-pwd):.+/, '$1:'+$TEMPLATE_PASSWORD);
  // Use this updated answer SDP
  rtc.setLocalDescription({
    type:'answer',
    sdp: sdp,
  });
});</code></pre></li>
<li><p>Guest starts waiting for a data channel, which it will <code class="js">eval</code> messages from</p>
<pre class="javascript" data-lang="Guest JS"><code>var dc;
rtc.ondatachannel = ev =&gt; {
  dc = ev.channel;
  dc.onmessage = e =&gt; eval(e.data);
};</code></pre></li>
<li><p>Host listens for the guest to try to connect, which allows us to finish the connection</p>
<div class="Warning">
This only works on Chromium-based browsers! And only over <span data-t="" data-widget="">LAN</span>! (not behind <span data-t="" data-widget="">NAT</span>)
</div>
<ul>
<li>The fingerprint comes from the <code class="sdp">a=ice-ufrag:</code> line</li>
<li>The password is known, since we asked the guest to set it to the one we chose</li>
<li>The <span data-t="" data-widget="">SDP</span> does not require many other details (like candidates) since the peer already initiated the connection</li>
</ul>
<pre class="javascript"><code>// On Chromium we can see the remote connection that is trying our
// Offer SDP before we have the right Answer SDP and, most importantly,
// before we have the fingerprint for its certificate to trust it
rtc.oniceconnectionstatechange = async (e) =&gt; {
  if (rtc.iceConnectionState === "checking") {
    // This `getStats` API is wonky and not fully standardized
    const stats = [...(await rtc.getStats()).values()];
    // But we can get the remote candidate and thus the username fragment from it
    const { usernameFragment: fingerprint } = stats.find(s =&gt; s.type === 'remote-candidate');
    // Which the guest kindly set to be its fingerprint

    // Most of this Answer SDP is just formality
    // e.g. the `c=` line is literally ignored but must be present
    // I believe the ice-{ufrag,pwd} is enough to identify which remote
    // we are talking about, given that it has attempted to connect
    // already (that is how we got here after all)
    const sdp = `
      v=0
      o=- 1 2 IN IP4 127.0.0.1
      s=-
      t=0 0
      a=group:BUNDLE 0
      a=extmap-allow-mixed
      a=msid-semantic: WMS
      m=application 9 UDP/DTLS/SCTP webrtc-datachannel
      c=IN IP4 0.0.0.0
      a=ice-ufrag:${fingerprint}
      a=ice-pwd:${AGREED_UPON_PASSWORD}
      a=ice-options:trickle
      a=fingerprint:sha-256 ${atob(fingerprint)}
      a=setup:active
      a=mid:0
      a=sctp-port:5000
      a=max-message-size:262144
    `.replaceAll(/\n\s+/g,'\n').slice(1); // keep the trailing newline!

    rtc.setRemoteDescription({ type: 'answer', sdp });
  }
};</code></pre>
<div class="Note">
Note that the host and guest have somewhat/extremely different <span data-t="" data-widget="">SDP</span>s for each other, and this is okay!
</div></li>
<li><p>Host waits for the connection to fully open and then sends some JavaScript over the <code class="js">DataChannel</code> to finish bootstrapping the guest</p>
<pre class="javascript"><code>dc.onopen = () =&gt; {
  dc.send(`
    // Your JavaScript code to start the application
    alert("hi");

    // Remember to clean up from the bootstrapping:
    // Delete global variables (especially from code golfing)
    // Remove event listeners to prevent further \`eval()\`
    rtc.ondatachannel = null;
    dc.onmessage = null;
    // Etc.

    // You also should add error handling, since
    // there was no room for it in the QR code
  `);
};</code></pre></li>
</ol>
<h2 id="tweaks-and-so-on">Tweaks and so on</h2>
<p>First of all: to get the JavaScript-in-HTML-in-<code>data:</code> <span data-t="" data-widget="">URI</span> to fit into a QR code with a full <span data-t="" data-widget="">SDP</span>, the JavaScript template needs to be minified a bunch, but it is possible.</p>
<p>As I mentioned above, outside of this happy path you need to return a fingerprint, and this is what the <a href="https://blog.veritates.love/qrinqr.html">QR in QR</a> code is intended for: with aggressive minification and code golfing, the guest can print a QR code which the host can scan. This is an alright solution for that in a local situation.</p>
<p>And for <span data-t="" data-widget="">WAN</span> connections, it needs the public <span data-t="" data-widget="">IP</span> address and public port from the <span data-t="" data-widget="">STUN</span> candidate(s). I donʼt really have a great way to return this information yet: itʼs just a bit ugly to write the guest code, it really should be a dedicated mode with a separate template. (<span data-t="" data-widget="">TURN</span> servers<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> are basically out of scope for this, though it would be possible to add support&nbsp;… but at that point you should almost always set up your own signaling server and use standard solutions, especially since <span data-t="" data-widget="">TURN</span> servers require passwords and are not publicly available because of the bandwidth considerations.)</p>
<p>Smaller details include:</p>
<ul>
<li>I set the username fragment to be the fingerprint without colons, but putting them back in requires code that is just ugly to present here. (Thanks JavaScript.)</li>
<li>The first <code class="js">eval</code> kicks off a multi-stage bootstrapping, first loading the stage 1 script, which runs itself on the guest, then it calls stage 2 (which is one of the scripts copied by stage 1), and finally it is ready to call the main app now that host and guest are basically identically loaded</li>
<li>Various debug helpers and error handling</li>
<li>Support for remote candidate (from STUN)</li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Apparently just over <span data-t="" data-widget="">LAN</span> (link-local connections?), though I have not really confirmed this.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>which act as relays, especially when one peer is behind symmetric NAT/CGNAT, which prevents P2P connections from being established with the help of STUN<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Code golf for computing a 32-byte QR code!</title>
<pubDate>Fri, 20 Dec 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/qrinqr.html</guid>
<description><![CDATA[<p>If you run <code class="js">.replaceAll(/ *(\/\/[^\n]*\n)?/g, '').replace('\\x20',' ').length</code> on <a href="https://blog.veritates.love/assets/js/qr.ann.js">this fileʼs contents</a>, you will see that this JavaScript comes in at 512 ASCII characters when minified! (Newlines without comments are still used as substitutes for semicolons, to keep the minified file somewhat readable. Other spaces are not important except for the one in the string.)</p>
<p>Why would I do such a thing? Well, it helps me bootstrap a WebRTC connection over QR codes! The host generates a HTML stub that contains this JavaScript, allowing it to display the fingerprint of the guestʼs generated certificate.</p>
<p>There is a hard limit of 2,953 bytes of UTF-8 for QR codes, and I have even less to work with considering that I have to encode it into a <code>data:</code> URI, so having a compact algorithm for this is essential.</p>
<div id="demo">
<p style="display: flex; align-items: baseline; gap: 2em">
<label class="input-wrapper" style="flex: 1"> <span>32 bytes of hexadecimal</span> <input id="demo-input" class="code" style="width: 100%; box-sizing: border-box; text-overflow: ellipsis"> </label> <button id="demo-random" class="add" style="flex: 0 0 auto">Random!</button>
</p>
<pre id="demo-output" class="no-visible-space"></pre>
<script>
  "use strict";
  function randomHex() {
    return Array.from(crypto.getRandomValues(new Uint8Array(32)), x=>x.toString(16).padStart(2,'0')).join(":").toUpperCase();
  }
  function display(f) {
    let s,d,u,a,z,i,r,x,k,Z,V,t,j,o,B,X,N;
    s=420+f.replaceAll(':','')+0
    d=[]
    a=[u=1];z=[1/0]
    for(i=0;d[i/2]="0x"+s[i]+s[++i],i<511;r=[...d])z[a[i]=u=2*u^(u>127)*285]??=i
    for(k=35;Z=+r[i=0],--k;V={})for({abs:B,max:X,min:N}=Math;i<34;t=(x,y=x)=>X(B(x-i),B(y-j)))d[34+i]=r[i]=a['\xFBC.=vF@^ -'.charCodeAt(i)+z[Z]]^r[++i]
    for(i=j=24;~j;j-=j%2^j>6?1:i<u|i-u>24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&0)V[[i,j]]=i-8&&j-8||16<i+j&i+j<25?"101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(i-6&&j-6&&d[k/8|0]>>7-k++%8&1)^(i+j)%2:4588023>>(i-8?24-i:j)&1
    o='';
    for(;~i;i--)for(o+=`
`,j=25;j--;)o+=`<b style=opacity:${V[[i,j]]}>\u2588</b>`
    document.getElementById("demo-output").innerHTML=o;
  }
  var input = document.getElementById("demo-input");
  display(input.value = randomHex());
  input.oninput = () => { if (/^(:?[a-fA-F0-9]{2}){32}$/.test(input.value)) display(input.value) };
  document.getElementById("demo-random").onclick = () => display(input.value = randomHex());
</script>
</div>
<div class="full-width">
<pre class="javascript wrap"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;511;r=[...d])z[a[i]=u=2*u^(u&gt;127)*285]??=i
for(k=35;Z=+r[i=0],--k;V={})for({abs:B,max:X,min:N}=Math;i&lt;34;t=(x,y=x)=&gt;X(B(x-i),B(y-j)))d[34+i]=r[i]=a['\xFBC.=vF@^ -'.charCodeAt(i)+z[Z]]^r[++i]
for(i=j=24;~j;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]=i-8&amp;&amp;j-8||16&lt;i+j&amp;i+j&lt;25?"101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;7-k++%8&amp;1)^(i+j)%2:4588023&gt;&gt;(i-8?24-i:j)&amp;1</code></pre>
</div>
<p>Hereʼs a walkthrough of the code:</p>
<p>Letʼs start with the input <code class="ts">f: string</code>, a 32-byte fingerprint encoded as hexadecimal, with colon separators between each byte. We sandwich it between the strings <code class="js">"420"</code> and <code class="js">"0"</code> to form the raw QR data <code class="ts">s: string</code> in plain hexadecimal: The nibbles <code class="js">"420"</code> represent the encoding mode (<code class="js">0b0100</code> for encoding bytes) and the length of the encoded data (<code class="js">0x20 = 32</code> bytes), and it needs to be padded with the trailing nibble <code class="js">"0"</code> to be a whole number of octets.</p>
<pre class="javascript"><code>s = 420 + (U=f[F='replace'](/:/g,'')) + 0</code></pre>
<p>(<code class="js">U</code> and <code class="js">F</code> are useful for golfing the WebRTC connection establishment – not pictured.)</p>
<p>We are going to grab the octets out of it to form 34 bytes in <code class="js">d</code>, but we also pad <code class="js">d</code> with 10 extra bytes for computing the error correction bytes (they end up as <code class="js">NaN</code>s, which mercifully does not matter, and later we overwrite them).</p>
<pre class="javascript"><code>d = []</code></pre>
<p>These are two tables for Galois fields: <code class="js">a</code> for antilogarithm (exponentiation) and <code class="js">z</code> for logarithm, such that <code class="js">a[z[i]] = i</code> (modulo 256). They are used to transform the problem of multiplication in the Galois field (which is pretty complicated) into a problem of addition (which is addition modulo 256, very easy).</p>
<pre class="javascript"><code>a = [u=1]; z = [1/0]</code></pre>
<p>To fill it in, we loop <code class="js">i</code> in the range <code class="js">0&lt;=i&lt;512</code>: the table repeats from 256 onwards, but doing it this way saves computing the modulo 256 later.</p>
<p>We are computing powers <code class="js">a[i] = 2**i</code> in the Galois field <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">GF</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>256</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{GF}(256)</annotation></semantics></math></span> with prime modulus <code class="js">285 = 0b100011101</code>, subtracted using bitwise “or” (<code class="js">^</code>):</p>
<pre class="javascript"><code>for (i=0; d[i/2] = "0x"+s[i]+s[++i], i &lt; 512; r=[...d]) //
  z[ a[i] = (x=2*a[i-1]) ^ (x &gt; 255)*285 ] ??= i</code></pre>
<p>As you can see, we snuck in the nibbles-&gt;bytes conversion on <code class="js">d</code> in the loop, just to save some space. This ends up filling <code class="js">d</code> with 34 bytes of actual data, 10 bytes of <code class="js">NaN</code> padding, more irrelevant bytes of <code class="js">NaN</code>s, and lots and lots of non-integer keys, all the way up to <code class="js">255.5</code>. Note that they are hexadecimal strings and so they need to be pulled out as numbers, using <code class="js">+d[k]</code>!</p>
<p>Now we compute the error correction code, which will be 10 bytes. This is the most mathematically complicated part!</p>
<p>The error correction code operates on polynomials over <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">GF</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>256</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{GF}(256)</annotation></semantics></math></span>: each “byte” is a coefficient, with index <code class="js">r[0]</code> being the leading term, and the constant term being in the last index.</p>
<p>We have already copied the data from <code class="js">d</code> into <code class="js">r</code>, so we will loop 34 times to compute the remainder, which will end up being 10 bytes after starting with 34 bytes + 10 zeros (the bytes here are roughly the degree of the polynomial, although leading zeros still count). We first save the leading coefficient <code class="js">Z=+r[0]</code> and then loop over the remaining coefficients, propagating them leftwards as we transform them. Although <code class="js">d</code> has a lot of extra junk <code class="js">NaN</code>s that we also copy over, they quickly become zeros from the bitwise arithmetic and do not impact the algorithm. And because <code class="js">z[0] = 1/0 = Infinity</code>, on the loop iterations when <code class="js">Z=+r[0]=0</code>, it just shifts all relevant items leftwards by one index, removing leading zeros one at a time.</p>
<p>The array <code class="js">[251,67,46,61,118,70,64,94,32,45][i]</code> is encoded as <code class="js">'\xFBC.=vF@^\x20-'.charCodeAt(i)</code>, and it represents the logarithm of the coefficients of the error correction polynomial, minus its leading term (the polynomial is monic, so its leading coefficient is <code class="js">1</code>, whose logarithm is <code class="js">0</code>). (The polynomial is the multiplication of <code class="js">(x-0)...(x-9)</code>, which we <em>could</em> compute&nbsp;… but it is shorter to just embed the coefficients directly, since we do not use polynomial multiplication anywhere else.) By taking the antilogarithm of the addition of the logarithms, we compute multiplication in <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">GF</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>256</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{GF}(256)</annotation></semantics></math></span>. This is where the doubled length of <code class="js">a</code> saves us one modulo operation, and awkward parenthesization to boot. Altogether, this computes the remainder of dividing the data (represented as a polynomial in <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">GF</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>256</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{GF}(256)</annotation></semantics></math></span>) by the error correction polynomial.</p>
<pre class="javascript"><code>for (k = 35; Z = +r[i=0], --k; V={}) //
  for ( var { abs: B, max: X, min: N } = Math; // grab some helpers
        i&lt;34; // loop from i=0 through i=33
        t=(x,y=x)=&gt;X(B(x-i),B(y-j)) // define a function for QR patterns for later
      ) //
    d[34+i] = r[i] = a['\xFBC.=vF@^\x20-'.charCodeAt(i) + z[Z]] ^ r[++i]</code></pre>
<p>Since we need to splice the result of error correction, namely <code class="js">r[0..10]</code>, into the bytes after our padded data, namely <code class="js">d[34..44]</code>, we just continuously perform this copying during the loop: only the last time we do this matters. (And of course we continue the tradition of adding junk to <code class="js">d</code> after the data we care about.)</p>
<p>Now we are ready to generate the graphical content of the QR code!</p>
<p>We will write each “module” (pixel) into <code class="js">V={}</code>, where <code class="js">V["0,0"]</code> is the top left, <code class="js">V["24,0"]</code> is the bottom left, <code class="js">V["0,24"]</code> is the top right, and so on. We use a cute array trick to build these coordinates: <code class="js">V[[0,0]]</code> evaluates to <code class="js">V["0,0"]</code>, since the object index <code class="js">[0,0]</code> gets coerced to a string, joining the stringified components with a comma. This is shorter than trying to initialize an array with 25 empty arrays.</p>
<p>After a lot of thinking and experimentation, I was able to reduce the QR code generation to one single loop, which is the best way to save characters, since <code class="js">for</code> loops require a lot of characters to set up (and <code class="js">while</code> loops are no better).</p>
<p>The first note is that we have to walk the QR code in a strange way to pull out the data in the correct order:</p>
<ul>
<li>We start by walking upwards: <code class="js">u=1</code>, and this corresponds to bit <code class="js">k=0</code> of the data. (These variables were initialized in other places, to save characters.)</li>
<li>The small-scale zigzag pattern is handled by <code class="js">j -= 1</code> or <code class="js">j += 1, i -= u</code></li>
<li>The condition to decide between these is a little annoying: for <code class="js">j &gt; 6</code>, it is odd values <code class="js">j</code>, and for <code class="js">j &lt; 6</code>, it is even values of <code class="js">j</code>. (Column 7 is skipped over, as it has timing patterns.) Thus if <code class="js">j%2 ^ j&gt;6</code> is truthy, we choose <code class="js">j -= 1</code>, else <code class="js">j += 1, i -= u</code>.</li>
<li>To make the larger-scale zigzag, when we reach the top or bottom edges of the QR code (<code class="js">i-u &lt; 0 || i-u == 25</code>), we decrement <code class="js">j</code>, and swap <code class="js">u = -u</code> to wander the other way.</li>
<li>There is one special case: along the column <code class="js">j=6</code>, we walk strictly from top to bottom (<code class="js">i++</code>), to pick up the fixed patterns and the timing pattern that fills the rest of the column. When that reaches the bottom, we resume at the top with <code class="js">i=0</code> and <code class="js">u=-1</code> along column <code class="js">j=5</code>.</li>
</ul>
<p>First we add some static information about the QR codeʼs error correction level (Low) and Mask Pattern (0). This would be a nightmare to compute dynamically, because they also contain error correction and masking themselves, so instead we embed magic bitstrings encoded as decimal (shorter than hexadecimal). The magic bitstring is <code class="js">4588023 = 0b0010001100000000111110111</code>, read from right to left and top to bottom. This information ends up along row 9 and column 9, with gaps in the middle: <code class="js">16 &lt; i+j &amp;&amp; i+j &lt; 25</code> is a cute way to encode the gaps without checking which of <code class="js">i</code> or <code class="js">j</code> equals <code class="js">8</code>: if <code class="js">j=8</code>, then it translates to <code class="js">8 &lt; i &lt; 17</code>, and vice-versa.</p>
<p>Next we use a helper <code class="js">t = (x,y=x) =&gt; Math.max(Math.abs(x-y), Math.abs(y-i))</code> to compute square patterns around certain locations. It returns the largest deviation of the current coordinate <code class="js">[i,j]</code> from the center <code class="js">[x,y]</code>, and if it is too high, the pattern will not be applied and the next part of the algorithm will run instead.</p>
<ul>
<li>The three finder patterns around <code class="js">[3,3]</code>, <code class="js">[3,21]</code> and <code class="js">[21,3]</code> have a radius of <code class="js">5</code> and the bit pattern <code class="js">"11010"</code>. (These are fixed for all QR codes.)</li>
<li>The lone alignment pattern at <code class="js">[18,18]</code> has a radius of <code class="js">3</code> and the bit pattern <code class="js">"101"</code>. (Larger versions of QR codes have more alignment patterns.)</li>
</ul>
<p>Next there are two timing patterns, vertical and horizontal, that run along row 7 and column 7 in the space not taken up by the other patterns. Again we can combine both lines into one check: <code class="js">(i+j)%2</code>.</p>
<p>Finally, if none of the static patterns apply, we have to pull out the binary data and increment the bit index <code class="js">k</code>:</p>
<ul>
<li>The <em>byte</em> we are interested in is <code class="js">d[(k/8) | 0]</code> which computes the integer division of <code class="js">k</code> by <code class="js">8</code>,</li>
<li>and the <em>bit index</em> is <code class="js">7 - (k%8)</code>, which is the amount we shift the byte by before masking with <code class="js">&amp; 1</code> (while incrementing <code class="js">k</code> inline, which saves some characters).</li>
<li>(Remember that <code class="js">d</code> now contains the error correcting code from bytes <code class="js">34</code> to <code class="js">44</code>!)</li>
<li>Finally we negate and XOR it with <code class="js">!(...) ^ (i+j)%2</code> to implement masking pattern 0, which consists of inverting the odd pixels.</li>
</ul>
<p>Notice that the masking pattern <code class="js">(i+j)%2</code> coincides nicely with the timing pattern: we only compute it once for the both of them! This is the reason for choosing that masking pattern, and we also happen to save a character with the magic constant <code class="js">4588023 = 0b0010001100000000111110111</code> because of its two leading zeros (which are displayed as white pixels on the right side and the top of the QR code, along row/column 9).</p>
<pre class="javascript"><code>for ( // Zigzag from bottom right, up and around to bottom left
      i = j = 24; ~j;                            //
      j -= j%2 ^ j&gt;6 ? 1 :                       //
           i&lt;u|i-u&gt;24 ? (j-6 ? u=-u : i=0,  1) : //
           j-6 ? (i-=u,-1) : i++ &amp; 0             //
    ) //
  V[[i,j]] = //
    i-8 &amp;&amp; j-8  ||  16&lt;i+j &amp; i+j&lt;25 // detect metadata or not
    ? "101"[t(18)] ?? // alignment pattern
      "11010"[N(t(3),t(3,21),t(21,3))] ?? // finder patterns
      !(i-6 &amp;&amp; j-6 &amp;&amp; // i==6 or j==6 for timing patterns
        d[k/8 | 0] &gt;&gt; 7 - k++%8  &amp;  1 // data + error correction, indexed by bit
      ) ^ (i+j)%2 // timing patterns *and* mask pattern
    : 4588023 &amp; 1&lt;&lt;(i-8 ? 24-i : j) // metadata</code></pre>
<p>Tada! Now we are left with <code class="js">V</code>, an object whose <em>numeric</em> value at index <code class="js">i+','+j</code> is nonzero if the pixel at <code class="js">i,j</code> is black and zeroish if it is white. (You have to pull it out with <code class="js">+V[[i,j]]</code> to cast the <code class="js">"0"</code> strings to a zero value.)</p>
<p>Tricks we used along the way include</p>
<ul>
<li>Booleans doubling as numbers, <code class="js">|</code> instead of <code class="js">||</code>, and other such coercions.</li>
<li>Very careful analysis of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_precedence#table">operator precedence</a> to eliminate parentheses. It is honestly so ridiculous that <code class="js">d[k/8|0]&gt;&gt;7-k++%8&amp;1</code> works correctly!</li>
<li><code class="js">j-6</code> as a subsitute for <code class="js">j!=6</code> when only the truthiness mattered (mostly in ternary conditionals!): e.g.&nbsp;<code class="js">j-6 ? u=-u : i=0</code> means “if <code class="js">j</code> is <code class="js">6</code>, then <code class="js">i=0</code>, else flip the sign of <code class="js">u</code>”.</li>
<li><code class="js">V[[i,j]]</code> to encode indices as <code class="js">i+','+j</code>.</li>
<li>Using static tables like <code class="js">"101"[t(18)]</code> and <code class="js">[251,67,46,61,118,70,64,94,32,45][i]</code> (actually <code class="js">'\xFBC.=vF@^ -'.charCodeAt(i)</code> now) and the bitstring <code class="js">4588023 &amp; 1&lt;&lt;j</code> to cheaply encode choices that change over time.</li>
<li>Squashing lots of loops together and re-using loop indices, to save on characters.</li>
<li>One single helper function. Seriously, it wasnʼt worth it for anything else!</li>
</ul>
<p>In general, choosing as many parts of the QR code standard ahead of time as is possible (fixed size, fixed mask pattern, fixed length, and so on) is the only way this was possible. And choosing a fixed mask pattern, while technically discouraged, is not even that big of a deal: the fingerprint bytes are essentially random, so odds are that this pattern will be good enough anyways.</p>
<p>All in all, this feels like a really successful project. It is incredible that it is even possible, and I am even happier that the code crystallized into a somewhat tidy form, as opposed to some of the monsters I created during development. All the characters I shaved off here are characters I can put towards things like WebRTC connection information in the SDP, or CSS, or error handling, or proper HTML structure.</p>
<p>Of course, most of the journey of how this code evolved and came out, what I was thinking of and what I <em>wasnʼt</em> thinking of, is in the less successful attempts at golfing the algorithm:</p>
<details class="Details">
<summary>
Previous revisions
</summary>
<p>These are just the copies I still have lying around, there arenʼt particularly evenly distributed or anything. Some of them have bugs!</p>
<ol>
<li><p>672 characters, my first real proof of concept after a day of hyperfocus. You can see that I used some different methods and initialized the layers of the QR code one at a time, costing four whole loops (but no special cases!):</p>
<pre class="javascript"><code>let{abs:B,max:X,min:N}=Math
a=[1]
z=[0,0]
for(i=0;++i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
s='420'+f.replace(/:/g,'')+'0'
d=[];for(i=0;i&lt;68;)d[i/2]=+("0x"+s[i++]+s[i++])
r=[...d,..."0000000000"]
while(X(...r.slice(0,-10))&gt;0)r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[r[0]]])
V=[]
W=25
for(i=0;i&lt;W;i+=i-8?1:9)V[V[[8,i]]=27132263&amp;1&lt;&lt;i,[i,8]]=30015987&amp;1&lt;&lt;i
for(i=W;i--&gt;0;)for(j=W;j--&gt;0;)V[t=(x,y=x)=&gt;X(B(x-i),B(y-j)),[i,j]]??="11010"[N(t(3),t(3,21),t(21,3))]??"101"[t(18)]??(i-6?j-6?V.V:1-i%2:1-j%2)
k=0;u=1
i=j=W-1
while(j&gt;=0)j-=(V[[i,j]]??=[...d,...r.slice(-10)][k/8|0]&gt;&gt;(7-k++%8)&amp;1^(1-i%2),j-(j&gt;6))%2?1:(i-u&lt;0||i-u==W)?(u=-u,j-7?1:2):(i-=u,-1)</code></pre></li>
<li><p>650 characters:</p>
<pre class="javascript"><code>let{abs:B,max:X,min:N}=Math
a=[1]
z=[0,0]
for(i=0;++i&lt;512;z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i)d=[]
s=420+(U=f[F='replace'](/:/g,''))+0
for(i=0;i&lt;88;)d[i/2]=+("0x"+s[i++]+s[i++])
for(r=[...d];X(...r.slice(0,-10))&gt;0;r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[r[0]]]))W=25
V=[]
for(i=0;i&lt;W;i+=i-8?1:9)V[V[[8,i]]=27132263&amp;1&lt;&lt;i,[i,8]]=30015987&amp;1&lt;&lt;i
for(i=W;i--;d[34+i]=r.at(-10+i))for(j=W;j--;)V[t=(x,y=x)=&gt;X(B(x-i),B(y-j)),[i,j]]??="11010"[N(t(3),t(3,21),t(21,3))]??"101"[t(18)]??(i-6?j-6?V.V:1-i%2:1-j%2)
k=0;u=1
for(i=j=W-1;j&gt;=0;j-=(j-(j&gt;6))%2?1:(i-u&lt;0||i-u==W)?(u=-u,j-7?1:2):(i-=u,-1))V[[i,j]]??=d[k/8|0]&gt;&gt;(7-k++%8)&amp;1^(1-i%2)</code></pre></li>
<li><p>636 characters:</p>
<pre class="javascript"><code>let{abs:B,max:X,min:N}=Math
a=[1]
z=[0,0]
for(i=0;++i&lt;512;z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i)d=[]
s=420+(U=f[F='replace'](/:/g,''))+0
for(i=0;i&lt;88;)d[i/2]=+("0x"+s[i++]+s[i++])
for(r=[...d];X(...r.slice(0,-10))&gt;0;r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[r[0]]]))W=25
V=[]
for(i=0;i&lt;W;i+=i-8?1:9)d[34+i]=r.at(-10+i),V[V[[8,i]]=27132263&amp;1&lt;&lt;i,[i,8]]=30015987&amp;1&lt;&lt;i
k=0;u=1
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
for(i=j=W-1;j&gt;=0;j-=(j-(j&gt;6))%2?1:i-u&lt;0||i-u==W?(j-6?u=-u:i=1,1):j-6?(i-=u,-1):(i+=1,0))V[[i,j]]??="11010"[N(t(3),t(3,21),t(21,3))]??"101"[t(18)]??(i-6&amp;&amp;j-6?V.V:(1-i+j)%2),V[[i,j]]??=d[k/8|0]&gt;&gt;(7-k++%8)&amp;1^!(i%2)</code></pre></li>
<li><p>604 characters. <code class="js">31327172</code> was my favorite number, but it was not canonical and it did not stay long.</p>
<pre class="javascript"><code>let{abs:B,max:X,min:N}=Math
a=[1];z=[0,0]
for(i=0;++i&lt;512;d=[])z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
s=420+(U=f[F='replace'](/:/g,''))+0
for(i=0;i&lt;88;)d[i/2]=+("0x"+s[i++]+s[i++])
for(r=[...d];X(...r.slice(0,-10))&gt;0;)r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[r[0]]])
V={}
for(i=0;i&lt;25;i+=i-8?1:9)d[34+i]=r.at(i-10),V[V[[8,i]]=4588023&amp;1&lt;&lt;i,[i,8]]=31327172&amp;1&lt;&lt;i
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
k=0;u=1
for(i=j=24;j+1;j-=j%2^j&gt;6?1:i-u&lt;0||i-u==25?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):(i++,0))V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(1+i+j)%2</code></pre></li>
<li><p>594 characters:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[1];z=[0,0]
for(i=0;d[i/2]=+("0x"+s[i]+s[++i]),i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
let{abs:B,max:X,min:N}=Math
for(r=d.slice(0,44);X(...r.slice(0,-10))&gt;0;)r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[r[0]]])
V={}
for(i=0;i&lt;25;i+=i-8?1:9)d[34+i]=r.at(i-10),V[[8,i]]=4588023&amp;1&lt;&lt;i,V[[i,8]]=31327172&amp;1&lt;&lt;i
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
k=0;u=1
for(i=j=24;j+1;j-=j%2^j&gt;6?1:i-u&lt;0||i-u==25?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):(i++,0))V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(1+i+j)%2</code></pre></li>
<li><p>561 characters:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0,0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
let{abs:B,max:X,min:N}=Math
for(r=d.slice(0,44);r[10]+1;r=r.slice(1).map((x,i)=&gt;x^a[[251,67,46,61,118,70,64,94,32,45][i]+z[+r[0]]]))V={}
for(k=i=0;i&lt;25;i+=i-8?1:9)V[[8,i]]=4588023&amp;1&lt;&lt;i,V[[i,8]]=31326660&amp;1&lt;&lt;i
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
for(i=j=24;j+1;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(d[34+k]=r[k],i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(i+j)%2</code></pre></li>
<li><p>553 characters, when I switched to manual iteration for the Galois remainder:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
r=[...d]
for(k=35;Z=+r[i=0],--k;V={})for(;i&lt;34;)r[i]=a[[251,67,46,61,118,70,64,94,32,45][i]+z[Z]]^r[++i]
for(i=0;i&lt;25;i+=i-8?1:9)V[[i,8]]=31326404&amp;1&lt;&lt;i,V[[8,i]]=4588023&amp;1&lt;&lt;i
let{abs:B,max:X,min:N}=Math
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
for(i=j=24;j+1;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(d[34+k]=r[k],i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(i+j)%2</code></pre></li>
<li><p>552 characters, when I consolidated the magic constants:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
r=[...d]
for(k=35;Z=+r[i=0],--k;V={})for(;i&lt;34;)r[i]=a[[251,67,46,61,118,70,64,94,32,45][i]+z[Z]]^r[++i]
for(i=0;i&lt;25;i+=i-7?1:10)V[[8,i]]=V[[24-i,8]]=4588023&amp;1&lt;&lt;i
let{abs:B,max:X,min:N}=Math
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
for(V[[8,8]]=i=j=24;j+1;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(d[34+k]=r[k],i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(i+j)%2</code></pre></li>
<li><p>548 characters:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;512;)z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
r=[...d]
for(k=35;Z=+r[i=0],--k;V={})for(;i&lt;34;)r[i]=a[[251,67,46,61,118,70,64,94,32,45][i]+z[Z]]^r[++i]
for(;i&lt;25;i+=i-7?1:10)V[[8,i]]=V[[24-i,8]]=4588023&amp;1&lt;&lt;i
let{abs:B,max:X,min:N}=Math
t=(x,y=x)=&gt;X(B(x-i),B(y-j))
for(V[[8,8]]=j=--i;j+1;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]??="101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(d[34+k]=r[k],i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(i+j)%2</code></pre></li>
<li><p>526 characters, when I finally got the QR code down to one loop:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;512;r=[...d])z[a[i]=((x=2*a[i-1])&gt;255)*285^x]??=i
for(k=35;Z=+r[i=0],--k;V={})for(var{abs:B,max:X,min:N}=Math;i&lt;34;t=(x,y=x)=&gt;X(B(x-i),B(y-j)))r[i]=a[[251,67,46,61,118,70,64,94,32,45][i]+z[Z]]^r[++i]
for(i=j=24;d[34+k]=r[k],~j;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]=i-8&amp;&amp;j-8||16&lt;i+j&amp;i+j&lt;25?"101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;(7-k++%8)&amp;1)^(i+j)%2:4588023&amp;1&lt;&lt;(i-8?24-i:j)</code></pre></li>
<li><p>518 characters:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;516;r=[...d])z[a[i]=(x=2*a[i-1])^(x&gt;255)*285]??=i
for(k=35;Z=+r[i=0],--k;V={})for(var{abs:B,max:X,min:N}=Math;i&lt;34;t=(x,y=x)=&gt;X(B(x-i),B(y-j)))d[34+i]=r[i]=a[[251,67,46,61,118,70,64,94,x,45][i]+z[Z]]^r[++i]
for(i=j=24;~j;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]=i-8&amp;&amp;j-8||16&lt;i+j&amp;i+j&lt;25?"101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;7-k++%8&amp;1)^(i+j)%2:4588023&amp;1&lt;&lt;(i-8?24-i:j)</code></pre></li>
<li><p>502 characters:</p>
<pre class="javascript"><code>s=420+(U=f[F='replace'](/:/g,''))+0
d=[]
a=[u=1];z=[1/0]
for(i=0;d[i/2]="0x"+s[i]+s[++i],i&lt;511;r=[...d])z[a[i]=u=2*u^(u&gt;127)*285]??=i
for(k=35;Z=+r[i=0],--k;V={})for({abs:B,max:X,min:N}=Math;i&lt;34;t=(x,y=x)=&gt;X(B(x-i),B(y-j)))d[34+i]=r[i]=a['\xFBC.=vF@^ -'.charCodeAt(i)+z[Z]]^r[++i]
for(i=j=24;~j;j-=j%2^j&gt;6?1:i&lt;u|i-u&gt;24?(j-6?u=-u:i=0,1):j-6?(i-=u,-1):i++&amp;0)V[[i,j]]=i-8&amp;&amp;j-8||16&lt;i+j&amp;i+j&lt;25?"101"[t(18)]??"11010"[N(t(3),t(3,21),t(21,3))]??!(i-6&amp;&amp;j-6&amp;&amp;d[k/8|0]&gt;&gt;7-k++%8&amp;1)^(i+j)%2:4588023&gt;&gt;(i-8?24-i:j)&amp;1</code></pre></li>
</ol>
<p>And as an addendum since you were nice enough to scroll through here, the silly code that renders it to HTML!</p>
<pre class="html"><code>&lt;style&gt;pre{line-height:1;padding:3em;transform:scaleY(0.6)}&lt;/style&gt;</code></pre>
<pre class="javascript"><code>o=f+'&lt;pre&gt;'
for(;~i;i--)for(o+='\n',j=25;j--;)o+=`&lt;b style=opacity:${V[[i,j]]}&gt;\u2588&lt;/b&gt;`
document.body.innerHTML=o</code></pre>
</details>
<p>And some links to helpful resources about QR codes:</p>
<ul>
<li><a href="https://qr.blinry.org/" class="uri">https://qr.blinry.org/</a></li>
<li><a href="https://www.nayuki.io/page/creating-a-qr-code-step-by-step" class="uri">https://www.nayuki.io/page/creating-a-qr-code-step-by-step</a></li>
<li><a href="https://www.thonky.com/qr-code-tutorial/" class="uri">https://www.thonky.com/qr-code-tutorial/</a></li>
</ul>
<style>
  #demo > pre {
    font-size: 8px;
    line-height: 1;
    padding: 5em 3em;
    user-select: none;
    transform: scaleY(0.6);
    transform-origin: top center;
    color: black;
    background: white;
    width: fit-content;
    margin: auto;
    margin-bottom: -10em;
  }
  pre.sourceCode:not([data-lang]).javascript::before {
    content: '';
    margin-bottom: 0;
  }
  pre.sourceCode:not([data-lang]).javascript {
    white-space: pre-wrap;
    overflow-wrap: anywhere;
    max-width: 100%;
  }
</style>]]></description>
</item>
<item>
<title>Design your programming languages right!</title>
<pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/design_it_right.html</guid>
<description><![CDATA[<p>I just think we should have some ground rules for new programming languages and their configuration. Yʼknow?</p>
<p>Just some rambly thoughts on features I think you should include, or at least think about and not block yourself <em>out of</em> including. And other topics I am thinking about with no real answers yet.</p>
<h2 id="solved-problems-non-issues">Solved problems / non-issues</h2>
<h3 id="indented-multiline-strings">Indented multiline strings!</h3>
<p>Itʼs so ugly when you go to embed a multiline string into your code, and you realize that you’re going to have to close your eyes and pretend the current indentation level does not exist, as the raw contents take over the left gutter.</p>
<p>This is a solved problem. <a href="https://github.com/dhall-lang/dhall-lang/blob/master/standard/multiline.md">Dhall</a> did a pretty good job of it (although I am not too fond of the escaping rules there), and <a href="https://docs.lix.systems/manual/lix/stable/language/values.html#type-string">Nix/Lix</a> have similar rules.</p>
<p>I implemented similar logic for JavaScript template literals in <a href="https://blog.veritates.love/assets/js/verity.js">Ve.dedent</a>, I am very happy with it. And Iʼve tried my best for PureScript (and Python?), but not having the distinction between source and escaped/interpolated texts makes it much harder, and more of a tool that works for some cases than a systematic approach that it could be if it was baked in.</p>
<p>Indented multiline strings are just a thing that you can put a few extra hours of effort into fixing early, before it becomes a problem for your users and then you canʼt change without backwards compatibility issues.</p>
<h3 id="relative-file-paths">Relative file paths</h3>
<p>File paths should be relative to the file theyʼre in, or to a well defined project root. This mostly applies to configuration, less so running programs (for which a working directory is usually fine), but like&nbsp;… imports should be predictable.</p>
<p>Notably, configuration files for both <a href="https://docs.docker.com/compose/how-tos/multiple-compose-files/extends/#understanding-multiple-compose-files">Docker Compose</a> and <a href="https://doc.rust-lang.org/cargo/reference/config.html#config-relative-paths">Rustʼs Cargo</a> get this wrong.</p>
<p>Again, you have to get it right up-front, or figure out solid plans for versioning. (But of course, programming languages that donʼt have the thought put in to get it right up front, usually donʼt have good enough versioning policies to deal with this either.)</p>
<h3 id="file-extensions">File extensions</h3>
<p>Pick an extension or two, and stick to it! Remember that if youʼre a new language, youʼre a guest entering existing ecosystems by their good grace and should work on their terms.</p>
<p>Syntax highlighting, in IDEs and online code viewers/git forges, is mainly based on the file extension. And if you donʼt have a recognizable file extension, your users are going to have to work harder.</p>
<p>As one example, Bazel uses Starlark in files named <code>WORKSPACE</code> and <code>BUILD</code> and <code>.bzl</code> or <code>.bazel</code>. Starlark just has Python syntax highlighting, which is nice that you can use that.</p>
<p>But itʼs hard to convince your IDE to highlight them if thereʼs different extensions and extensionless file names. (Itʼs even harder if these names are configurable, but I donʼt think <code>WORKSPACE</code> and <code>BUILD</code> are?) Itʼs harder to <code>grep</code> through the files if you have to include all the forms that it can occur. And so on.</p>
<h3 id="commas">Commas</h3>
<p>Another solved problem: allow trailing commas! (And possibly leading commas, if you feel like that&nbsp;… or actual bullet points.)</p>
<h3 id="extensible-syntax">Extensible syntax</h3>
<p>A lot of languages have made mistakes around numeric literals (wanting to add more prefixes or suffixes, but the path forward is blocked by backwards compatibility), or string/regex escapes (use delimited escapes like <code class="js">"\u{XXXX}"</code>!), or keywords.</p>
<p>Itʼs more my personal opinion, but I dislike bare keywords. I think keywords should come with a sigil to clearly denote them as a keyword and allow extending the language with more keywords without breaking old code that used them as identifiers. Do you <em>really</em> think youʼll get the perfect set of keywords right the first time? … can you point to a programming language that did?</p>
<h2 id="mostly-unsolved-nuanced-problems">(Mostly) unsolved, nuanced problems</h2>
<h3 id="developer-experience-vs-released-code">Developer experience vs Released code</h3>
<p>iterating on code as youʼre developing it, versus having a nice clean, pristine released version&nbsp;… theyʼre quite different things, and I think these workflows should be respected!</p>
<p>e.g.&nbsp;when developing, we often put web servers on different ports and/or LAN hosts, and use HTTP or self-signed HTTPS (or even <code>file:///</code> in the few cases we can get away with it!), whereas in production it might be behind a reverse proxy under some specific route, and so on.</p>
<h3 id="versioning">Versioning</h3>
<p>Versioning means a lot of things.</p>
<p>One of the problems that I havenʼt really seen <em>solved</em> before, is how to deal with code <em>across</em> versions.</p>
<p>Like, letʼs say that I want to have a migration script between versions of my released software. Well, I guess the code for it has to live in the later version – itʼs not like the previous version knew what was coming up. But how do you test it? You kind of need to check out the previous version of your code from source control, and have them both in parallel. (This is also something where the “development” and “release” modes are pretty separate!)</p>
<p>And in general, if youʼre expecting people to write libraries in your programming language, give them a sensible way to talk about versions. One of the cooler tools in this area are the ones that check a libraryʼs API (especially if it is typed!) to determine whether it should be a patch/minor/major release.</p>
<p><em>However</em>, I must stress: version numbers are always going to be subject to judgment calls. They are an imperfect tool of communication, not a mathematically precise abstraction.</p>
<hr>
<p>Oh another hobby horse: Please always include dates with your release version numbers! It doesnʼt have to be <em>in</em> the version number, but it should be easily accessible, displayed beside it or in a tooltip or on a canonical webpage. Itʼs nearly impossible to compare versions <em>across</em> software (languages, runtimes, packages, dependencies) without having a sense of release dates of it all.</p>
<h3 id="file-watching">File watching</h3>
<p>This is part of a larger discussion around build systems and the like, but.</p>
<p>Iʼve never found it possible to retrofit detailed file watching onto build systems that didnʼt have it. Without, like, writing a whole Python program to go and parse files, reconstruct their dependency tree, make sure I know how each file is getting used and if it is relevant at all, reload the whole watcher if the configuration changes, and so on.</p>
<h3 id="integration-with-tools">Integration with tools</h3>
<p>Like <code>find</code>/<code>grep</code>: itʼs much nicer if you can ask your build tool to tell you all the files to search through, and then you can ask if you want to include dependencies or not. (Also this listing of files/globs gives you a first step towards filewatching too, although (again) you really need proper integration to be able to account for added files, and changing configuration, and so on!)</p>
<p>Itʼs even better if you want to add proper code search, being able to distinguish your search terms in identifiers versus strings, or in types versus terms, and so on. Yeah ^.^</p>]]></description>
</item>
<item>
<title>Self-names (paths)</title>
<pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/selfnames.html</guid>
<description><![CDATA[<blockquote>
<p><a href="https://martinfowler.com/bliki/TwoHardThings.html">There are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors.</a> </p>
</blockquote>
<p>You know, Iʼve always heard this and been like, “Yeah, naming functions and variables is difficult, language and communication are difficult, I guess Iʼll just call it <code>Create​Puppeteer​And​Chromium​Instance​Or​Testing​Stub​Factory</code> and call it a day”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>However, I think the stronger problem is that we expect to be able to reuse names (*paths) in contexts other than they were made in. We need to!</p>
<h2 id="selfnames-in-webdev-with-reverse-proxies">Selfnames in webdev with reverse proxies</h2>
<p>Reverse proxies (like nginx) are a particularly compelling example of this that I keep running into: they can change the public URL of something, in a way that the code often needs to know about, and there isnʼt always a great way to tell the frontend code about.</p>
<p>For work Iʼve been working on packaging our multiple layers of products into a single deployment, thus deployed on a single HTTPS port but with different root paths for each software. Getting it to work through the reverse proxies was a bit of a pain (and is still not perfectly finished: some paths have to redirect like <code>/B/*</code> -&gt; <code>/A/B/*</code>).</p>
<p>For my blog, Iʼve kept the directory structure very predictable so far so it doesnʼt matter where it is hosted: there are no absolute references, even to <code>assets/</code> and so on. But if I want to have articles that are nested under directories, either I need to add a <code>../</code> to all of these relative URLs, or I need to commit to having it hosted at the root of the domain.</p>
<p>There are some ways to work around this&nbsp;… unfortunately <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base"><code>&lt;base&gt;</code></a> is a particularly bad one, since it cannot leave relative URLs unaffected, for example. (It would be great if it was able to just rename absolute URLs that start with a slash, for example.)</p>
<p>Idk, you basically just have to commit to caring about it in <em>some</em> place, passing along information to handle it where you can (and hopefully not break down too many abstraction boundaries).</p>
<h2 id="selfnames-in-programming-languages-modules">Selfnames in programming languages (modules?)</h2>
<p>When developing <a href="https://blog.veritates.love/assets/js/verity.js">verity.js</a> I decided that I prefer the code to be <em>copyable</em>, not convenient to write. So I committed to always writing out the <code class="js">Ve.</code> prefix so that I was able to copy the source code out and run it from outside the module, .</p>
<p>But to some extent this <em>should</em> be a tooling problem, <em>were</em> we to live in the alternate reality where we treated programs as structured syntax, not plain text.</p>
<p>Like, in theory, if you were to copy code out of one Haskell or PureScript (not JavaScript) module into another, it would be able to re-qualify all of the identifiers and add imports for you, possibly throwing an error <em>only</em> if the code was using local identifiers that were not exported (though it could prompt you with a button to add exports for them).</p>
<p>But the hegemonic tools we are forced to use do not understand this fine distinction.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Fictional example, no Iʼve never done that.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Monoids in Public</title>
<pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/monoids_in_public.html</guid>
<description><![CDATA[<h2 id="vdom-trees-as-monoids">VDOM trees as monoids</h2>
<p class="dated">
2023/11/15
</p>
<p>Imagine you have your favorite VDOM model:</p>
<pre class="purescript"><code>data VDOM
  = Text String
  | Node
      ElementType
      (Array Attributes)
      (Array VDOM)</code></pre>
<p>Now, weʼve done this before, itʼs pretty inconvenient to use. It forces use to reify component boundaries in the DOM itself. If you need to return something of type <code class="haskell">VDOM</code>, but you produced several things, you need to wrap it in a <code class="html">&lt;div&gt;</code> or <code class="html">&lt;span&gt;</code> – but now you need to know which to choose! Itʼs not great.</p>
<p>What if we made <code class="haskell">VDOM</code> into a monoid? That would solve lots of problems!</p>
<p>This is basically what React Fragments are, so we add a new constructor:</p>
<pre class="purescript"><code>data VDOM
  = Text String
  | Node
      ElementType
      (Array Attributes)
      VDOM
  | Fragment
      (Array VDOM)</code></pre>
<p>The advantage of adding a new constructor is that we donʼt have to change so many types, particularly when constructing things. We just need a new way to consume <code class="haskell">Fragment</code> at the end of the process.</p>
<div class="Note" data-box-name="Side-Effect">
<p>The children of a <code class="haskell">VDOM</code> do not have to be an array anymore, which makes constructing them slightly more convenient sometimes. (And in other circumstances, you can just use <code class="haskell">Fragment</code> or <code class="haskell">fold :: Array VDOM -&gt; VDOM</code>.)</p>
</div>
<p>Now we can write an interesting monoid instance for this, which builds up a fragment but tries to remove nesting as it does so.</p>
<pre class="purescript"><code>instance Monoid VDOM where
  mempty = Fragment []
instance Semigroup VDOM where
  append (Fragment []) vdom = vdom
  append vdom (Fragment []) = vdom
  append (Fragment v1s) (Fragment v2s) = Fragment (v1s &lt;&gt; v2s)

  -- Keep flattening, to keep it associative
  append v1 (Fragment v2s) = Fragment ([v1] &lt;&gt; v2s)
  append (Fragment v1s) v2 = Fragment (v1s &lt;&gt; [v2])

  -- Finally, if none of the above cases apply,
  -- we wrap it up in a two-element array:
  append v1 v2 = Fragment [v1, v2]</code></pre>
<details class="Bonus">
<summary>
Bonus
</summary>
<p>You can also add special behavior if you want to collapse <code class="haskell">Text</code> nodes, but this starts to get a little ugly since it needs to look inside <code class="haskell">Fragment</code> too:</p>
<pre class="purescript"><code>instance Semigroup VDOM where
  append (Fragment []) vdom = vdom
  append vdom (Fragment []) = vdom
  append (Fragment v1s) (Fragment v2s) = Fragment (v1s &lt;&gt; v2s)

  -- Handle text specially
  append (Text "") vdom = vdom
  append vdom (Text "") = vdom
  append (Text t1) (Text t2) = Text (t1 &lt;&gt; t2)

  -- We need to handle text at the edges of fragments too
  -- for associativity (I did not check all of the details)
  append (Fragment vs) (Text t2)
    | Just (Tuple vs' t1) &lt;- stripTextEnd vs =
      Fragment (vs' &lt;&gt; [Text (t1 &lt;&gt; t2)])
  append (Text t1) (Fragment vs)
    | Just (Tuple t2 vs') &lt;- stripTextStart vs =
      Fragment ([Text (t1 &lt;&gt; t2)] &lt;&gt; vs')
  append (Fragment v1s) (Fragment v2s)
    | Just (Tuple v1s' t1) &lt;- stripTextEnd v1s
    , Just (Tuple t2 v2s') &lt;- stripTextStart v2s =
      Fragment (v1s' &lt;&gt; [Text (t1 &lt;&gt; t2)] &lt;&gt; v2s')

  -- Keep flattening, to keep it associative
  append v1 (Fragment v2s) = Fragment ([v1] &lt;&gt; v2s)
  append (Fragment v1s) v2 = Fragment (v1s &lt;&gt; [v2])

  -- Finally, if none of the above cases apply,
  -- we wrap it up in a two-element array:
  append v1 v2 = Fragment [v1, v2]

stripTextStart :: Array VDOM -&gt; Maybe (Tuple String (Array VDOM))
stripTextStart = Array.uncons &gt;=&gt; case _ of
  { head: Text t1, tail: vs } -&gt; Just (Tuple t1 vs)
  _ -&gt; Nothing

stripTextEnd :: Array VDOM -&gt; Maybe (Tuple (Array VDOM) String)
stripTextEnd = Array.unsnoc &gt;=&gt; case _ of
  { init: vs, last: Text t2 } -&gt; Just (Tuple vs t2)
  _ -&gt; Nothing</code></pre>
<div class="Note">
<p>With these additional cases, the empty text node <code class="haskell">Text ""</code> is <em>almost</em> an identity, but the empty fragment <code class="haskell">Fragment []</code> is still the identity of the monoid: <a href="https://proofwiki.org/wiki/Identity_is_Unique">you cannot have two identities in a monoid</a>. And I think thereʼs a specific reason why you want <code class="haskell">Fragment []</code> to be the identity, but I havenʼt actually worked through the details to fully justify it.</p>
</div>
</details>
<h2 id="join-with-separator-monoid">Join with separator monoid</h2>
<p class="dated">
2023/11/15
</p>
<p>I confess that this is also motivated by webdev: for the class attribute, which is a space-separated list of class names.</p>
<p>We do a similar trick: we detect the identity and handle it specially.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<pre class="purescript"><code>newtype ClassName = ClassName String

instance Monoid ClassName where
  mempty = ClassName ""

instance Semigroup ClassName where
  append (ClassName "") e = e
  append e (ClassName "") = e
  -- Join two non-empty class names with a space
  append (ClassName c1) (ClassName c2) =
    ClassName (c1 &lt;&gt; " " &lt;&gt; c2)</code></pre>
<p>Unfortunately, itʼs a bit of work to generalize this to any separator. Youʼd want to track the separator at the type level to ensure it is the same across the whole monoid. Without dependent types, you have to tie it to some typeclass, like some kind of singleton reflection.</p>
<p>For the case of strings in PureScript, we can use symbols (type-level strings):</p>
<pre class="purescript"><code>newtype JoinWith (s :: Symbol) = JoinedWith String

instance IsSymbol s =&gt; Monoid (JoinWith s) where
  mempty = JoinedWith ""

instance IsSymbol s =&gt; Semigroup (JoinWith s) where
  append (JoinedWith "") e = e
  append e (JoinedWith "") = e
  append (JoinedWith s1) (JoinedWith s2) =
    JoinedWith
      (s1 &lt;&gt; reflectSymbol (Proxy :: Proxy s) &lt;&gt; s2)</code></pre>
<p>You could also easily adapt this for any type that you can construct with strings, like a <a href="https://pursuit.purescript.org/packages/purescript-dodo-printer/2.2.1/docs/Dodo.Internal#t:Doc">pretty printer</a>. (You also need to be able to check whether it <a href="https://pursuit.purescript.org/packages/purescript-dodo-printer/2.2.1/docs/Dodo.Internal#v:isEmpty">is empty</a>, of course.)</p>
<p>Now you can do such fun stuff as:</p>
<pre class="purescript"><code>joinWithComma :: Array String -&gt; String
joinWithComma = unwrap &lt;&lt;&lt; foldMap
  (JoinedWith :: String -&gt; JoinWith ", " String)</code></pre>
<p>And the real benefit of making a proper monoid structure is that it is now compositional. You can just chuck it in a record and it does the right thing ^.^</p>
<h2 id="precedence-in-pretty-printers">Precedence in pretty printers</h2>
<p class="dated">
2024/05/01
</p>
<div class="centered">
<p><em>Originally posted at <a href="https://tech.lgbt/@monoidmusician/112368939004740994" class="uri">https://tech.lgbt/@monoidmusician/112368939004740994</a></em></p>
</div>
<p>This semiring is an amalgamation of a few concepts: a unification monoid, the <a href="https://pursuit.purescript.org/packages/purescript-maybe/6.0.0/docs/Data.Maybe.Last#t:Last"><code class="purescript">Last</code></a> monoid, and some other stuff.</p>
<p>My goal is to capture precedence during the pretty-printing phase of my printer–parser–pretty-printer framework. It really <em>really</em> needs to be compositional and to handle arbitrary structures, not just the usual binary operators.</p>
<p>The idea is that the applicative <code class="purescript">&lt;*&gt;</code> combinators of the parser will correspond to multiplication <code class="purescript">*</code> of precedence, and the alternative <code class="purescript">&lt;|&gt;</code> combinators of the parser will correspond to addition of precedence.</p>
<p>During printing, when the precedence combines in certain ways, it will automatically insert parentheses (or some other method of delineating precedence, obviously i am not going to hardcode it).</p>
<p>The</p>
<pre class="purescript"><code>Prec 1 + Prec 1 * Prec 2
  = Prec 1 + Prec 2
  = NoPrec (since 1 /= 2)

Prec 1 * (NoPrec + Prec 2)
  = ??? no good answer …</code></pre>
<hr>
<p>it is a similar problem as follow sets: what do you do with empty alternatives? … just not recursive (no need to peek inside nonterminals)</p>
<hr>
<p>well, this is algebra, so we can just invent an answer <code class="purescript">MTPrec</code> (“empty or [known] precedence”) and see if it still works out:</p>
<pre class="purescript"><code>NoPrec + Prec 2
  = MTPrec 2

Prec 1 * EmptyOrPrec 2
  = NoPrec (since 1 /= 2)</code></pre>
<p>I guess I also need a <code class="purescript">DiffPrec</code> …</p>
<p>hmm I wrote an impl, best to throw it into QuickCheck at this point, I think</p>
<hr>
<p>QuickCheck is happy! I will just have to consider tomorrow whether this actually buys me anything…</p>
<p>specifically I want it to help me delineate precedence for pretty printing&nbsp;… <em>and</em> parsing? idk yet</p>
<p>the specific idea is that it will explain why reduction rules can be assigned precedence in Happy (this is necessary for the implicit adjuxtaposition operator for function application), and how it defaults to that of the last token</p>
<hr>
<pre class="purescript"><code>data Prec v
  = NoPrec
  | AnyPrec
  | DiffPrec
  | Prec v
  | MTPrec v

instance semiringPrec :: Eq v =&gt; Semiring (Prec v) where
  zero = AnyPrec
  one = NoPrec

  add DiffPrec _ = DiffPrec
  add _ DiffPrec = DiffPrec
  add AnyPrec v = v
  add v AnyPrec = v
  add NoPrec (Prec v) = MTPrec v
  add (Prec v) NoPrec = MTPrec v
  add NoPrec (MTPrec v) = MTPrec v
  add (MTPrec v) NoPrec = MTPrec v
  add (Prec v1) (Prec v2)
    | v1 == v2 = Prec v1
    | otherwise = DiffPrec
  add (Prec v1) (MTPrec v2)
    | v1 == v2 = MTPrec v1
    | otherwise = DiffPrec
  add (MTPrec v1) (Prec v2)
    | v1 == v2 = MTPrec v1
    | otherwise = DiffPrec

  mul AnyPrec _ = AnyPrec
  mul _ AnyPrec = AnyPrec
  mul NoPrec v = v
  mul v NoPrec = v
  mul _ DiffPrec = DiffPrec
  mul DiffPrec (MTPrec _) = DiffPrec
  mul (Prec v1) (MTPrec v2)
    | v1 == v2 = Prec v2
    | otherwise = DiffPrec
  mul (MTPrec v1) (MTPrec v2)
    | v1 == v2 = MTPrec v1
    | otherwise = DiffPrec
  mul _ (Prec v) = Prec v</code></pre>
<hr>
<p>shout-out to quickcheck-laws</p>
<p><a href="https://github.com/purescript-contrib/purescript-quickcheck-laws/blob/v7.0.0/src/Test/QuickCheck/Laws/Data/Semiring.purs" class="uri">https://github.com/purescript-contrib/purescript-quickcheck-laws/blob/v7.0.0/src/Test/QuickCheck/Laws/Data/Semiring.purs</a></p>
<hr>
<p>I think the upshot is that parsing rules have a simple precedence behavior: just use the Last monoid for each rule, since the alternative rules are already in a list structure</p>
<p>pretty printing will require this new semiring, since it does not have alternatives in the same structure, it is just a function</p>
<p>so when you transition from “known precedence” to “unknown precedence”, is where it adds the opportunity to parenthesize</p>
<p>ughhh how does this interact with CST nowwww</p>
<hr>
<p>CST shouldnʼt need precedence, right, thatʼs kind of the point of it, that it just preserves parentheses that existed in the input</p>
<h2 id="top-down-traversals">Top-Down Traversals</h2>
<p class="dated">
2024/09/18
</p>
<p>Recently I faced a problem: how do I get more control out of a traversal in PureScript?</p>
<p>There are two problems here:</p>
<ol type="1">
<li>Collapsing a tree to a flat, one-dimensional monoid structure is too simplified</li>
<li>PureScript is strict, so short-circuiting is more complicated</li>
</ol>
<p>In particular, I want to do a single top-down traversal and estimate the complexity of evaluating an Erlang expression. The hardest part is the complexity of literals: a statically-allocated literal is trivial to evaluate, but all children of a literal must be literals. Additionally, we need to not count the complexity of the bodies of lambdas: they are just a single allocation too.</p>
<p>As a refresher on the kind of traversal I am talking about, I had the existing signature</p>
<pre class="purescript"><code>visit ::
  forall m.
    Monoid m =&gt;
  -- A callback to value a single node
  (ErlExpr -&gt; m) -&gt;
  -- The aggregate of the node and its children
  (ErlExpr -&gt; m)</code></pre>
<p>My first iteration was returning <code class="purescript">Tuple Boolean m</code>, but this suffered from being confusing (does <code class="purescript">true</code> mean to keep the childrenʼs result or skip it?), and it did not solve the first point.</p>
<p>Eventually I landed on this type:</p>
<pre class="purescript"><code>data Visit m
  -- Skip evaluating the children
  = ShortCircuit m
  -- Evaluate the children and append this value
  | Append m
  -- Customize the result of evaluating the children
  | Continue (m -&gt; m)</code></pre>
<p>Note that <code class="purescript">Append</code> is just for convenience, it is equivalent to <code class="purescript">Continue &lt;&lt;&lt; append</code> (where <a href="https://pursuit.purescript.org/packages/purescript-prelude/6.0.1/docs/Data.Semigroup#v:append"><code class="purescript">append :: m -&gt; m -&gt; m</code></a> is the monoid operation, also written <code class="purescript">(&lt;&gt;)</code>).</p>
<p><code class="purescript">ShortCircuit</code> also would not be necessary, if the monoid operation was lazy. It would be equivalent to <code class="purescript">Continue &lt;&lt;&lt; const</code>. But alas, PureScript is strict and its Prelude only includes strict append, and itʼs not really worth having a lazy append.</p>
<p>No matter, it is pretty simple to case on <code class="purescript">Visit</code>.</p>
<pre class="purescript"><code>-- | Traverse with the ability to short circuit
-- | and alter results of child traversals
visit' ::
  forall m.
    Monoid m =&gt;
  (ErlExpr -&gt; Visit m) -&gt;
  (ErlExpr -&gt; m)
visit' f = go
  where
  go e = case f e of
    -- Avoid computing `children e`
    ShortCircuit m -&gt; m
    -- Just append, like normal `visit`
    Append m -&gt; m &lt;&gt; children e
    -- Allow it to manipulate `children e`
    -- however it wants to based on `e`
    Continue mm -&gt; mm (children e)

  -- Recurse into the children
  children = case _ of
    -- ^ `case _ of` is an anonymous        --
    -- argument, equal to `\e -&gt; case e of` --
    Literal _ -&gt; mempty
    Var _ _ -&gt; mempty
    BinOp _ e1 e2 -&gt; go e1 &lt;&gt; go e2
    UnaryOp _ e1 -&gt; go e1
    BinaryAppend e1 e2 -&gt; go e1 &lt;&gt; go e2
    List es -&gt; foldMap go es
    ...</code></pre>
<p>This structure of <code class="purescript">Monoid m =&gt; m -&gt; m</code> is great for making the most out of the tree traversal: it allows you to delimit the children and operate on them as a group, which was not possible before.</p>
<p>Itʼs also related to the <a href="https://en.wikipedia.org/wiki/Endomorphism_ring">Endomorphism Semiring</a>, which is <a href="https://blog.veritates.love/Eudoxus.html">very cool</a>. One of the algebraic structures of all time.</p>
<p>Anyways, now we can do what I came here to do: estimate the runtime complexity of an Erlang expression.</p>
<p>We start by crafting a monoid <code class="purescript">Complexity</code> to keep track of the information about the cumulative complexity of an expression, including whether it is a group of literals. It is based on <code class="purescript">Additive Int</code> (the integers as a monoid under addition), with the twist of the Boolean distinction between <code class="purescript">Lit</code> and <code class="purescript">Complex</code> (preferring <code class="purescript">Complex</code> of course, which makes <code class="purescript">Lit 0</code> the identity).</p>
<p>Note that literals still have the <code class="purescript">Int</code> cost because multiple literals side-by-side have a cumulative cost (this is what is modeled in <code class="purescript">Semigroup Complexity</code>), which is canceled out in <code class="purescript">groupOfLiterals</code> when it forms part of a larger literal (only if all children are literals).</p>
<p>That is, <code class="erl">{ 3 =&gt; 4, 5 =&gt; [6,7,8] }</code> is a literal, but <code class="erl">{ x =&gt; fun f/1, y =&gt; 2 }</code> is not a literal (only the keys <code class="erl">x</code> and <code class="erl">y</code> and the value <code class="erl">2</code> is a literal there).</p>
<pre class="purescript"><code>data Complexity
  = Lit Int
  | Complex Int
instance semigroupComplexity :: Semigroup Complexity where
  append (Complex i) (Complex j) = Complex (i + j)
  append (Lit i) (Complex j) = Complex (i + j)
  append (Complex i) (Lit j) = Complex (i + j)
  append (Lit i) (Lit j) = Lit (i + j)
instance monoidComplexity :: Monoid Complexity where
  mempty = Lit 0

unComplexity :: Complexity -&gt; Int
unComplexity (Lit _) = 1
unComplexity (Complex i) = i

-- | Estimate the runtime complexity of an expression.
-- | Used for determining when to memoize a function.
estimatedComplexity :: ErlExpr -&gt; Int
estimatedComplexity = unComplexity &lt;&lt;&lt; visit' case _ of
  -- Do not recurse into closures
  Fun _ _ -&gt; ShortCircuit (Complex 1)
  -- Yeah, `fun f/1` is an allocation ...
  FunName _ _ _ -&gt; ShortCircuit (Complex 1)
  -- A curried call costs one
  FunCall Nothing (FunCall _ _ _) _ -&gt; Append (Complex 1)
  -- Base calls cost more since they might do more work
  -- (Note: atoms count during recursion, so unqualitifed &gt;= 3,
  -- and qualified calls &gt;= 4, plus arguments of course)
  FunCall _ _ _ -&gt; Append (Complex 2)
  -- Literals are cheap
  Literal _ -&gt; ShortCircuit (Lit 1)
  -- Literal constructors are cheap if
  -- all of their children are literals
  List _ -&gt; groupOfLiterals
  Tupled _ -&gt; groupOfLiterals
  Map _ -&gt; groupOfLiterals
  Record _ -&gt; groupOfLiterals
  -- Everything else costs 1 plus its children
  _ -&gt; Append (Complex 1)
  where
  groupOfLiterals :: Visit Complexity
  groupOfLiterals = Continue case _ of
    Lit _ -&gt; Lit 1
    Complex i -&gt; Complex (i + 1)</code></pre>
<ul>
<li><a href="https://github.com/id3as/purescript-backend-erl/blob/703361c61b5848de1b8e4cb894cc8f2307618d4e/src/PureScript/Backend/Erl/Syntax.purs#L253-L261" class="uri">https://github.com/id3as/purescript-backend-erl/blob/703361c61b5848de1b8e4cb894cc8f2307618d4e/src/PureScript/Backend/Erl/Syntax.purs#L253-L261</a></li>
<li><a href="https://github.com/id3as/purescript-backend-erl/blob/703361c61b5848de1b8e4cb894cc8f2307618d4e/src/PureScript/Backend/Erl/Syntax.purs#L310-L352" class="uri">https://github.com/id3as/purescript-backend-erl/blob/703361c61b5848de1b8e4cb894cc8f2307618d4e/src/PureScript/Backend/Erl/Syntax.purs#L310-L352</a></li>
</ul>
<h2 id="your-requests-here">Your Requests Here</h2>
<p>know any other cute liʼl monoids I should include?</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Pedagogically I probably should have started with this example, but I donʼt really feel like re-working this post right now.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Infodumping About Selective Applicative Functors</title>
<pubDate>Wed, 10 Apr 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/infodump_selective_applicatives.html</guid>
<description><![CDATA[<div class="centered">
<p><em>Originally posted at <a href="https://tech.lgbt/@monoidmusician/112250458187094582" class="uri">https://tech.lgbt/@monoidmusician/112250458187094582</a></em></p>
</div>
<p>tonightʼs infodump on selective applicative functors:</p>
<p>we know about monads, which have dynamic control flow: based on the result of a previous computation, you can invent a whole new computation to run in the chain</p>
<pre class="purescript"><code>(&gt;&gt;=) :: m x -&gt; (x -&gt; m y) -&gt; m y</code></pre>
<p>this is the most flexible you can be, and it necessitates a linear order of evaluation</p>
<p>applicatives have static control flow: the set of computations to run is fixed up front, and then you get to combine their results at the end</p>
<p>applicatives can evaluate however they like: sequentially, in parallel … they can even evaluate right-to-left (like monoids, they can be flipped via <code>^op</code>)</p>
<pre class="purescript"><code>(&lt;**&gt;) :: m x -&gt; m (x -&gt; y) -&gt; m y</code></pre>
<p>alternatives model nondeterminism: you donʼt write into the program what branch to choose, but however you interpret the functor has to decide</p>
<p>this is useful for parsers: the parser will return results from branches that match, discarding branches that fail</p>
<pre class="purescript"><code>(&lt;|&gt;) :: m x -&gt; m x -&gt; m x</code></pre>
<hr>
<p>selective applicative functors lie in between monads and applicatives in terms of their power, and show similarities with alternatives too</p>
<p>unfortunately, selective applicatives are tricky to formulate correctly, but the basic flavor is given by <code class="purescript">select</code> and <code class="purescript">branch</code>:</p>
<pre class="purescript"><code>select :: m (Either u v) -&gt; m (u -&gt; v) -&gt; m v
branch :: m (Either x y) -&gt; m (x -&gt; z) -&gt; m (y -&gt; z) -&gt; m z</code></pre>
<p>one way to think of it from a high level is that selective applicative functors let you have <em>determined</em> choice:</p>
<p>the computation itself gets to determine what branch to take, by whether it returns a <code class="purescript">Left</code> or a <code class="purescript">Right</code></p>
<p>it is no longer nondeterministic like <code class="purescript">&lt;|&gt;</code></p>
<p>but it also isnʼt completely dynamic like monads: you have to declare all the branches up front, make some dynamic choices along the way, and use all the information to come up with a final result</p>
<hr>
<p>for several months Iʼve been thinking about selective applicative functors in the context of parsers specifically</p>
<p>I realized that thereʼs a reason that <code class="purescript">&lt;|&gt;</code> and <code class="purescript">branch</code> feel similar in terms of both being branching structures of control flow, and the implications that has for scoping and syntax and such:</p>
<p>selective parsers are just parsers with dynamic failure: <code class="purescript">try :: m x -&gt; (x -&gt; Maybe y) -&gt; m y</code>, where you get to inspect a result but choose to make the parser fail anyways</p>
<p>parsers with (finite!) case matching built in, and just the intuitive notion of scope that that brings</p>
<p>I posted some notes about why this is on cohost:</p>
<p><a href="https://cohost.org/monoidmusician/post/2588944-more-more-more-seman" class="uri">https://cohost.org/monoidmusician/post/2588944-more-more-more-seman</a></p>
<p>and my notes on selective functors more generally:</p>
<p><a href="https://cohost.org/monoidmusician/tagged/selective%20applicative%20functor" class="uri">https://cohost.org/monoidmusician/tagged/selective%20applicative%20functor</a></p>
<p>and Iʼve been developing a framework for parser combinators that will hopefully execute selective applicative structures with <span data-t="" data-widget="">LR(1)</span> or <span data-t="" data-widget="">GLR</span> tables</p>
<p>(uhhh I havenʼt figured out if it corresponds to a known class of grammars yet)</p>
<hr>
<p>so why is it so tricky to formulate?</p>
<pre class="purescript"><code>select :: m (Either u v) -&gt; m (u -&gt; v) -&gt; m v
branch :: m (Either x y) -&gt; m (x -&gt; z) -&gt; m (y -&gt; z) -&gt; m z</code></pre>
<p><code class="purescript">select</code> is weird: <code class="purescript">Either</code> is a tensor, but <code class="purescript">-&gt;</code> sure as heck isnʼt.</p>
<p>an alternative formulation goes like</p>
<pre class="purescript"><code>m u -&gt; m (Either v (u -&gt; v)) -&gt; m v</code></pre>
<p>where you have a “maybe constant function” (<code class="purescript">Either v (u -&gt; v)</code>), but this still doesnʼt fit into category theory nicely at all</p>
<p><code class="purescript">branch</code> is even weirder: it looks like it has the right shape, but it doesnʼt compose!!</p>
<p>the 2-ary <code class="purescript">branch</code> does not easily give rise to 3-ary <code class="purescript">branch</code>, you basically have to reimplement <code class="purescript">select</code> in terms of <code class="purescript">branch</code> and then apply it multiple times, it is so annoying</p>
<p>my solution and notes on why this is is here:</p>
<p><a href="https://github.com/MonoidMusician/blog/blob/main/PureScript/src/Parser/Selective.purs" class="uri">https://github.com/MonoidMusician/blog/blob/main/PureScript/src/Parser/Selective.purs</a></p>
<p>basically you have to treat it like the control flow it is: break out the profunctors/arrows, specifically have a profunctor for “finite case branching on some type”, and then use that as your building block for a N-ary <code class="purescript">branch</code></p>
<hr>
<p>so the formulation I like says, “follow a computation with a finite case tree on its result, whose result is the result of the whole computation”:</p>
<pre class="purescript"><code>caseTreeOn :: forall i r. f i -&gt; CaseTree i f r -&gt; f r</code></pre>
<p>(<code class="purescript">CaseTree</code> is tricky to define, with existential quantification … I think thatʼs part of why nobody has stumbled across it to my knowledge)</p>
<p>these are strong functors, so you can pass down any information you learned in the first computation into the branches of the second … basically how you would expect variable scoping to work (in non-linear type theories) :)</p>
<p>(yes you can shut up about how monads need to be strong to be applicative functors: everything is strong here.)</p>
<hr>
<p>this is a strengthening of the usual definition of selective functors (which just use <code class="purescript">select</code>): it encodes <em>exclusive determined choice</em></p>
<p>now, itʼs a bit tricky to answer what this gives you, what any of this gives you,</p>
<p>but exclusive determined choice is important for parsers, at least: for the purposes of static analysis, you would like to know that two branches are exclusive, to know that ambiguities between them will always be resolved</p>
<p>you simply do not get this knowledge with <code class="purescript">select</code>: if you look at how to encode <code class="purescript">branch</code> via <code class="purescript">select</code>, youʼll realize that you have to inspect the control flow of (potentially) arbitrary functions to make that determination, which is absolutely forbidden</p>
<p>(basically it works by saying that each branch “could” be run, and shuffling around data to ensure that the right branch gets chosen or skipped each time&nbsp;… it is really annoying and inelegant)</p>
<hr>
<p>now would be a great time to clarify this:</p>
<p><strong>nothing in the formalism says that branches have to be skipped, and this is a feature not a bug</strong></p>
<p>I will repeat</p>
<p><strong>branches can be executed even if they were not chosen, and this is on purpose</strong></p>
<p>in the case of <code class="purescript">select</code>, it means that <code class="purescript">select</code> can be implemented in terms of <code class="purescript">&lt;*&gt;</code> which always runs both branches! (and just discard the result of the one that was not necessary)</p>
<p>I will get more into this when I ask “what does this formalism get us, anyway?”</p>
<p>but for now, observe that the <em>beauty</em> (yes, beauty) of selective applicative functors is that they are more plentiful:</p>
<p>whereas types mostly have one monad instance, and maybe a couple different applicative instances, they will have a proliferation of selective instances:</p>
<p>lists have their usual monad structure which gives an applicative structure (Cartesian product), but they also have a ziplist structure, and then their flipped/<code>^op</code> versions</p>
<p>all these give different selective structures, and more!</p>
<hr>
<p>another example: the <code class="purescript">Const</code> functor has no monad structure, but it has a standard applicative structure given by monoid concatenation (and its opposite order, which we do not care about)</p>
<p>but as a selective functor we can work some magic: <code class="purescript">Under</code> with only capture the effect executed unconditionally (<span data-t="" data-widget="">i.e.</span> the first arguments of <code class="purescript">select</code>, ignoring the second arguments) and <code class="purescript">Over</code> will take it all, regardless of if it would be ignored during runtime (this is the selective structure given by the applicative)</p>
<p>this is in The Paper, read more there (section 2.2): <a href="https://dl.acm.org/doi/10.1145/3341694" class="uri">https://dl.acm.org/doi/10.1145/3341694</a></p>
<p>but it starts to answer our question: why is this useful?</p>
<p>itʼs useful because you can approximate the effects you are about to run, in advance: they all exist statically, the control flow <em>can</em> be dynamic, but itʼs tailor made so you can <em>ignore</em> the control flow and know everything that might pop up</p>
<hr>
<p>itʼs tempting to impose a law that branches of control flow that are never taken are always ignored</p>
<p>but there is a huge problem with that: to obey the law, an implementation either needs to (1) inspect arbitrary functions to determine if the next computation could possibly run, or (2) actually execute the one or many possibilities and keep track of the results&nbsp;… <span data-t="" data-widget="">i.e.</span> run/simulate the computation.</p>
<p>both of those are non-starters for static analysis, it simply ruins the abstraction we are going for</p>
<p>you might ask, “why not formulate static analysis as a separate abstraction, and leave selective functors for the well-behaved ones?”,</p>
<p>The Paper tells you why!!</p>
<p>through the example of Haxl (a library mostly meant for DB queries) shows that you want it to live in a single abstraction so that you can have <em>static analysis interleaved with dynamic execution</em></p>
<p>how cool is that??</p>
<p>basically batches DB queries to get all required data and maybe conditionally required data, Iʼm fuzzy on the details still</p>
<hr>
<p>so yeah, if you let it all live under one abstraction, you get nice things</p>
<p>like, you can take the product of two selective applicative functors,</p>
<p>so you can just tuple up your over-approximation, your under-approximation, and your actual execution context into one functor, simply because they all worked on their own&nbsp;…</p>
<p>… or you can find ways to interleave them like Haxl did</p>
<p>the main problem with Haxl, which is not its fault but rather Haskellʼs, is that Haskell typeclasses require that instances agree with each other:</p>
<p>if a type implements Monad, it needs to implement Applicative in a closely compatible way</p>
<p>and the same choice was made with Selective: must agree with Monad instance if it exists</p>
<p>I think this is mostly good design, itʼs important that things behave predictably</p>
<p>itʼs just so tempting to cut corners and implement more interesting instances for Applicative and Selective, mostly because no language nor library features make dealing with it easier</p>
<hr>
<p>Haxl in particular got in hot water for having an Applicative instance that didnʼt agree with its Monad instance, since the Applicative wants to do static analysis and batch everything, while Monad simply does not allow batching</p>
<p>we should support this somehow! thereʼs a really interesting story to be told there! we do want to prefer static analysis when possible!</p>
<p>itʼs just hard to express currently (it requires making newtypes for each behavior you think of), and I really think we need to make this easier at the language+library level (itʼs something that I want to address in tmTTmt!)</p>
<p>there is <a href="https://pursuit.purescript.org/packages/purescript-parallel/7.0.0/docs/Control.Parallel.Class"><code class="purescript">Parallel</code></a> in PureScript, which gives <code class="purescript">parTraverse</code> and other goodies, but idk Iʼve never enjoyed making new types for it……</p>
<hr>
<p>okay so as the final word in what selective applicative functors get us in terms of static analysis:</p>
<p>my case tree abstraction makes it more clear</p>
<p>the whole deal with regular applicative functors is that their static analysis is just a monoid, given by the <code class="purescript">Const</code> instance</p>
<p>in fact, I would argue thatʼs all that static analysis is: an interpretation of the functor <code class="purescript">f a -&gt; c</code> that is lawful as a morphism of the appropriate structure of type <code class="purescript">f a -&gt; Const c a</code>.</p>
<p>with <code class="purescript">caseTreeOn</code>, we donʼt just have a monoid anymore: we still combine effects sequentially with a monoid, but we combine the alternatives with a (potentially differently behaved) semigroup</p>
<p>(we can ignore empty case trees: 0-ary branch just evaluates its first argument)</p>
<p>thereʼs probably some laws you want to impose between the monoid and semigroup</p>
<p>in fact, having a lattice or semilattice <a href="https://blog.veritates.love/semilattice_semiring.html">is particularly nice</a></p>
<p>and semilattices crawl all over static analysis, you wouldnʼt believe it</p>
<p>(well, maybe you would ^^)</p>
<hr>
<p>and as a final message that should have been a first message for intuition:</p>
<p>what type of <code class="purescript">do</code> syntax would we give to selective applicatives?</p>
<p>for monads we have regular <code class="purescript">do</code> syntax:</p>
<pre class="purescript"><code>do
  x &lt;- f
  y &lt;- g x
  case x + y of
    42 -&gt; return True
    r -&gt; loop r</code></pre>
<p>for applicatives we have much stricter <code class="purescript">ado</code> notation, where each binding only is visible in the final <code class="purescript">in</code> clause (return statement):</p>
<pre class="purescript"><code>ado
  x1 &lt;- c1
  x2 &lt;- c2
  in x1 + x2</code></pre>
<p><code class="purescript">selective</code> will allow case branches, where the bound variables are visible in <code class="purescript">case</code> and <code class="purescript">in</code> but still not the right sides of binds:</p>
<pre class="purescript"><code>ado
  x1 &lt;- c1
  x2 &lt;- c2
  case x1 + x2 of
    42 -&gt; pure True
    r -&gt; ado
      -- x1, x2, and r are still not in scope
      x3 &lt;- c3
      -- until `in`
      in x1 + x2 + x3 == 42</code></pre>
<p>unfortunately the desugaring will be a lot more complicated: the compiler essentially needs to pick a strategy for pattern matching and expose it during desugaring</p>
<p>thereʼs also details in branching in the middle vs at the end, yeah&nbsp;…</p>]]></description>
</item>
<item>
<title>Pickling Tasty Data</title>
<pubDate>Sun, 28 Jan 2024 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/pickling.html</guid>
<description><![CDATA[<p>I want to talk about data today. In particular, I want to talk about runtime representations of data, <strong>real</strong> data – data that can be mutable and referentially opaque at runtime – and demystify what they actually are in terms of more familiar notions of data.</p>
<p>You shouldnʼt just throw up your hands once you have cyclic references! Itʼs possible and worthwhile to design tools to work with the raw graph of runtime data, no matter its shape.</p>
<p>With the proper metaprogramming hooks, you could save and restore a whole runtime environment <em>from the inside</em>, which is pretty amazing to think about.</p>
<p>(Well, okay, you might give up at things like functions, if there isnʼt enough metaprogramming, or running sockets, for example – thatʼs okay!)</p>
<p>The main thing we will work up to (and go beyond) is Pythonʼs <a href="https://docs.python.org/3/library/pickle.html"><code class="python">pickle</code> module</a>, including my own implementation of it for the <a href="https://wiki.flightgear.org/Nasal_scripting_language">Nasal scripting language</a> (which I believe is cleaner in some respects, although obviously less industrial).</p>
<h2 id="background">Background</h2>
<p>This post has spent a long time marinating in my mind, so Iʼm happy to finally get it on the page!</p>
<p>Iʼve identified some basic aspects of data:</p>
<ol>
<li>Pure (immutable) data
<ul>
<li>Either acyclic&nbsp;…</li>
<li>… or allowed to be cyclic</li>
</ul></li>
<li>Mutable data (say, in-memory)
<ul>
<li>Youʼre basically forced to allow cyclic references!<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
<li>Sharing matters!</li>
</ul></li>
<li>Data defined in reference to external things (like file or socket handles)
<ul>
<li>External is relative – as it should be!</li>
<li>Your need to think about capturing intent
<ul>
<li><span data-t="" data-widget="">e.g.</span> file paths are probably your best indicator of intent – but if it was a temporary file, you could probably create a new temporary file instead! but oh now what if a different string is storing the path of the file, now you donʼt know how those pieces of data relate anymore and cannot update that string&nbsp;…</li>
</ul></li>
</ul></li>
<li>Functions? <em>Are</em> functions data?? (Iʼm including closures and procedures and routines and all that stuff in my definition of functions, btw.)</li>
<li>Quotiented data (Agda, Lean, Rocq)
<ul>
<li>see <a href="https://blog.veritates.love/adt_lies_for_truth.html">Subtypes/Quotients: Lies Told in Defense of the Truth</a> (<span data-t="" data-widget="">WIP</span>)</li>
</ul></li>
</ol>
<p>It will be important to think about what notions of equality are useful and adequate for these kinds of data!</p>
<p>We will talk about runtimes, including what garbage collectors do. Garbage collection is pretty special, since it gets into all the nitty gritty implementation details of a runtime: it essentially pins down the data model of most languages that have garbage collection.</p>
<p>It is also important to talk about what capabilities the language provides for working with and thus distinguishing data. If the difference cannot be observed, it does not exist! (And we may be “morally” justified in ignoring it anyways.)</p>
<h3 id="serialization-deserialization">Serialization, deserialization</h3>
<p>Serializing in its basic form – for pure data – means writing it out to a string such that it can be recovered from that string. (Bitstring, bytestring, Unicode string, even a bignum – the exact details do not matter. It also does not matter if it is a well packed encoding or a sparse encoding with lots of invalid strings that do not deserialize.)</p>
<p>Pickling is more general: it means serializing non-pure data by taking a snapshot of mutable data, preserving referential identity in the process (this is hard!), and doing your best with external references, and maybe giving up on functions.</p>
<p>Part of my argument is that serializing and pickling is very tied up in what data means!</p>
<p>Like, What is the essence of data? I hope it is something you can grasp fully, explain fully, and write out to a file and fully reconstruct in a new runtime context. (Mumble mumble: decidable equality, computation, countability.)</p>
<h3 id="equivalent-vs-equal">Equivalent vs equal</h3>
<p>I think I have definitions of equal and equivalent that are useful.</p>
<p>Equality in the classical sense<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> is going to be too strict, I argue, for the notion of data I want to consider. First of all, it is hard to compare values across runtimes, which is silly! Data does not only exist for an instant in time! And two mutable objects can be <em>interchangeable</em> even if they are not <em>identical</em> references.</p>
<p>This discrepancy happens as soon as you have mutable references, which you could tell apart if you have both to compare, but otherwise would act similar.</p>
<div class="Key_Idea">
<p>So I will use “equal” to mean “values that live within the same run of the runtime and will definitely act the same, thus equal in all ways the language could distinguish<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>”.</p>
<p>And I will use “equivalent” to mean “values that, if they exist in the same run of the runtime, would cause no difference if all references to them were swapped and then their children were shallowly swapped; otherwise, values that would act as similar as possible across different runs of the runtime”.</p>
</div>
<div class="Example">
<p>We definitely need to walk through an example of what “equivalent” means to unpack my definition. Hereʼs one in JavaScript, although the particulars of JavaScript do not matter:</p>
<pre class="javascript"><code>// Set up some data
let shared = [];
let v0 = { 0: shared, 1: [], 2: 2 };
v0[3] = v0;
let v1 = { 0: shared, 1: [], 2: 2 };
v1[3] = v1;
shared.push(v0, v1);

// I hope you agree that this characterizes
// the state of the data, most or less
for (let v of [v0, v1]) {
  // shared reference
  assert(v[0] === shared);
  // equivalent empty arrays,
  // though not equal
  assert(v[1].length === 0);
  // index 2 is 2
  assert(v[2] === 2);
  // self reference
  assert(v[3] === v);
}
// and they are referenced by shared in order
assert(shared[0] === v0);
assert(shared[1] === v1);

// they are not equal:
assert(v0 !== v1);

// but we can swap them, ...
[v0, v1] = [v1, v0];
// ... all references to them, ...
[v0[3], v1[3]] = [v1[3], v0[3]]; // yes, self references count
[shared[0], shared[1]] = [shared[1], shared[0]];
// ... and the immediate references they hold,
// since they have the same shallow structure
[v0[0], v1[0]] = [v1[0], v0[0]];
[v0[1], v1[1]] = [v1[1], v0[1]];
[v0[2], v1[2]] = [v1[2], v0[2]];
[v0[3], v1[3]] = [v1[3], v0[3]];
// this last one fixes up their self references again!

// Now we have the same observable state of the world!
for (let v of [v0, v1]) {
  // shared reference
  assert(v[0] === shared);
  // equivalent empty arrays,
  // though not equal
  assert(v[1].length === 0);
  // index 2 is 2
  assert(v[2] === 2);
  // self reference
  assert(v[3] === v);
}
// and they are still referenced by shared, in the
// order corresponding to the same variable names
assert(shared[0] === v0);
assert(shared[1] === v1);

// so we conclude that `v0` and `v1` are equivalent!</code></pre>
</div>
<div class="Note">
<p>Note that “equal” and “equivalent” are, strictly speaking, external notions. However, “equal” is often testable internally, such as by <code class="javascript">===</code>. (Except for the case of <code class="javascript">NaN</code> – you technically have to use <code class="javascript">a === b || (a !== a &amp;&amp; b !== b)</code> to detect <code class="javascript">NaN ==== NaN</code>, and I believe that different <code class="javascript">NaN</code>s are indistinguishable.)</p>
<p>“Equivalent” is much harder to test: for functions it will be impossible, but even for data made out of simple JSON-like structures it takes a fair amount of bookkeeping and some trickery to truly decide it.</p>
</div>
<p>In Dhall, equal and equivalent happen to be the same!<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Unfortunately this is more a reflection of the rather stagnant notion of data in Dhall – no mutability, no references, no cyclic structures.</p>
<p>As soon as you have mutable references, equality and equivalence will not be the same.</p>
<p>(This is because you can always<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> use test mutations to tell when two references are identical or not, so you cannot just outlaw referential equality and hope that they become indiscernable.)</p>
<p>And practically speaking, there are always wrinkles.</p>
<div class="Details" data-box-name="Rambling">
<p>Maybe there are bignums who can be observed to have different encoding by esoteric functions, but both encode the same number – you would be justified in wanting to consider them equal. (Especially if this is a distinction that can be observed by those esoteric functions but not reflected by a pickling function, for example. That is, if you could know that one number has an overlong encoding by virtue of being observably <em>different</em> from the other number, but not know which number is overlong, or, indeed, how overlong it is. Well, I suppose pickling would mean you have a canonical, short form, so it would just be a question of not knowing how overlong it is – maybe even being able to reconstruct an overlong form without trying a bunch of weird math operations to force decanonicalization, which would potentially get undecidable.)</p>
</div>
<h2 id="by-concept">By Concept</h2>
<p>Letʼs talk about concepts of data that exist across specific languages and runtimes!</p>
<h3 id="strings">Strings</h3>
<p>As a warm-up to thinking about references and pointers: Letʼs observe that immutable strings are treated specially by a lot of runtimes!</p>
<p>V8 has a lot of different representations of strings, and it is free to change representation between them, <span data-t="" data-widget="">e.g.</span> while garbage collecting. It is free to make these changes since they arenʼt observable from JavaScript (outside of performance characteristics).</p>
<p>Erlang likewise has immutable binaries (bytestrings) which serve similar purposes although they only support fast slicing (no fast concatenation). To get fast concatenation, users are expected to build up nested lists and flatten it out into one binary at the end of all the concatenation operations. (Luckily it is rare to want to index back into a binary as your are building it up, so this is acceptable for most use-cases.)</p>
<p>The thing that the Erlang garbage collector is specifically allowed to do is to delete old binaries whose contents are only partially referenced. Then it has the task of fixing up the references to those slices to refer to the new binaries with adjusted indices. This is definitely mutating data at some level (<span data-t="" data-widget="">e.g.</span> the level of raw memory), but it is not visible from Erlang at all.</p>
<p>Anyways, this is just a nicer example of stuff the runtime can do behind the scenes that has a very precise semantic description. It happens “behind the scenes” because changes occur in memory that do not effect equality, as seen from the language. As we start to think about references and managed pointers and external references and functions, it gets more complicated!</p>
<p>It is also a good warning to be careful about what “immutable” means: since every runtime uses mutation at some level, we only care about immutability as viewed from the language itself.</p>
<h3 id="mutability-or-purity">Mutability or purity</h3>
<p>Mutability should be one of the first things you think of when you think about data, especially if you have had some exposure to ideas from Functional Programming (FP).</p>
<p>The really nice thing about pure languages like Haskell and PureScript is that they separate out <a href="https://hackage.haskell.org/package/base-4.19.0.0/docs/Data-IORef.html#t:IORef">mutable</a> <a href="https://pursuit.purescript.org/packages/purescript-refs/6.0.0/docs/Effect.Ref#t:Ref">references</a> from pure data, and dispense with mutable variables altogether. It affords us a much nicer toolbox for expressing these concepts, in theory and in code.</p>
<h4 id="referential-identity-vs-referential-transparency">Referential identity vs referential transparency</h4>
<p>One way to say it is that pure data is characterized by its serialization. If it makes no reasonable difference whether you keep using the original value versus the value after it has been serialized and deserialized, then that is pure data. (This is a reformulation of referential transparency.)</p>
<p>Mutable data cares about its referential <strong>identity</strong>, on the other hand. (Note that “reference” most often means something like “pointer”, but it doesnʼt have to be restricted to that.)</p>
<h4 id="sharing-references">Sharing references</h4>
<p>The thing about pure data is that it essentially doesnʼt really care if it is a tree or a DAG. I mean, it matters in terms of efficiency and storage space! (Though this is rarely exposed at a useful level.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>) But the results of an algorithm wonʼt be changed just by sharing more or less internal structure among the immutable data.</p>
<p>Mutable data pretty obviously cares about sharing.</p>
<h3 id="functions">Functions</h3>
<p>Functions are tough. When viewed from above (mathematically) and below (most runtime implementations), they cannot be sensibly serialized.</p>
<p>One thing that is always true<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> is that you <strong>cannot</strong> expect to know when two functions are equivalent. They may happen to be equivalent in a obvious way, but if they arenʼt, you cannot necessarily find out that they actually have distinct behavior. (In other words: equivalence is semidecidable [reference needed].)</p>
<p>If you have the original syntax defining the functions, you <em>do</em> have a snowballʼs chance in hell of deciding that two functions are equivalent, by doing some procedures to normalize the syntactic definitions of the functions. (One difficulty is that you will also have to keep track of closures, including captured variables and open variables.)</p>
<p>But once the syntax is forgotten (<span data-t="" data-widget="">viz.</span> at runtime), the best you can do is a pointer comparison, which is a very poor decider of equivalence.</p>
<p>The funny thing is that, although all functions start out as syntax, syntactic normalization is very rare for languages.</p>
<p>Only a few term-based languages like Dhall will always keep functions as syntax<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, and only theorem provers like Agda/Lean/Rocq will keep the function syntax around for their core operation (whereas code extraction and runtime is almost entirely a separate issue).</p>
<p>(Aside: In theory you could defunctionalize a whole closed-system program right? At least for pure data? Maybe for mutable too?)</p>
<p>However, in languages like Agda, each function definition is considered distinct, so it might as well be a pointer check. (This is true for almost all theorem prover languages, certainly for recursively-defined functions – Dhall just avoids the issue by not having recursive functions!)</p>
<h2 id="by-language">By Language</h2>
<p>To really talk about data, we have to talk about specific runtimes. Weʼll work our way up from simplest to more thorny.</p>
<h3 id="fantasy">Fantasy</h3>
<p>Languages that nobody actually runs. Theyʼre just too academic or something. (Joking.)</p>
<h4 id="json">JSON</h4>
<p>JSON is a pretty great place to start.</p>
<p>JSON is pure, immutable data. It is acyclic and unshared. If you want to represent sharing, you need to represent it at a different level! By encoding some notion of identities and references, that is.</p>
<p>Many other things (like binary data/bitstrings) are mathematically equivalent to JSON in this regard. They are “just” pure data, in which you can encode any other pure data, with more or less help from existing structure like arrays and objects.</p>
<p>There are some wrinkles, like the fact that numeric precision is not specified, and the order of keys may matter to some runtimes and not others (okay, practically all runtimes <a href="https://stackoverflow.com/a/5525820">mostly</a> preserve order by now).</p>
<p>Note that JSON is often deserialized to <em>mutable</em> data. This means that <em>mutable</em> data may not roundtrip through JSON: shared values will be unshared. But Iʼm getting ahead of myself.</p>
<h4 id="dhall"><a href="https://dhall-lang.org/">Dhall</a></h4>
<p>From an abstract perspective, Dhall is pretty much like JSON, with a couple key differences:</p>
<ul>
<li>The data is strictly typed.</li>
<li>You can serialize functions!</li>
</ul>
<p>Dhall comes with a good notion of equality – judgmental equality – which applies normalization to open terms (expressions with free variables – in particular, functions). By applying algebraic reasoning, judgmental equality can sometimes show that two functions are equal, but not always!</p>
<h4 id="agda"><a href="https://agda.readthedocs.io/en/latest/">Agda</a></h4>
<p>(I use this mostly as a catch-all for theorem provers.)</p>
<p>Agda is kind of like Dhall, but its emphasis is different, and it has more features. As mentioned somewhere here, recursive functions mean that it gives up even earlier on detecting equality of functions. The other important new feature is quotients.</p>
<p>Quotients are interesting: they are – at some level – represented by the same (runtime) data as everything else, but some of the underlying data has to be treated as equal by <em>everything</em> (in particular, by equality, and thus by the rest of the theory, since everything has to preserve equality).</p>
<p>Specifically, Higher Inductive Types and Observational Type Theory are interesting topics here, but way too deep to get into at the moment (and well covered by others – not something I feel much need to opine on in this context).</p>
<h3 id="real-world">Real World</h3>
<p>Okay maybe some people actually run these languages and interact with their runtimes.</p>
<h4 id="erlangelixirbeam">Erlang/Elixir/BEAM</h4>
<p>Erlang is pretty interesting, for an untyped language. Data is fundamentally immutable<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> and acyclic and this has influenced many aspects of its design.</p>
<p>This enables somewhat exotic features like non-linear pattern matching and deep equality, which are unheard of in untyped, mutable languages. (These are the same feature, actually. Non-linear pattern matching is implemented via deep equality.)</p>
<p>In fact, Erlang specifies a very specific serialization format for data, for seamlessly communicating across distributed systems.</p>
<h5 id="what-are-processes">What are processes?</h5>
<p>It is not the case that Erlang processes are data. That is, processes themselves are not just a kind of data. Erlang does not claim to let you save the full state of a process off to disk and restart it from the saved data. That would be a little silly – what would happen to all the other processes it was bound to? No, processes are part of a dynamic runtime system.</p>
<p>However, a <em>reference</em> to a process <em>is</em> “just” data still, and can be compared for equality like any other data, and it can be serialized.</p>
<p>(The same for BEAM functions and closures, btw. Their references are opaque in some sense, but still just data.)</p>
<p>And interestingly, the dynamic, asynchronous nature of processes means that they <em>must</em> expose mutation.</p>
<p>Indeed, one way to implement a mutable reference is to spin up a process that holds the “current” value<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> and returns it when queried and purely updates it in its state. That is, its state is immutable, but external callers can see fresh data whenever they query the process.</p>
<h4 id="haskell">Haskell</h4>
<p>Haskell is actually one of the most complex ones here, since there are many levels you can talk about data at.</p>
<p>One the one hand, you can talk about pure data all day long. You can pretend that it operates like Agda or Dhall – totally pure! (Except you cannot compare functions for equality [except you can].)</p>
<p>You can even add mutable references (again with equality [again with the exception]). Itʼs actually really beneficial to have this separation between mutable references and immutable data that they contain, but I didnʼt get into it here.</p>
<p>Mutable references form a possibly cyclic directed graph, just like the imperative languages we will be talking about. But Haskell can also form cyclic data references via laziness: <a href="https://wiki.haskell.org/Tying_the_Knot">“tying the knot”</a>, as it is called.</p>
<p>However, Haskell is a bit weird in that you can also peek inside the machine, and compare pointers and do other “naughty” stuff. This can be used to short-circuit deep equality comparisons via referential equality, memoize functions on uncomparable types, and other <a href="https://acatalepsie.fr/posts/overloading-lambda">legitimate</a> <a href="https://dl.acm.org/doi/pdf/10.1145/3409002">uses</a><a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. Except it isnʼt so naughty (if you do it right), it is just a different layer of abstraction.</p>
<p>In fact, if you drill down, Haskell has some kind of data model that its runtime operates on. This will tell you when it is okay to use <code class="haskell">unsafeCoerce</code>, for example. Itʼs maybe worth talking about the way Haskell evaluates, what its thunks represent, how mutable and immutable data work, <a href="https://hackage.haskell.org/package/stm-2.5.3.0/docs/Control-Concurrent-STM.html">STM</a>, FFI,— but it just goes on for ages.</p>
<p>I think itʼs really worth thinking about this deeply, taking seriously the kinds of data that Haskell uses at runtime, and how references to them interact, how the garbage collector makes sense of it all.</p>
<p>But as we will see, an awful lot of runtimes seem to be about managing the graph of references of data, and itʼs useful to be able to work with those graphs at some point, even if the language is hesitant to give it up so easily. (Allowing a program unmanaged access to its own heap would be a disaster. Itʼs understandable, really.)</p>
<h4 id="javascript">JavaScript</h4>
<p>JavaScript will be our stand-in for a scripting language with a simple, dynamically typed, mutable data model (and garbage collector).</p>
<p>Everyoneʼs familiar with the JSON side of JavaScript: it stands for JavaScript Object Notation, after all. But once you embed in the larger language, you can get things like cyclic references via mutation. Even things like arrays work differently than JSON promised.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p>As a silly example,</p>
<pre class="javascript"><code>// this is the “weird” JS `const`
// where the variable reference is
// constant, but the data is mutable!
const selfRef = [];
selfRef.push(selfRef);
console.log(selfRef[0] === selfRef);

console.log(JSON.stringify(selfRef));
// Uncaught TypeError: cyclic object value</code></pre>
<p>This is no longer JSON serializable!</p>
<p>This one is still JSON serializable, but it no longer behaves the same after deserialization:</p>
<pre class="javascript"><code>const twin = {name: "Lo"};
const twins = [twin, twin];
const gemini = JSON.parse(JSON.stringify(twins));
twins[1].name = "Hi";
gemini[1].name = "Hi";
console.log(JSON.stringify(twins)); // [{name: "Hi"}, {name: "Hi"}]
console.log(JSON.stringify(gemini)); // [{name: "Lo"}, {name: "Hi"}]</code></pre>
<p>So JavaScript, by allowing mutation, can observe cyclic and shared references that JSON simply does not have.</p>
<p>Most people donʼt reckon with this aspect of the runtime at a deep level! Obviously they throw mutable references around all the time and understand that they are shared, and will design some kind of serialization format that uses IDs or something and then reconstruct the right shared references on top of that. But they donʼt build debugging tools for JavaScript itself that would work with arbitrary data.</p>
<p>But what if you didnʼt have to?</p>
<p>Thereʼs actually a way to make a serialization so that <code class="javascript">gemini</code> behaves like <code class="javascript">twins</code>. I call this pickling, after the Python library. More on this later.</p>
<h5 id="functions-1">Functions</h5>
<p>Not much worth saying about functions. You can get their source code in JavaScript (why??), but you cannot observe their closure, so you cannot pickle them up thoroughly.</p>
<h5 id="globals-such-as-dom-references">Globals, such as DOM references</h5>
<p>As will be the theme, references to foreign data (not strings, numbers, objects, arrays) are tough.</p>
<p>Global object types are worth thinking about. They are opaque to code, but in theory they live in predictable places in the global namespace each time, so the proper reference to them can be reconstructed. However, thereʼs still complications, such as that different runtimes will expose different ones (Chromium, Firefox, Node, Deno,&nbsp;…).</p>
<p>By far the most common types of foreign objects will be from the DOM. Some can be serialized pretty directly – at least snapshotted if they arenʼt immutable (like all the little attribute list or node list types, or bounding box type).</p>
<p>If you have a reference to an element with an <code class="html:Attribute">id</code>, you might expect that you could serialize it, and then reload the page, and have it still refer to “that” element. But “that” element doesnʼt exist anymore. Maybe thereʼs a new one with the same <code class="html:Attribute">id</code> – maybe the <code class="html:Attribute">id</code> doesnʼt exist anymore! Well, it is sort of the best marker of intent there is.</p>
<p>And so we come to the conclusion that we will always be struggling with the API boundaries of runtimes, of data that isnʼt constructed from within the language itself. Once you have data inside your system that references things outside, how do you deal with it? What kind of guarantees could you still get when persisting it?</p>
<h5 id="debugging-cyclic-structures">Debugging cyclic structures</h5>
<p>It is worth noting that NodeJS debugging facilities finally implemented support for detecting cyclic references when printing out structures and letting you know what the reference is.</p>
<p>Itʼs a simple thing, but itʼs a barrier that most people throw up their hands when encountering.</p>
<p>Itʼs also funny that when debugging things interactively, via point and click stuff, lazily expanding, that you donʼt care too much whether the data structure is cyclic or shared: nothing will blow up since it does not recurse automatically.</p>
<h5 id="pickling-javascript-runtime-values">Pickling JavaScript runtime values</h5>
<p>You can imagine an algorithm (well, I could write it if I wasnʼt sleepy) that pickles JSON-like objects, but in a way that respects mutability and sharing. It would write out a function definition to reconstruct a new mutable object equivalent to the one it was given.</p>
<p>In JavaScript you would have to do this the slow way. You would maintain a list of <strong>all</strong> mutable objects you have seen, along with where you saw them as a path down from the root object. You would then output code that reconstructs an object incrementally, by adding properties in order, and grabbing shared references from other parts of the object as necessary (or caching them in variables).</p>
<p>The cool thing is that you can do it all with <code class="javascript">const</code>! You donʼt need mutability at the variable level, you can (and should) do it all at the mutable value level.</p>
<p>The algorithm I described can do this for data that is simple in structure, but complicated in terms of references, and with extensions it could handle more things (like regular expressions would be easy to add, <code class="javascript">undefined</code> would be trivial). Actually, it is funny – it would also need to be extended to handle sparse arrays, and all of these little details tell you about how simplified JSON is from the actual data model of JavaScript.</p>
<p>This would give you your own faithful, accurate slice of the runtime heap as viewed from the perspective of one objectʼs watershed of references. The resulting reconstructed value would behave the same with regards to mutability of its children. It just would not compare equal with <code class="javascript">===</code>, since it is a newly allocated value (and all of its children are too).</p>
<p>However, if nobody else remembered the old object, and you substituted in the new object very sneakily&nbsp;… nobody would know 🤫</p>
<h4 id="python">Python</h4>
<p>Python is pretty similar to JavaScript, in the rough kinds of mutable data it supports, but worth talking about separately.</p>
<p>It has more explicit boundaries around mutability and immutability in its data types. (Although still not as nice as Haskell. And I suppose JavaScript has been getting a little more in the way of immutability and actual data types.)</p>
<p>Python also provides the pickling library that is one of the main subjects of this article. More on this later.</p>
<p>Some wrinkles:</p>
<ul>
<li><p>The fact that <a href="https://docs.python.org/3.3/using/cmdline.html#envvar-PYTHONHASHSEED">the hashing function rotates each run</a> is really interesting! It technically is an observable difference between runs, but it isnʼt some essential semantic feature of the data. And you would have the same sort of thing if you are allowed to see an ordering on pointers.</p></li>
<li><p>External references, like files and sockets and other stuff – talked about elsewhere.</p></li>
<li><p>Regexes are really interesting. Theyʼre pointers to foreign object (compiled regexes in some library implementation). But they can be reconsistuted into equivalent objects very easily.</p></li>
</ul>
<h5 id="pickling-python-runtime-values">Pickling Python runtime values</h5>
<p>Itʼs worth getting to know the <a href="https://docs.python.org/3/library/pickle.html"><code class="python">pickle</code> module</a>ʼs capabilities and limitations, so I will just copy and paste the juicy bits here:</p>
<blockquote>
<p>The <code>pickle</code> module keeps track of the objects it has already serialized, so that later references to the same object won’t be serialized again. […]</p>
<p>This has implications both for recursive objects and object sharing. Recursive objects are objects that contain references to themselves. […] Object sharing happens when there are multiple references to the same object in different places in the object hierarchy being serialized. <code>pickle</code> stores such objects only once, and ensures that all other references point to the master copy. Shared objects remain shared, which can be very important for mutable objects.</p>
</blockquote>
<blockquote>
<p><code>pickle</code> can save and restore class instances transparently, however the class definition must be importable and live in the same module as when the object was stored.</p>
</blockquote>
<blockquote>
<p>Note that functions (built-in and user-defined) are pickled by fully <a href="https://docs.python.org/3/glossary.html#term-qualified-name">qualified name</a>, not by value. <a href="https://docs.python.org/3/library/pickle.html#id8">[2]</a> This means that only the function name is pickled, along with the name of the containing module and classes. Neither the function’s code, nor any of its function attributes are pickled. Thus the defining module must be importable in the unpickling environment, and the module must contain the named object, otherwise an exception will be raised. <a href="https://docs.python.org/3/library/pickle.html#id9">[3]</a></p>
</blockquote>
<blockquote>
<p>Similarly, when class instances are pickled, their class’s code and data are not pickled along with them. Only the instance data are pickled. This is done on purpose, so you can fix bugs in a class or add methods to the class and still load objects that were created with an earlier version of the class. If you plan to have long-lived objects that will see many versions of a class, it may be worthwhile to put a version number in the objects so that suitable conversions can be made by the class’s <code>__setstate__()</code> method.</p>
</blockquote>
<p>This last quote raises an important point: there is some aspect of intent when restoring data to a new runtime. Just because you named the class or function the same, does not mean it is the same class or function! But it is a good marker of intent and worth preserving.</p>
<h3 id="others">Others</h3>
<h4 id="go-java">Go, Java, …</h4>
<p>I actually donʼt know a whole lot about Go or Java.</p>
<p>But they need some structure, at least for garbage collection purposes!</p>
<p>“Heap layout”.</p>
<p>Basically every runtime <em>at least</em> needs to keep track of which piece of data is a pointer or not.</p>
<h4 id="rust">Rust</h4>
<p>dunno?</p>
<h4 id="cc">C/C++</h4>
<p>Uh, yeah. Good luck.</p>
<p>Pointers “are” numbers? What the fuck?!</p>
<p>Clearly thereʼs nothing much we can say about coherent semantics&nbsp;… without getting really deep into the weeds of what is and isnʼt undefined behavior and why.</p>
<p>However, it does reinforce the point: at a very very basic level, OSes and memory management and stuff are about managing the graph of live pointers –&nbsp;it is just very very hard to determine what bytes are actually live pointers at any given point in a C program, and what bytes are other kinds of data.</p>
<h2 id="nasal-scripting-language">Nasal Scripting Language</h2>
<p>Yeah, it gets its own section and backstory!!</p>
<p><a href="https://wiki.flightgear.org/Nasal_scripting_language">Nasal</a> is a small embedded scripting language. Its name stands for “Not another scripting language”.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> Its only notable use is in the <a href="https://wiki.flightgear.org/Main_Page">FlightGear open-source flight simulator</a>, although <a href="https://kymatica.com/apps/algoscore">AlgoScore</a> and a tiny handful of other tiny projects use it.</p>
<p>Its data model is basically JavaScript, but simpler and better. (Arrays are their own data type, are not allowed to be sparse, and you can actually iterate over collections in a sensible manner. Good riddance to Lua and JavaScript. Ugh.)</p>
<p>It has some metaprogramming facilities by default, plus I prototyped some more of my own, including full bytecode decompilation.</p>
<p>Finally it has this one special function: <code class="javascript">id(obj)</code>. It returns a string representation of the (stable) pointer for any object!</p>
<pre class="javascript" data-lang="Nasal"><code>&gt;&gt;&gt; id([])
'vec:0x7fea11014c40'</code></pre>
<p>I mean, I guess it is like the <code class="python">id()</code> function in Python&nbsp;… Yeah, both use mark/sweep GCs, so pointers are stable.</p>
<p>Anyways, the other great thing about Nasal is that objects donʼt have constructors! It is so liberating.</p>
<h3 id="pickling-nasal-runtime-values">Pickling Nasal runtime values</h3>
<p>Pickling consists of writing out a file that, when executed, returns an equivalent object. (The body of a file is simply a function. Plus all statements are expressions – they have a return value, although sometimes it is a pretty useless return value.)</p>
<ul>
<li>You initialize a hashmap of object ids that have been seen.</li>
<li>For each object you see, you look at the hashmap:
<ul>
<li>If not, you add the reference to the hashmap, and add a variable to the file to save the reference in case you need it later.</li>
<li>If it exists, you insert code to reference the existing variable and stop walking the structure.</li>
</ul></li>
<li>For non-recursive data, you just set it directly.</li>
<li>For recursive data (objects and arrays), to handle cyclic references you may need to initialize it to an empty value and add items via mutation. Thus when those items mention their (grand)parent, that reference already exists in a variable, and the rest of the structure will continue to be built as necessary.</li>
</ul>
<p>In lieu of a hashmap, you could even use a list of objects, and traverse it in linear time to compare referential identity. This is possible in most dynamic languages, just really slow.</p>
<h3 id="functions-builtins-bootstrapping">Functions, builtins, bootstrapping</h3>
<p>I also tried to work on a bootstrapping system for Nasal. I never completed it.</p>
<p>Anyways, this is relevant because I did add bytecode decompilation for functions. You could already inspect bound scopes of closures, and callers and local scopes of the call stack. All that was left was builtins (which donʼt have bytecode).</p>
<p>If you have a contract with the bootstrapping system, you could look up the globally accessible names for the builtin functions that you could not decompile, and hopefully assume that equivalent builtin functions would live in those same spots on the next bootstrapping too.</p>
<p>The problem, still, is builtin external references, like files and such. Some could be supported on a case-by-case basis, but not everything.</p>
<p>Also, ideally you would airgap<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> the builtins, since some builtins are fake builtins. That is, they are wrappers over actual builtin functions, but you could only access those builtins through the closure of the wrapped function – so you might as well stop bytecode decompilation for the wrapped functions (by wrapping the decompiler!) and treat them as builtins.</p>
<p>Anyways, in theory you would almost be able to save the entire state of a running Nasal system and fully reconstitute it under an equivalent bootstrapped environment. At the very least, you would expect to be able to save complicated data with simple functions.</p>
<h3 id="equivalence">Equivalence</h3>
<p>The pickling process points towards a method of determining equivalence. Obviously you should sort the file in some semantic way, and rename variables to less arbitrary things. Maybe normalize the bytecode for functions.</p>
<p>After that, you should just be able to compare your resulting files and use that as a notion of equivalence!</p>
<p>Alternatively, you could write out a direct algorithm: take two objects at runtime and walk them recursively with the same kind of hashmap trick, comparing at which paths you see the objects, and then just make sure the shared references appear at the same minimal-paths from the root across their sharings. (You want to avoid cyclic recursions, of course, which does mean you will only look at minimal paths.)</p>
<p>Iʼll call this&nbsp;… “graph equality”? “Stable equality”? It is what Iʼve meant by “equivalence” all along.</p>
<h3 id="ghost-objects-foreigns-property-tree">Ghost objects (foreigns), property tree</h3>
<p>Nasal has a concept of “ghost” objects which are pointers to foreign objects, literally just C pointers with some associated data to help the garbage collector.</p>
<p>These are constructed by C APIs, and the only way to reconstruct them would be if you can call those APIs again to produce equivalent objects – which may not always be possible.</p>
<p>One of the main foreign interfaces of Nasal is <a href="https://wiki.flightgear.org/Property_tree">FlightGearʼs property tree</a> – a central store of important simulator values that is accessible from all of FlightGearʼs subsystems, not just Nasal. References to these nodes can be stored (making use of ghost objects) and manipulated through <a href="https://wiki.flightgear.org/Nasal_library/props">an API</a>, in a way that is somewhat like accessing the DOM in JavaScript.</p>
<p>This is one type of ghost reference that could easily be handled by a pickling script: since the path of the node is available, you just have to serialize that, and then obtain the node again when deserializing. However, there still is some rough edges: what if the node doesnʼt exist when it is getting loaded again? It could be possibly recreated, but now the deserialization has side-effects, which is weird. Or a separate property tree could be created to sandbox the script, and relevant nodes created there.</p>
<p>Property trees can also be saved to XML and loaded from there, although there are various details that donʼt translate well regardless of serialization format. One example is properties that are managed by C++ code, instead of having their data be managed by the property tree – but those properties typically exist by the time Nasal is initialized.</p>
<p>So thereʼs always some details that need to be figured out or approximated when dealing with external APIs and data that is not managed in the language itself.</p>
<h3 id="strings-1">Strings</h3>
<p>Nasal strings were actually a fun challenge. It has mutable strings!</p>
<p>It has immutable interned strings, which are cached in a global lookup table. This is used for identifiers (including object keys), to speed up comparisons.</p>
<p>It also has mutable strings (and I believe they can be mutated to be immutable? it is a little weird).</p>
<p>The referential identity of strings is not exposed – the equality operator ignores it. However, you can still determine whether two mutable strings are the same reference, by using test mutation: if you mutate one and the other stays the same, they are different references.</p>
<p>(You can even use missed fast comparisons to determine if a string is interned or not.)</p>
<h2 id="broader-thoughts">Broader Thoughts</h2>
<p>The main thing I want you to take away is that dynamic runtimes donʼt have to be scary places filled with spaghetti data flying around all over the place. Itʼs actually possible to tame mutable references in many ways!</p>
<p>The concrete lesson is that there are three useful notions of equivalence, that are used for characterizing what levle of abstraction of “data” we want to be looking at, and I think the middle one is much more important than we give it credit for:</p>
<ul>
<li>Referential equality, which treats everything as live, mutable references, but is too fine-grained and doesnʼt make sense across restarting the program. This is the notion of equality that your runtime (and particularly its garbage collector) is tasked with preserving for your code.</li>
<li>My new notion of equivalence, which I will call “graph equality of mutable data”, which keeps track of shared mutable references and so on.</li>
<li>The notion of <a href="https://lodash.com/docs/#isEqual">“deep equality”</a> of objects, which treats them mostly as if they are immutable data. (I didnʼt talk about it at all, whoops, but I assume you are familiar with it.) It can be very useful, but it acts a lot like traditional serialization, and isnʼt comprehensive enough to actually probe the whole of a running system.</li>
</ul>
<p>So while referential equality forms your basic data model of a language, I encourage thinking about equivalence. <strong>If you could swap out two objects completely</strong> (including <em>existing</em> references to them), <strong>would you be able to notice?</strong></p>
<p>And then you need to keep abstracting away what you care about. Do you care about exact hash values? Do you store those hash values in a way that would make reconstruction fail to mean the same thing with a different random seed? And so on.</p>
<p>So thereʼs still domain-specific work to be done, as there always is.</p>
<div class="Key_Idea">
<p>But if we can expose the underlying graph of referential relationships, we have a much much MUCH larger toolbox for working with data and data serialization.</p>
</div>
<h3 id="graph-equality-of-mutable-data">Graph equality of mutable data</h3>
<div class="Key_Idea">
<p>Is (shallow) referential equality the best we can do? What about deep (explicitly non-referential) equality?</p>
<p>Emphatically no – but, it is probably not worth it.</p>
<p>See, we could have the notion of equality that pickling and unpickling preserve. Graph equality, where the sharing of mutable references is tracked and tabulated by their role, instead of exact referential identity.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>If you have two data graphs where pointers are shared in equivalent ways, sure, they could totally be considered parallel universes and interchangeable amongst themselves. (Obviously if something external holds references to them and you donʼt have a way to swap them out, this can break.)</p>
</div>
<p>The only problem is that it is pretty expensive, it requires a <em>lot</em> of bookkeeping, and most people generally donʼt care – they are fine either writing the equality comparison they need, or settling for the standard deep equality.</p>
<p>However, it is very useful!</p>
<p>Like, as one example, this is literally what <a href="https://hackage.haskell.org/package/base-4.17.0.0/docs/GHC-StableName.html">stable names</a> are used for.</p>
<div class="Key_Idea">
<p>Runtimes are literally built on graphs!</p>
<p>We want to be able to touch this. To expose it, to hold it in our hands. To work with it, to meld it to our own needs. To chart our own course through the graph, traversing references and recording where weʼve already visited.</p>
<p>We can have very nice things if we give up the dichotomy of referential identity versus deep equality, and embrace the graph nature of runtimes.</p>
</div>
<h3 id="constructors">Constructors</h3>
<p>As part of these musings on data, I subscribe to the idea that the only objects that should have constructors (at the level of data – obviously client code will want different abstractions) are objects that are constructed from external references, FFI.</p>
<p>Idk, constructors in the sense of mainstream OOP are mostly a distraction for this view of data I want to talk about. They just arenʼt good, arenʼt necessary, they get in the way – especially since the arguments to the constructors donʼt have to correspond to the runtime data of the object at all.</p>
<h2 id="appendix">Appendix</h2>
<p>Miscellaneous thoughts that donʼt belong in the conclusion but do belong at the end.</p>
<h3 id="uses-of-references">Uses of references</h3>
<p>You really should not be able to ask for two references to be ordered against each other: it doesnʼt mean anything with regards to the <em>meaning</em> of the program (although it may record some historical data about how the program <em>did</em> happen to run). But you kind of should be able to put them into a map efficiently, and ordering/hashing is potentially important for that, but only if it can be stable.</p>
<p>Mark/sweep GC is good for stability of pointers (and thus comparisons). I think mark/compact still can preserve comparisons.</p>
<p>Weak references are interesting. Every time Iʼve wanted weak references, Iʼve always actually wanted to do them as reverse references: data stored on the key object, instead of in a map indexed by the key object. (Of course this may leak memory if the map you want to store is not long-term/global.)</p>
<h3 id="abstract-model-for-gcable-data">Abstract model for <span data-t="" data-widget="">GCable</span> data</h3>
<p>I think itʼs instructive to pin down a model of garbage collectable data in Haskell/PureScript, where we can talk about references separately from pure data structures.</p>
<p>This is enough to model the fragment of JavaScript values I said should be covered by the pickling function I sketched. (Well, you could easily add <code class="javascript">undefined</code>.)</p>
<details class="Details">
<summary>
Code
</summary>
<pre class="haskell"><code>-- The managed heap for the runtime data.
-- I believe this is what rustaceans
-- call an arena?
newtype Heap s metadata shape = Heap
  (MVector s (RuntimeData shape, metadata))

data RuntimeData shape
  -- Runtime data is given by a pure shape
  -- (which needs to be `Traversable`!)
  -- which contains runtime references
  -- in a known way
  = RuntimeData (shape RuntimeRef)
  -- It can also be an external “ghost”
  -- reference that we have a function
  -- to destruct (or dereference, if
  -- it is shared data)
  | ExternalGhost Ptr (IO ())

-- A managed reference we control,
-- thus it is an opaque pointer
-- into the opaque memory heap
data RuntimeRef
  = ManagedOpaque Int
  deriving (Eq, Ord)
  -- ^ the user is allowed `Eq`
  --   but not `Ord`

-- An example shape for mutable data
-- in the spirit of JSON (the only
-- reason it is not JSON is that JSON
-- is immutable, being a serialization
-- format, strictly speaking)

-- A JSON value, either a plain value
-- or a reference to a mutable value
data JSONValue ref
  = Null
  | Number Scientific
  | String Text
  | ByRef ref
  deriving (Eq, Ord, Functor, Foldable, Traversable)

-- What data lies behind a mutable value?
data JSONShape ref
  = Array [JSONValue ref]
  | Object [(Text, JSONValue ref)]
  deriving (Eq, Ord, Functor, Foldable, Traversable)

-- If we take the immediate fixpoint,
-- without mutable references in the
-- loop, we get plain immutable JSON data,
-- except that it is lazy, so it is
-- potentially infinite
newtype JSON = JSON (JSONValue JSON)

data Idx
  = ArrayIdx Int
  | ObjectIdx Text

-- A machine for creating a graph in
-- the mutable JSON structure
data Machine ref
  = SetKey ref Text (JSONValue ref) (Machine ref)
  | Push ref (JSONValue ref) (Machine ref)
  | Get ref Idx (JSONValue ref -&gt; Machine ref)
  | NewArray (ref -&gt; Machine ref)
  | NewObject (ref -&gt; Machine ref)
  | Return (JSONValue ref)</code></pre>
<p>Now we can talk about the concepts from above.</p>
<pre class="haskell"><code>equal :: Eq ref =&gt;
  JSONValue ref -&gt;
  JSONValue ref -&gt;
  Boolean
equal = (==)

-- Since Haskell is lazy,
-- JSON is a greatest fixpoint,
-- so, with some care, I believe
-- you could even reify recursive
-- data into the JSON type
-- (but `Eq` would not terminate)
snapshot ::
  (ref -&gt; m (JSONShape ref)) -&gt;
  JSONValue ref -&gt; m JSON

deepEq ::
  (ref -&gt; m (JSONShape ref)) -&gt;
  JSONValue ref -&gt;
  JSONValue ref -&gt;
  m Boolean
deepEq read x y = do
  m &lt;- snapshot read x
  n &lt;- snapshot read y
  -- compare as JSON
  pure (m == n)

equivalent :: Ord ref =&gt;
  (ref -&gt; m (JSONShape ref)) -&gt;
  JSONValue ref -&gt;
  JSONValue ref -&gt;
  m Boolean
equivalent read l0 r0 =
  runStateT (comparing [] (l0, r0)) empty
  where
  comparing ::
    [Idx] -&gt;
    (JSONValue ref, JSONValue ref) -&gt;
    StateT (Map ref [Idx], Map ref [Idx]) m Boolean
  comparing path (l, r) =
    -- Try to match up the values
    case zipMatch l r of
      -- They are both references
      Just (ByRef (ll, rr)) -&gt; do
        -- First we check if we should short circuit
        -- if they have been seen before
        (seenL, seenR) &lt;- get
        case (lookup ll seenL, lookup rr seenR) of
          -- Seen both
          (Just p1, Just p2) -&gt; do
            -- We have to have seen them at the same path,
            -- since we are traversing in the same order
            pure (p1 == p2)
          -- Seen neither
          Nothing, Nothing -&gt; do
            -- Keep track of where we saw this
            -- reference, separately for left and right
            -- (since it is valid for both to use the
            -- same reference for different purposes)
            modify
              (insert ll path *** insert rr path)
            -- Read the current values of the reference
            x &lt;- lift (read ll)
            y &lt;- lift (read rr)
            -- Try to match them up
            case zipMatch x y of
              -- Failed: different types
              Nothing -&gt; pure False
              -- Similar arrays: recurse into children
              Just (Array xys) -&gt;
                allM (uncurry comparing)
                  -- Add the index onto the path
                  (intoArray path &lt;$&gt; enumerate xys)
              -- Similar objects: recurse into children
              Just (Object xys) -&gt;
                allM (uncurry comparing)
                  -- Add the key onto the path
                  (intoObject path &lt;$&gt; xys)
          -- Failed: seen one but not the other
          _, _ -&gt; pure False
      -- Succeed if it is a pure value
      -- that is equal on both sides
      lr -&gt; pure (isJust lr)

intoArray path = first $ \idx -&gt; ArrayIdx idx : path
intoObject path = first $ \key -&gt; ObjectIdx key : path</code></pre>
</details>
<p>Hopefully you can see from the implementation of the <code class="haskell">equivalent</code> function how two distinct references can still be interchangeable for all intents and purposes. We could write out this interchange formally, since all the references are visible on the heap, and then state some theorems about some functions.</p>
<p>However, for other processing, we donʼt even really need this arena/managed heap. We can use the Haskell runtime itself!</p>
<p>I havenʼt worked out the details (<a href="https://hackage.haskell.org/package/base-4.17.0.0/docs/GHC-StableName.html">stable names</a>?), but we should be able to reify the graph of a cyclic <code class="haskell">JSON</code> value too.</p>
<div class="Warning">
<p>The main difference is that, in Haskell, the infinite <code class="haskell">JSON</code> could be truly infinite (like, procedurally generated) – it does not need to be backed by a finite amount of data like it would be in JavaScript.</p>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Except in Rust, I think?<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Leibniz equality, “Identity of indiscernibles”<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>besides performance – we always disregard performance here<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Citation needed.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Sighs in <a href="https://blog.veritates.love/tmttmt.html">tmTTmt</a>&nbsp;…<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Even in non-Turing-complete languages!<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>This is slightly unfair, considering that Dhall now uses <span data-t="" data-widget="">NbE</span>, but it amounts to the same thing.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>BEAM uses mutation to construct data locally, but this is only an implementation detail that cannot be observed from Erlang.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>inasmuch as a concurrent system can have a current state&nbsp;…<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>See §3.2 “Stable Names”.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>JS arrays can be sparse. Still mad about that.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><a href="https://github.com/andyross/nasal/blob/088be4d3642f696ad99bad3c79d15b692b368934/www/index.html#L182-L186">“Nasl” was already taken</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Sorry, wrong word.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>think: pointer<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>A Semiring From Any Semilattice</title>
<pubDate>Sat, 28 Oct 2023 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/semilattice_semiring.html</guid>
<description><![CDATA[<p>Iʼve been working on some theoretical aspects of programming recently. Writing new compiler optimization passes. Thinking about <a href="https://github.com/MonoidMusician/blog/blob/main/PureScript/src/Parser/Languages/Talk.purs">parsers</a> through the lens of <a href="https://hackage.haskell.org/package/selective-0.7/docs/Control-Selective.html#t:Selective">selective applicative functors</a>, and tweaking them to encode <a href="https://github.com/MonoidMusician/blog/blob/main/PureScript/src/Parser/Selective.purs">exclusive choice</a>.</p>
<p>If you go far enough down the rabbit hole, it turns out that you want semirings for static analysis. This is not unheard of in compilers! Itʼs a really good technique for analyzing control flow, for example: information about exclusive branches are combined additively, and information from sequential operations are combined multiplicatively. It is especially appropriate because, semantically speaking, you want those sequential operations to distribute over the branching.</p>
<p>(You can already see this in more typical typeclasses like <code class="haskell">Alternative</code>, which is naturally analyzed by taking <code class="haskell">&lt;*&gt;</code> to <code class="haskell">*</code> and <code class="haskell">&lt;|&gt;</code> to <code class="haskell">+</code>. Itʼs just that Iʼm interested in augmenting <code class="haskell">Selective</code> to encode exclusive choice too.)</p>
<p>This led me to come up with this construction: how to make a semiring out of a semilattice.</p>
<p>This construction answers the question, “if you need a semiring for static analysis, how do you also keep other data around that does not care about the branching structure?” (like, say, a monoid).</p>
<div class="Details">
<p>Specifically in selective applicative parsers, I need it to answer the question of why aggregating information about the grammar is a valid thing to do across parser combinator segments, no matter how they are combined.</p>
<p>And in the compiler pass I was doing, I was implementing demand analysis via semirings (especially the <a href="https://en.wikipedia.org/wiki/Tropical_semiring">min tropical semiring</a>). I actually donʼt have specific information I was considering aggregating as a semilattice, but it was a possibility that might come up, especially if I want to fuse some passes together. Right now my one pass is really three traversals of the tree, with various monad stacks of reader, writer, and state. (Yes I used all three.)</p>
</div>
<p>I don’t know if this construction is well-known! Let me know if you have a reference for it.</p>
<div class="Key_Idea" data-box-name="tl;dr">
<p>You can make a semiring out of a semilattice by adjoining a new zero element. Lifting the semilattice operation in the two obvious ways gives you <code class="haskell">+</code> and <code class="haskell">*</code>. Idempotence gives distributivity(!).</p>
</div>
<h2 id="background">Background</h2>
<p>(Bounded) semilattices are commutative monoids whose operation is also idempotent: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mi>x</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x \diamond x = x</annotation></semantics></math></span> for all <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span>.</p>
<p>I will write the monoid operation as <code class="haskell">x &lt;&gt; y</code> and as <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \diamond y</annotation></semantics></math></span>, and the empty element as <code class="haskell">mempty</code> or <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span>. </p>
<div class="Bonus">
<p>Semilattices have deep connections to order theory: they induce a really nice preorder given by <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \leq y</annotation></semantics></math></span> when <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mi>y</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x \diamond y = x</annotation></semantics></math></span> (or vice-versa, depending on whether you are talking about meet or join semilattices – and no, I cannot keep them straight 🏳️‍🌈). But we donʼt need the order theory here.</p>
</div>
<p>Semirings are rings without subtraction: just addition and multiplication and their identities, zero and one, respectively. And <a href="#distributivity">distributivity</a> and <a href="#annihilation">annihilation</a> laws to intertwine these two monoids.</p>
<p>The funny part of this is that “semi-” means different things: semirings are just missing subtraction (kind of a weird use of semi, which is why some call them <a href="https://ncatlab.org/nlab/show/rig">rigs</a>), but semilattices are literally half of a lattice (one idempotent commutative monoid instead of two interlinked).</p>
<p>(Lattices are actually closely related to semirings: they have the same shape of operations, and you can turn every bounded <em>distributive</em> lattice into a semiring – in two ways, in fact, since you can make a lattice with the opposite order.)</p>
<p>So itʼs like a mathematical joke that they can be related to each other at all!</p>
<p>How do we get two monoids out of one??</p>
<h2 id="description">Description</h2>
<p>The key idea is to adjoin a zero. Thatʼs it.</p>
<p>The rest of the moves can be determined from that premise, so letʼs see how it works:</p>
<pre class="purescript"><code>data WithZero t = Zero | NonZero t

-- Imagine that `t` is really a `Semilattice`
-- (this does not exist as a class in PureScript)
instance Monoid t =&gt; Semiring (WithZero t) where
  zero = Zero
  one = NonZero mempty

  add Zero Zero = Zero
  add Zero r = r
  add l Zero = l
  add (NonZero l) (NonZero r) = NonZero (l &lt;&gt; r)

  mul (NonZero l) (NonZero r) = NonZero (l &lt;&gt; r)
  mul _ _ = Zero</code></pre>
<p>The two operations are the semilattice operation lifted through <code class="haskell">Maybe</code> in the two possible ways:</p>
<ul>
<li><code class="haskell">add</code> follows the pattern of the default <code class="haskell">Semigroup a =&gt; Monoid (Maybe a)</code> instance, that uses <code class="haskell">Nothing</code> as its identity. This makes sense since weʼre adding <code class="haskell">Zero</code>, the identity for <code class="haskell">add</code>. Indeed, it is forced by the laws, and the fact that we only have one binary operation to use.</li>
<li><code class="haskell">mul</code> is like the other possible instance, <code class="haskell">Monoid a =&gt; Monoid (App Maybe a)</code>, formed by <code class="haskell">(&lt;&gt;) = lift2 (&lt;&gt;)</code>. This is likewise forced by the annihilation law and the fact that we only have one binary operation to use.</li>
</ul>
<h2 id="laws">Laws</h2>
<p>Iʼm going to be lazy and use math notation for the laws, with the understanding that when I say <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \neq 0</annotation></semantics></math></span> for example, it means in Haskell/PureScript that <code class="haskell">x = NonZero x' :: WithZero t</code> for some unique <code class="haskell">x' :: t</code>, and if <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x, y \neq 0</annotation></semantics></math></span> then <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \diamond y</annotation></semantics></math></span> means <code class="haskell">NonZero (x' &lt;&gt; y')</code>.</p>
<h3 id="distributivity">Distributivity</h3>
<p>The fun part is the left and right distributivity laws:</p>
<p>To prove left distributivity, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>∗</mo><mi>y</mi><mo>+</mo><mi>x</mi><mo>∗</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">x * (y + z) = x * y + x * z</annotation></semantics></math></span>, we look at some cases:</p>
<ul>
<li>If <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x = 0</annotation></semantics></math></span>, then we have <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>∗</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>=</mo><mn>0</mn><mo>∗</mo><mi>y</mi><mo>+</mo><mn>0</mn><mo>∗</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">0 * (y + z) = 0 = 0 * y + 0 * x</annotation></semantics></math></span>.</li>
<li>If <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">y = 0</annotation></semantics></math></span>, then we have <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>0</mn><mo>+</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>∗</mo><mi>z</mi><mo>=</mo><mi>x</mi><mo>∗</mo><mn>0</mn><mo>+</mo><mi>x</mi><mo>∗</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">x * (0 + z) = x * z = x * 0 + x * z</annotation></semantics></math></span>.</li>
<li>If <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">z = 0</annotation></semantics></math></span>, then we have <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>∗</mo><mi>y</mi><mo>=</mo><mi>x</mi><mo>∗</mo><mi>y</mi><mo>+</mo><mi>x</mi><mo>∗</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x * (y + 0) = x * y = x * y + x * 0</annotation></semantics></math></span> similarly.</li>
<li>So now we can assume that all three variables are nonzero. But that means we fall back to the underlying semilattice operation: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>x</mi><mo>⋄</mo><mo stretchy="false">(</mo><mi>y</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋄</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">x \diamond (y \diamond z) = (x \diamond y) \diamond (x \diamond z).</annotation></semantics></math></span> But by commutativity and associativity, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋄</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⋄</mo><mo stretchy="false">(</mo><mi>y</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">(x \diamond y) \diamond (x \diamond z) = (x \diamond x) \diamond (y \diamond z).</annotation></semantics></math></span> And finally we finish off with idempotence: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>x</mi><mo>⋄</mo><mo stretchy="false">(</mo><mi>y</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">x \diamond (y \diamond z).</annotation></semantics></math></span></li>
</ul>
<p>We prove right distributivity in the same way <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>∗</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mi>z</mi><mo>=</mo><mi>x</mi><mo>∗</mo><mi>z</mi><mo>+</mo><mi>y</mi><mo>∗</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">(x * y) + z = x * z + y * z</annotation></semantics></math></span>, based on the calculation <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mo>⋄</mo><mo stretchy="false">(</mo><mi>y</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋄</mo><mo stretchy="false">(</mo><mi>z</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">(x \diamond z) \diamond (y \diamond z) = (x \diamond y) \diamond (z \diamond z).</annotation></semantics></math></span></p>
<p>The takeaway is that <strong>idempotence of the semilattice gives us distributivity of the semiring</strong>. This is why having a semilattice and not merely a monoid is essential.</p>
<p>This does make some sense: if weʼre aggregating information that does not care about branching structure at all, well, semilattices are great models for accumulating knowledge. Idempotence says you only learn a fact once.</p>
<div class="Bonus" data-box-name="Generalizing">
<p>We donʼt require multiplication to be commutative, so if you drop the left-distributivity law, you could get away with a <a href="https://en.m.wikipedia.org/wiki/Band_(algebra)#Right-regular_bands">right-regular band</a> with the law <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mi>y</mi><mo>⋄</mo><mi>x</mi><mo>=</mo><mi>y</mi><mo>⋄</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x \diamond y \diamond x = y \diamond x</annotation></semantics></math></span>.</p>
<p>I think left-distributivity is a bit weirder than right-distributivity, in the context of control flow. Right distributivity just says you can copy any training code into each case branch.</p>
<p>However, in general Iʼm a fan of left-regular bands, since they intuitively preserve order.</p>
<p>Also, to be fair, you could absolutely disregard some semiring laws for the sake of static analysis of programs: you donʼt always want to treat programs as purely algebraic structures, and often want to dig into the details of how they were constructed.</p>
<p>Like, if youʼve factored out common control flow, thatʼs almost always for a reason! So your static analysis should reflect that.</p>
</div>
<h3 id="annihilation">Annihilation</h3>
<p>We made this true by definition of <code class="haskell">mul</code>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>∗</mo><mi>x</mi><mo>=</mo><mn>0</mn><mo>=</mo><mi>x</mi><mo>∗</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">0 * x = 0 = x * 0</annotation></semantics></math></span>.</p>
<h3 id="additive-monoid">Additive monoid</h3>
<h4 id="identity">Identity</h4>
<p>We also made <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>+</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">0 + x = x = x + 0</annotation></semantics></math></span> true by definition of <code class="haskell">add</code>.</p>
<h4 id="associativity">Associativity</h4>
<p>So we just need to prove that <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>+</mo><mo stretchy="false">(</mo><mi>y</mi><mo>+</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">x + (y + z) = (x + y) + z</annotation></semantics></math></span> for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x, y, z \neq 0</annotation></semantics></math></span>. But that follows from the semilatticeʼs associativity: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mo stretchy="false">(</mo><mi>y</mi><mo>⋄</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>y</mi><mo stretchy="false">)</mo><mo>⋄</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">x \diamond (y \diamond z) = (x \diamond y) \diamond z</annotation></semantics></math></span>.</p>
<h4 id="commutativity">Commutativity</h4>
<p>Yes.</p>
<h3 id="multiplicative-monoid">Multiplicative monoid</h3>
<h4 id="identity-1">Identity</h4>
<p>For <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>∗</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>∗</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 * x = x = x * 1</annotation></semantics></math></span>, we need two cases: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x = 0</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \neq 0</annotation></semantics></math></span>. But if <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x = 0</annotation></semantics></math></span>, it is trivial still. (This is the nice way the identities and annihilator elements interact. They donʼt add any proof burden to the other.)</p>
<p>So for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \neq 0</annotation></semantics></math></span> (and since <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">1 \neq 0</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span> is given by the semilatticeʼs identity <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span>), we look at the underlying semilattice and find that <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mo>⋄</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>=</mo><mi>x</mi><mo>⋄</mo><mi>e</mi></mrow><annotation encoding="application/x-tex">e \diamond x = x = x \diamond e</annotation></semantics></math></span> as we want.</p>
<h4 id="associativity-1">Associativity</h4>
<p>Same case analysis as usual: if <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x, y, z \neq 0</annotation></semantics></math></span> then we get associativity from the semilattice, otherwise both sides equal <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span> by the power of the annihilator.</p>
<h4 id="commutativity-1">Commutativity</h4>
<p>Yes.</p>
<h3 id="absorption-laws-fail">Absorption laws fail</h3>
<p>Note that we cannot make a lattice out of the semilattice – thatʼs a step too far. Intuitively from the order theory point of view, thereʼs no reason why would would be able to, since the meet and join operations of a lattice have opposite views of the preorder of the lattice.</p>
<p>And algebraically, the two absorption laws would fail in general: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∗</mo><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x * (x + y) = x</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>+</mo><mo stretchy="false">(</mo><mi>x</mi><mo>∗</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x + (x * y) = x</annotation></semantics></math></span> (even stating them like that looks weird). For <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x \neq 0</annotation></semantics></math></span>, by idempotence of the semilattice we would see <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>⋄</mo><mo stretchy="false">(</mo><mi>x</mi><mo>⋄</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mo>⋄</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \diamond (x \diamond y) = x \diamond y</annotation></semantics></math></span>, which only equals <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span> if <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>e</mi></mrow><annotation encoding="application/x-tex">y = e</annotation></semantics></math></span>. Thereʼs just no way to get rid of the extra <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span> there if we are sticking to one operation.</p>
<h2 id="iterating">Iterating</h2>
<p>You could technically iterate this construction, since <code class="haskell">add</code> and <code class="haskell">mul</code> are both idempotent, commutative, associative operations now. However itʼs not terribly interesting.</p>
<p>You end up adjoining some number of identities and annihilators to the underlying semilattice. (New top/bottom elements, depending on which way you look at it.) The order that you do this in does not matter, only how many times you choose to do each way.</p>
<h2 id="additional-comments">Additional comments</h2>
<p>Want a semiring without zero? No need to adjoin a zero, then – just use the same carrier type. The remaining laws still just work.</p>
<p>For static analysis, the zero is only good for representing unreachable/error cases. But the identity of the semilattice is indispensible: itʼs the empty analysis for when you know nothing yet or have nothing to contribute.</p>
<p>Important to note that all of these algebraic constructs (monoids, semilattices, semirings<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) are closed under taking products. This is why I said “how do you <em>also</em> keep other data around” in the introduction.</p>
<h3 id="explaining-to-non-mathematicians">Explaining to non-mathematicians</h3>
<p>The concept of a semiring is an abstract conception of what a number is. A particular semiring is a specific conception of what can be a number. We can manipulate these “numbers” in the familiar ways – mostly.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>but <strong>not</strong> fields<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>TransMorphism Type Theory MetaTheory</title>
<pubDate>Fri, 13 Oct 2023 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/tmttmt.html</guid>
<description><![CDATA[<p><span style="display: block;text-align: center;font-size:1.2em">🦋 <em>heck u! *programs ur semicolons :3*</em> 🦋</span></p>
<p>Iʼve been dreaming of making my own metalanguage for writing type theories for many years now. I havenʼt implemented much yet, but Iʼve been refining my ideas. Hereʼs a tiny taste:</p>
<p><em>What you write:</em></p>
<pre class="js" data-lang="tmTTmt"><code>// If we are casing on a known boolean, we know which case to choose
normalize/ ["if" "true" "then" exprT "else" exprF] =&gt; exprT;
normalize/ ["if" "false" "then" exprT "else" exprF] =&gt; exprF;
// If both branches have the same value, the boolean is irrelevant
// This is an example of non-linear pattern matching, which will get desugared
normalize/ ["if" _cond "then" expr "else" expr] =&gt; expr;
// Fallback case, including most other nodes not specified
normalize/ layer =&gt; normalized:
  // ^ We compute the result, `normalized`, by following these operation(s):
  // Recursively calling normalize on each child node of this node
  // (that's it, that's the only operation in this case, but there could be more)
  map normalize layer =&gt; normalized
  // ^ okay this line probably needs tweaking for type inference ...</code></pre>
<p><em>What it means:</em></p>
<pre class="haskell"><code>normalize (Roll (IfThenElse metadata cond exprT exprF)) =
  case normalize cond of
    -- Note that "true" above is allowed to stand for the literal in the AST
    -- (as well as the Boolean type in tmTTmt itself), but in Haskell we need
    -- an explicit constructor `BooleanLiteral` to embed it in the AST:
    BooleanLiteral True -&gt; exprT
    BooleanLiteral False -&gt; exprF
    condN -&gt;
      let (exprTN, exprFN) = (normalize exprT, normalize exprF)
      in case areEqual exprTN exprFN of
        -- Every time we equate two expressions, especially though matching on
        -- the same variable name twice, we return a unified node, so that we
        -- have a chance to merge *metadata* when the underlying *data* is
        -- the same. In typechecking, unifying can also unify metavariables,
        -- through algebraic effects or something.
        Just exprN -&gt;
          exprN
        -- We fall back to the `map` operation, special cased for the node we
        -- already matched here. We can pass the metadata through to the result,
        -- or update it -- but how?? It will be specified in other places,
        -- e.g. through typeclasses and auxiliary functions ...
        Nothing -&gt;
          Roll (IfThenElse (updateMetadata?? metadata) condN exprTN exprFN)
normalize (Roll layer) = Roll (map normalize layer)</code></pre>
<p>I want to skew to the left of many design choices that have been made for most languages, aiming for very specific tradeoffs to achieve aesthetics and functionality.</p>
<p>My goal is to have a syntax that is straightforward for humans to write and easy for computers to interpret.</p>
<p>But I donʼt want this process to be magic! I just want it to look convenient for writing powerful systems of type theory.</p>
<h2 id="abstract">Abstract</h2>
<p><a href="https://blog.veritates.love/blog.veritates.love/tmttmt.html">tmTTmt</a> (transmorphism Type Theory metatheory) is an experiment in the UX and aesthetics of a pure, typed functional programming language, with the goal of being an interlingua (it must be easy to parse, reducible to an implementation with few required primitives, and human readable along the way, including methods for understanding what the source code is and does) and with an eye towards being suitable for being an exceptional metalanguage for type theory and compilers and also a welcoming place to write down algorithms of general interest (e.g.&nbsp;computing a cubic Bézier from a quadratic Bézier, or computing an LR(1) parse table from a grammar, or describing high-level cryptography operations that can be compiled to appropriate code in languages such as JavaScript, Python, or Erlang)</p>
<h2 id="demos">Demos</h2>
<p>AAaaahhhh</p>
<p>Implementation in progress!</p>
<p>See also <a href="#development">Development</a>.</p>
<div class="widget" data-widget="Widget.Query" data-widget-empty="true" data-widget-datakey="default" data-widget-data-keys="tmttmt-example">

</div>
<h3 id="type-system">Type system</h3>
<div class="widget" data-widget="Parser.Main.TMTTMT" data-widget-loading="true" style="display: contents" data-widget-data-example="typecheck-examples">

</div>
<h3 id="evaluation">Evaluation</h3>
<div class="widget" data-widget="Parser.Main.TMTTMT" data-widget-loading="true" style="display: contents" data-widget-data-example="eval-examples">

</div>
<h2 id="motivation">Motivation</h2>
<p>My problem with existing programming languages is that they are too heavily tied to a fixed logic of computation: ADTs in Haskell are great (especially for language design!), at least right up until you need to add extra data to your ADTs, and now that infects your whole program with ugliness and bookkeeping.</p>
<p>In general, <strong>this distinction between data and metadata</strong> is so <em>crucially</em> important to me. And not something that is really considered in any typed programming language! Data has always gotten tied directly to the logic you are working in, and metadata was given no freedom to roam around. So letʼs unleash them. Let it loose :3</p>
<div class="Example">
<p>As a very concrete example of this, imagine caching which variables are present in each term (such as <a href="https://en.wikipedia.org/wiki/Director_string">Director strings</a>, or a simple extra <code>Set Name</code> on each node). This can be used to skip allocations when you know nothing is changing in operations that target variables. But now you need to keep track of that information literally everwhere you construct nodes in your AST! Despite it being a really simple algorithm to compute on its own, one that hopefully could be incrementally updated in most cases.</p>
<p>As another example, source spans are really tricky to keep around and get right. (I have thoughts on that – that we shouldnʼt be using source spans! – but thatʼs beside the point.) But imagine if you didnʼt have to do any work to keep them around: the logic of tmTTmt could keep that information around, and generate empty source spans for nodes that are inserted by the compiler. (With some way to optionally borrow source spans from other node(s).)</p>
<p>As a third example of why we should separate data and metadata: if we keep the identity of nodes separate from their raw data, we can keep track of which source terms interact with each other. The better you can keep track of source spans and <em>provenance</em>, the more reliable this system will be. If you keep track of which types are unified with each other, and can map them back to locations in the source, it could even tell you all of the places you need to edit if you want to change the type of something (or where you need to insert conversions).</p>
</div>
<p>If you arenʼt forced to work in the base logic of Haskell, and instead have more freedom to come up with a linguistics and logic of type theory design itself, youʼll get several benefits:</p>
<ul>
<li><p>You donʼt have to rewrite your whole compiler to introduce optimizations, like I mentioned above.</p></li>
<li><p>You could generate graphical representations of the rules, from the exact same source that the program is derived from. This would be fantastic for interactive typechecking rules, which could enhance error messages with the particular rule that failed to be derivable, and allow you to search back through the parts of the derivation that did succeed.</p>
<div class="Bonus">
<p>You may still want separate sets of rules for conventional “paper” presentations, however. Like as a term rewriting system, instead of <span data-t="" data-widget="">NbE</span>, for example. But if both of them are executable, you can test whether they are equivalent! (With QuickCheck, unit tests, or assertions.)</p>
</div></li>
<li><p><a href="https://github.com/dhall-lang/dhall-lang/issues/469">dhall-lang#469: Machine-readable semantics</a></p></li>
</ul>
<h3 id="history">History</h3>
<p>Iʼve been ranting about tmTTmt on cohost as an outlet until I have the time to actually write the darn thing: <a href="https://cohost.org/monoidmusician/tagged/tmttmt"><span class="citation" data-cites="monoidmusician">@monoidmusician</span>/#tmttmt</a>.</p>
<p>The real genesis of the project was when I was attempting to write Dhall-PureScript (many apologies for dropping the ball on that one). I wanted to go all in on extensible row types and recursion schemes. I think theyʼre awesome tools, but they proved too impractical to use in PureScript, since they wrecked the existing pattern matching facilities of the core logic of PureScript. I have also learned a lot in the meantime (<span data-t="" data-widget="">e.g.</span> about parsing, about languages like Erlang) and developed a lot more ideas. I think Iʼm ready to make it happen!</p>
<h2 id="general-design-goals">General design goals</h2>
<ul>
<li>Simple syntax, which can be easily interpreted by other programs in other ways.</li>
<li>Type-directed shenanigans. (Typeclasses, mostly. Also type-directed syntax sugar.)</li>
<li>Algebraic effects, or something. This is necessary for lightweight unification.</li>
<li>Compilation steps to get from that syntax to some core logic/runtime in some language.
<ul>
<li>Desugaring nonlinear patterns into appropriate equality/unification steps.</li>
<li>Desugaring core logic into monads/applicative(/selectives?)</li>
<li>Inlining; removing redundant steps.
<ul>
<li>In particular, it will be the expectation that these operations are safe for any custom monads/effects that users use. As an example, resolving imports in <a href="https://dhall-lang.org/">Dhall</a> requires doing disk access and network requests, but those network requests are cached during resolving, so their resolution is idempotent and redundancies can safely be removed. (And obviously if there are URLs that do not have to be resolved, thatʼs great for efficiency! Although you can argue about safety, which is why these things need to be customizable.)</li>
</ul></li>
<li>Personally I think it would be fun to target PureScript, JavaScript, Erlang … very different needs across each of those.</li>
</ul></li>
<li>Functors! I love functors.</li>
<li>Encourage healthy abstractions. I think thatʼs a great word: <em>healthy</em> abstractions.</li>
<li>I have this idea for a type system and I donʼt know if it will pan out&nbsp;… Something like TypeScript done better (or similar sorts of ad-hoc type systems).</li>
<li>Easy debugging and decent dev UX. Being able to dump terms in a representable/inspectable format. Being able to trace execution and focus logs. Flags to enable/disenable features. Assertions. Idk.</li>
</ul>
<h3 id="specific-design-choices">Specific design choices</h3>
<ul>
<li>Lightweight literals, type-directed.
<ul>
<li><p>A literal is a string or a list of literals or variables. (Basically reinventing lisp lol.)</p></li>
<li><p>Types are basically patterns of literals, meaning literal singleton types plus arrays and unions of types, like TypeScript but hopefully in a sensible way. Thus it is obvious what type a literal has, and then this can be subsumed by other types.</p></li>
<li><p>There are also nominal types; still figuring out the details there. The main goal is to mostly get rid of newtype wrappers, so you can just match on the constructors-as-literals you want through all the cruft. But type annotations will still be necessary to disambiguate types in some cases. And full type annotations are usually tedious, so some system of named coercions may be helpful.</p></li>
<li><div class="Key_Idea">
<p>In particular, by committing ourselves to <em>this</em> logic of <strong>literals as ground truth for comparing <em>across types</em></strong>, we can generate automatic coercions between subsets of complex types.</p>
<p>I understand why a lot of languages want literals to have distinct types (<span data-t="" data-widget="">e.g.</span> Haskell ADTs all have distinct, named constructors), but it just poses a barrier to the fluidity I want to have in this system for language design of all things. If you name something <code class="js">["if" _ "then" _ "else" _]</code> then you know what it represents! No matter if it is in the source CST, the desugared AST, or a final core pass&nbsp;…</p>
</div>
<p>In some target runtimes, if they are faithful to the literals, these will be actual zero-cost coercions. However, because the expectation is that compilation is type-directed and enough type information is available to insert conversions as necessary, there is no reason that they are required to be coercions in implementation.</p></li>
<li><p>Restriction types, of nominal types constrained to fewer possible cases, would be incredibly useful.</p></li>
<li><p><span data-t="" data-widget="">tl;dr</span> is that this should help with the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/11/trees-that-grow.pdf">“trees that grow”</a> problem of multiple related ASTs.</p></li>
<li><p>Iʼm wavering on including records: I think they donʼt mesh well with the system of inference. But there is an alternative, which is to include sort of “grab bags”: where you donʼt pretend to know the totality of the record (in particular, there is no sensible way to implement <code class="haskell">Eq</code> for records), but you have some partial knowledge of what you want to be in there.</p>
<p>In concrete terms, this means that inclusion in the grab bag is the only sensible constraint you get to ask for; you donʼt really get to “delete fields” or “merge” or such.</p></li>
<li><p>Avoiding row types&nbsp;… idk. Row types are great but I think there are enough alternatives in this type theory that they would not be so important. In particular, having union types (and maybe restriction types) means that you can talk about parts of the AST.</p>
<p>If I did have row types, I would want to make sure they are not limited to existing constructs of records and variants (product and sum types), there are so many other symmetric tensors to think about! <span data-t="" data-widget="">E.g.</span> configuration options tend to come as a record of maybes, but sometimes you need a bunch of things tensored together with <code class="haskell">These</code>, so you know that at least one is specified.</p></li>
</ul></li>
<li>Function calls cannot be nested, functions are only applied to literals/variables.
<ul>
<li>This is for two reasons: it makes the syntax lighter, and it means that the user was very specific about the order of execution.</li>
<li>One concrete benefit is that you need much fewer delimiters in the syntax, since each pattern ends at a well-known point.</li>
</ul></li>
</ul>
<h4 id="patterns">Patterns</h4>
<p><a href="https://cohost.org/monoidmusician/post/3252802-first-class-patterns" class="uri">https://cohost.org/monoidmusician/post/3252802-first-class-patterns</a></p>
<ul>
<li><p>We need a way to reflect patterns into values, filling in any variables with default values. This is most useful to implement unification: to unify a term with a pattern, you first replace the variables with unification variables, call the unification function (which has no idea what a pattern is), and then match the pattern against the result.</p>
<p>So if you want to unify <code class="js">T</code> against <code class="js">["tuple" x y]</code>, you first generate two unification variables <code>U1</code> and <code>U2</code>, then run <code class="js">unify T ["tuple" U1 U2] =&gt; R</code> (if <code class="js">T</code> is a unification variable, this will write into state that it is now known to be a tuple!), and finally do regular pattern matching of <code class="js">R</code> against <code class="js">["tuple" x y]</code>, binding <code class="js">x</code> and <code class="js">y</code> to the respective subnodes of <code class="js">R</code>.</p>
<ul>
<li><p>Iʼm not quite sure if this deserves to be called first-class patterns. To be honest, Iʼm not sure what first-class patterns would even mean! But it is very simple, practical, and it does all the things I personally would want out of first-class patterns.</p></li>
<li><p>It is a technique I have also been using in more and more places: in my <a href="https://github.com/MonoidMusician/blog/blob/main/PureScript/src/Parser/Languages/Talk.purs">LR parser combinator framework</a>, and in writing a compiler.</p>
<p>The basic idea is that a <code class="haskell">Pattern</code> or <code class="haskell">Matcher</code> (or whatever you want to call it) is a combination of the shape that it expects (minus actual data), and then what to do once it receives that shape (with the data filled in, producing some arbitrary result). You can combine these applicatively and with other tools (if you can combine the shapes and pick them back apart); it is very useful, even without any language support whatsoever, just DSLs and fancy types. These are basically codecs in a single direction (not bidirectional).</p></li>
</ul></li>
<li><p>Non-linear pattern matching.</p></li>
<li><p>Static evaluation of functions, so they can be considered as macros producing patterns.</p>
<p>This means that they have to reduce to a pattern, without running any effectful functions, and cannot have stuck case matching, and so on.</p></li>
<li><p>Pattern aliases?</p></li>
</ul>
<h3 id="use-cases-to-achieve">Use-cases to achieve</h3>
<ul>
<li><p>Writing down programs in the style of judgment rules for different flavours of typechecking (unification and bidirectional) and normalization (rewrite systems and normalization by evaluation).</p></li>
<li><p>Optimizing these algorithms by applying transformations from the source code to add ~things~. And using the same techniques to add additional metadata, for nice features.</p>
<div class="Bonus" data-box-name="Mini Rant">
<p>This is my problem with a ton of code that gets written, and I am certainly guilty of it too: we get the fundamental logic written, but never get over the hump to the point of providing nice features, in part because the languages/libraries we use do not facilitate the nice features – heck, they even made writing the logic so arduous in the first place that we run out of steam –&nbsp;and partly because, as I have mentioned repeatedly, it would mean touching half of the codebase again just to add fields that none of the existing logic cares about.</p>
<p>Urgh. Letʼs find ways to do better, and create the tools that reflect our values.</p>
<p>… Anyways, back to those use-cases:</p>
</div></li>
<li><p>Trace evaluation of these programs and generate interactive visualizations based on this.</p></li>
<li><p>Generate types for precise errors based on analyzing failure modes of the written logic.</p></li>
<li><p>Working with multiple related AST types. Working with types related in other ways, such as non-empty constraints. (These get pretty onerous to work with, when you have to write completely separate types for non empty things, and make sure you preserve non-emptiness in the right places. Trust me, Iʼve tried!)</p></li>
<li><p>Simplify writing advanced programming techniques:</p>
<ul>
<li>Continuation Passing Style (CPS). This is (apparently) really great for efficiency for a bunch of reasons (<span data-t="" data-widget="">e.g.</span> quicker backtracking), but can be mind-bending to write directly.</li>
<li>Deriving zippers/one-hole contexts for datatypes, possibly even <a href="http://strictlypositive.org/CJ.pdf">Clowns &amp; Jokers</a> style for incremental stack-safe computations. (One-hole contexts are possible to derive generically with typeclass machinery. But the conversions get super annoying…)</li>
<li>Functional Reactive Programming (FRP). Existing FRP frameworks are&nbsp;… alright. But none really capture the right logic/linguistics to make it easy.</li>
<li>Incremental computation. I mean&nbsp;… just imagine an incremental compiler, where trivial refactors donʼt cost any time, changing constants in the source code changes them directly in the compiled artefacts, and other tasks scale proportionally to the amount of things they actually affect.</li>
<li>“Free” constructions (I mean, minus laws, since we donʼt have quotients). These are just so difficult to make, with a lot of boilerplate.</li>
<li>Codecs. Parsing. I love parsers so it would be great to integrate them. Maybe even into the type theory! (It is apparently possible to algorithmically decided whether one regular expression is contained in another uwu :3.)</li>
<li>STM. Eventual consistency. Other lattice-y stuff.</li>
<li>Parallel evaluation, à la <code class="haskell">unamb</code> or so.</li>
</ul></li>
<li><p>Idiolects?</p>
<ul>
<li><p>Providing N×M variations of APIs is annoying:</p>
<pre class="purescript"><code>setPrecA :: forall rec err prec nt cat o. cat -&gt; Associativity -&gt; prec -&gt; Comb rec err prec nt cat o Unit
setPrecA cat assoc prec = case pure unit of
  Comb c -&gt; Comb c { tokenPrecedence = [cat /\ (prec /\ assoc)] }

setPrecL :: forall rec err prec nt cat o. cat -&gt; prec -&gt; Comb rec err prec nt cat o Unit
setPrecL = setPrecA &lt;@&gt; AssocL
setPrecR :: forall rec err prec nt cat o. cat -&gt; prec -&gt; Comb rec err prec nt cat o Unit
setPrecR = setPrecA &lt;@&gt; AssocR
setPrec :: forall rec err prec nt cat o. cat -&gt; prec -&gt; Comb rec err prec nt cat o Unit
setPrec = setPrecA &lt;@&gt; NoAssoc

tokenPrecA :: forall rec err prec nt cat o. Token cat o =&gt; cat -&gt; Associativity -&gt; prec -&gt; Comb rec err prec nt cat o o
tokenPrecA cat assoc prec = setPrecA cat assoc prec *&gt; token cat

tokenPrecL :: forall rec err prec nt cat o. Token cat o =&gt; cat -&gt; prec -&gt; Comb rec err prec nt cat o o
tokenPrecL = tokenPrecA &lt;@&gt; AssocL
tokenPrecR :: forall rec err prec nt cat o. Token cat o =&gt; cat -&gt; prec -&gt; Comb rec err prec nt cat o o
tokenPrecR = tokenPrecA &lt;@&gt; AssocR
tokenPrec :: forall rec err prec nt cat o. Token cat o =&gt; cat -&gt; prec -&gt; Comb rec err prec nt cat o o
tokenPrec = tokenPrecA &lt;@&gt; NoAssoc</code></pre>
<p>Does reifying the arguments as a datatype with super lightweight syntax do what we need? maybe&nbsp;…</p></li>
<li><p>Would be nice to have ways to say “add a precedence to <em>this</em> (whatever it is)” or “add a name to <em>that</em>”. Idk.</p></li>
</ul></li>
</ul>
<h2 id="non-goals">Non-goals</h2>
<ul>
<li>Not intended to support dependent types or any theorem proving features.</li>
<li>This is not intended to be a logic language, although it could be compiled to a logic language. Thus we will not expect to be doing proof search during execution. (Arguably could be doing proof search during compilation.)</li>
<li>Similarly: not interested in baking in unification. That can (and should) be provided by users; the goal is to make the syntax lightweight enough to facilitate it.</li>
<li>Probably not going to have Rank-N types for a while, if ever. I mean, I like Rank-N types, especially for APIs, but most things end up being better expressed by inductive data types, and this way I have a type inference algorithm that is actually tractable&nbsp;…</li>
</ul>
<h2 id="more-details">More Details</h2>
<p>(A separate section so I donʼt bury <a href="#non-goals">Non-goals</a>)</p>
<h3 id="abstractions-i-want">Abstractions I want</h3>
<p>Worship the shape of data and the structure of code …</p>
<ul>
<li>Any metatheory that makes dealing with variable binding easier is worth a lot!
<ul>
<li>What I did in Dhall-PureScript: <a href="https://github.com/MonoidMusician/dhall-purescript/blob/469c3e10d51a8afb90f2e231cf3e6101f50814eb/src/Dhall/Variables.purs#L119-L201">Dhall/Variables.purs</a> This just does basic bookkeeping of when variables are bound, based on the functors I used in the recursion schemes, but I think it proved to do most of what I needed.</li>
<li><div class="Bonus" data-box-name="Aside">
<p>The other, silly solution, is to commit to only having one binder: lambda, and phrasing pi in terms of lambda. I convinced myself it works out on paper but I got a little stuck trying to prove it to Agda. Heh heh heh&nbsp;…</p>
</div></li>
</ul></li>
<li>Container functors, the building blocks of an AST.
<ul>
<li><code class="haskell">traverseWithIndex :: (i -&gt; a -&gt; m b) -&gt; (f a -&gt; m (f b))</code></li>
<li><code class="haskell">mergeWith :: (i -&gt; a -&gt; b -&gt; c) -&gt; f a -&gt; f b -&gt; Maybe (f c)</code>
<ul>
<li>I believe that we need a lot more binary operations like this, for matching on two shapes at once! It is not something that is covered by recursion schemes for example. <code class="haskell">Data.Map</code> has a terrible interface (<code class="haskell">unionWith</code> is so bleh).</li>
</ul></li>
<li><a href="https://github.com/MonoidMusician/dhall-purescript/blob/main/src/Dhall/Core/Zippers.purs">Zippers/one-hole contexts</a> (optional – I never actually used them in Dhall-PureScript, but they could be useful for some things):
<ul>
<li><code class="haskell">upZF :: ZF f' x -&gt; f x</code></li>
<li><code class="haskell">downZF :: f x -&gt; f (ZF f' x)</code></li>
<li><code class="haskell">ixF :: f' x -&gt; i</code></li>
</ul></li>
</ul></li>
<li>Array stuff
<ul>
<li>normal <code>zipWith</code></li>
<li>“long” <code>zipWith</code></li>
<li><code>takeWhileJustWithRest :: (a -&gt; Maybe b) -&gt; Array a -&gt; (Array b, Array a)</code>
<ul>
<li>some kind of condensor pattern</li>
</ul></li>
<li>something better than <code>mapAccumL</code>/<code>mapAccumR</code> lol
<ul>
<li>every time I want to reach for a stateful traversal, I find it so annoying!</li>
</ul></li>
<li>maybe some actual parser type thing</li>
</ul></li>
</ul>
<h3 id="examples">Examples</h3>
<p><em>~Disclaimer that I use typechecking and type inference interchangeably.~</em></p>
<h4 id="typechecking-lists">Typechecking lists</h4>
<p>I think it is <em>very <strong>very</strong></em> useful to move from thinking of unification as a binary operation to it as a N-ary operation. As one example, consider (homogeneous) list literals.</p>
<p>The way a lot of typecheckers work when inferring list literals is that it assumes the first item has the right type, and then it typechecks the remaining items against it. But what if it is the first item that has the wrong type, and all 12 other items are actually right? I believe it is best to typecheck each term in isolation, then see if the results can be unified all at once – and then unify the unification states, since unification variables may have been unified in inconsistent ways. (This requires unification state to be <code class="haskell">WriterT</code> not <code class="haskell">StateT</code>. Yeah.)</p>
<pre class="js" data-lang="tmTTmt"><code>typecheck/ ["ListLiteral" items] =&gt; ["App" "ListType" itemType]
  map typecheck items =&gt; itemTypes
  ensureConsistency itemTypes =&gt; itemType</code></pre>
<h4 id="typechecking-non-dependent-pi-types">Typechecking non-dependent pi types</h4>
<p>I would like to be able to short-circuit typechecking non-dependent functions, and return a result even if the argument is ill-typed or does not have the correct type.</p>
<p>(Why? Because having a more global view of errors is often useful, since the hyperlocal errors we are used to can obscure the real problem.)</p>
<p>This would show up as a soft error that allows further typechecking to proceed. Soft errors can be turned into critical errors when we need to be able to trust the result of typechecking, <span data-t="" data-widget="">e.g.</span> to know that normalization is going to complete.</p>
<pre class="js" data-lang="tmTTmt"><code>typecheck/ ["App" fn arg] =&gt; resultType:
  // Unifies the result with a "Pi" type
  typecheck fn =&gt; ["Pi" binder domain codomain]
  // See if `codomain` does not in fact depend on `binder`
  tryApplyConstant binder codomain
  ? ["constant" resultType]:
    // `resultType` got assigned, so this case is not necessary to produce
    // *some* result that can inform further type errors, though this node does
    // not truly typecheck if it fails:
    typecheck arg =&gt; domain
    // `domain` is a non-linear pattern match, unifying `argType` and `domain`
    // (any further references to `domain` would refer to the unified node)
  ? ["non-constant"]:
    // Typecheck the argument in strict mode to ensure that type errors result
    // in an immediate failure even if an approximate result can be computed:
    strictly ([] =&gt; typecheck arg) =&gt; domain
    // (Unification with `domain` is always strict, it never adds soft errors.)

    // Now that it is safe to compute with `arg`, we apply it to compute the
    // result type:
    substitute binder arg codomain =&gt; resultType
  !

// Probably should simplify this somehow ...</code></pre>
<div class="Note" data-box-name="Aside">
<p>Is this good notation for lambdas as arguments to functions? I donʼt know.</p>
<pre class="js" data-lang="tmTTmt"><code>  strictly | [] =&gt; r:
    typecheck arg =&gt; r
  ! =&gt; domain</code></pre>
<p>Macros for currying?</p>
<pre class="js" data-lang="tmTTmt"><code>asdf (!2 append !1 !0 !)</code></pre>
<p>I want to avoid some problems:</p>
<ul>
<li>Indentation. Figuring out how to indent lambdas as arguments to functions is so annoying.</li>
<li>Related: figuring out where the lambdas end is also annoying. I do like dangling lambdas actually.</li>
</ul>
<pre class="js" data-lang="tmTTmt"><code>["if" ($matches-tag arg1) (: MyExprType) "then" "true" "else" ($failed-match)]</code></pre>
</div>
<pre class="haskell"><code>-- The behavior of `select` for the typechecker monad/thingy is that if the
-- first computation returns a `Left`, it will accumulate errors from the second
-- computation, instead of failing and blocking computation like `&gt;&gt;=`.
--
-- In particular, it does accumulate errors from `strictly`, in that case.
select :: f (Either b a) -&gt; f (a -&gt; b) -&gt; f b
strictly :: f a -&gt; f a
tryApplyConstant :: Binder -&gt; Type -&gt; Maybe Type

typecheck :: Type -&gt; f Type
typecheck (App fn arg) =
  select
    ( typecheck fn &gt;&gt;= \fnType -&gt;
        unifyPi fnType &gt;&gt;= \binder domain codomain -&gt;
          case tryApplyConstant binder codomain of
            Just r -&gt; Left r
            Nothing -&gt; Right Unit
    )
    ( strictly $ typecheck arg &gt;&gt;= \argType -&gt;
        unify argType domain &lt;#&gt; \_unified -&gt;
          apply binder arg codomain
    )</code></pre>
<h2 id="development">Development</h2>
<p>For ease of development I am just embedding it as part of the <a href="https://github.com/MonoidMusician/blog/tree/main/PureScript/src/Parser/Languages/TMTTMT">the code for my blog</a>.</p>
<p>I have a rough parser (needs to be updated) using my parser combinator library, yay.</p>
<p>Working on the type system currently: starting with structural types. Then need nominal types, constraints, effects, polymorphism, …</p>
<p>The evaluator needs local variables.</p>
<h3 id="types">Types</h3>
<p>Implementing the basic structural type system for tmTTmt. Basically composed of unions of structural types in the language of JSON, including singletons, tuples, (non-empty) lists, and (non-empty) strings. (No objects, yet – those require constraints.) Oh, and functions, though you cannot interact with those via pattern matching (no view patterns!).</p>
<p>Enter a type in the top box and some patterns in the bottom box, and it will show you the type that each pattern matches (and the types of the variables it binds), and it will show you the refined type of the leftover <em>non</em>-match at the end. (Currently does not handle the fact that non-linear pattern matches should not refine the type … or something. Idk how exhaustivity checking is going to work tbh.)</p>
<div class="widget" data-widget="Parser.Main.TMTTMT.TypeSplit" data-widget-loading="true" style="display: contents">

</div>
<p>The rough grammar for types:</p>
<pre class="bnf"><code>ty =
  | '[' ty+ ']' -- fixed-size tuple
  | '+' ty -- non-empty list
  | '*' ty -- sugar for `'+' ty '|' '[' ']'`
  | ty '|' ty -- union
  | '$$' -- non-empty strings
  | '$' -- strings, sugar for `'$$' '|' '"' '"'`
  | '"' strchar* '"' -- string literal
  | ty '-&gt;' ty -- function type
  | name -- type variable
  | '(' ty+ ')' -- type application
  | '(' '?' ty+ ')' -- type hole
  | '(' '|' ')' -- empty type (Void/never)</code></pre>
<details class="Example">
<summary>
Example types
</summary>
<pre class="tmttmt"><code>(# primitive #)
#type Void = (|)

#type Unit = []

#type Wrap a = [a]

(# sugar for `$$ | ""` #)
#type String = $
(# primitive #)
#type NEString = $$

(# `Maybe a` can be coerced to `List a` #)
#type Maybe a = [] | [a]

Maybe2List : forall a. Maybe a -&gt; List a
Maybe2List a =&gt; a

(# sugar for `+a | []` #)
#type List a = *a
(# primitive #)
#type NEList a = +a

#type Cons a = [] | [a (Cons a)]
#type Snoc a = [] | [(Snoc a) a]

#type Endo a = a -&gt; a

#type Tuple a b = [a b]

#type Either a b =
  | ["L" a]
  | ["R" b]

(# newtype (once I have nominal types) #)
#type Validation a b = Either a b

#type These a b =
  | Either a b
  | ["B" a b]

(# strings and lists, recursively #)
#type AnyData =
  | $
  | *AnyData

(# strings, lists, and functions, recursively #)
(# for an untyped language #)
#type UniType =
  | AnyData
  | (UniType -&gt; UniType)

(# sorry not sorry #)
(# (you will appreciate me later) #)
#type Nat = [] | [Nat]</code></pre>
</details>
<p>Check whether one type is a subtype of another:</p>
<div class="widget" data-widget="Parser.Main.TMTTMT.SubType" data-widget-loading="true" style="display: contents">

</div>]]></description>
</item>
<item>
<title>The Best Errors for Solving Dependency Versions</title>
<pubDate>Sat, 21 Jan 2023 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/version_solver.html</guid>
<description><![CDATA[<div class="Bonus" data-box-name="Backstory">
<blockquote>
<p>Just copy the <a href="https://github.com/elm/compiler/blob/0.19.1/builder/src/Deps/Solver.hs">Elm version solver</a> from Haskell to PureScript, itʼll be easy.</p>
</blockquote>
<p>Uh huh. Totally.</p>
<blockquote>
<p>Oh we need good errors too.</p>
</blockquote>
<p>Yup. Thought so.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</div>
<p>And so the feature creep started&nbsp;… but the journey was <em>so</em> worth it.</p>
<p>How did I get here and what did I come up with?</p>
<div class="Key_Idea" data-box-name="tl;dr">
<p>A <a href="https://github.com/purescript/registry-dev/blob/master/lib/src/Solver.purs">novel algorithm</a> for resolving dependency bounds to solved versions:</p>
<ul>
<li>Incorporates <a href="#intuitive-foundations-quasi-transitive-dependencies">transitive dependency bounds</a> for a breadth-first search:
<ol type="1">
<li>What dependencies are required no matter which package version in the range we commit to?</li>
<li>Whatʼs the loosest bound for each dependency then?</li>
</ol></li>
<li>By taking this intuitive approach, we gain two things:
<ol type="1">
<li><a href="#errors">Better errors</a>, matching what users would expect.</li>
<li>Efficiency too, if you could believe it.</li>
</ol></li>
<li>Implemented using semilattices (<a href="#monoids-monoids-everywhere">monoids</a>).</li>
</ul>
</div>
<p>(I know youʼre probably not going to read this whole long article and <a href="#errors">Errors</a> is the very last section, but please feel free to skip ahead to that one since that was the whole point of this exercise!)</p>
<h2 id="background">Background</h2>
<h3 id="the-purescript-registry">The PureScript registry</h3>
<p>The PureScript community has been designing a new registry to hold PureScript packages for some time now. PureScript projects initially used <a href="https://bower.io/">Bower</a> (a defunct npm competitor for Node.js packages), and I embarrassingly hung on to Bower until just last year. Most of the community, however, has been using <a href="https://github.com/purescript/spago">Spago</a>, a PureScript build tool supporting package sets (fixed versions of packages that are known to be compatible). Long story, but some core members have been designing a <a href="https://github.com/purescript/registry">new registry</a> to house current and historical PureScript packages. Weʼre very close to releasing it!<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>In the interest of maintaining a healthy ecosystem, we want the new registry to support not just package sets but also traditional version solving. And thatʼs where I came in. Something about my mathy skills being a perfect fit for getting <a href="https://xkcd.com/356/">nerd-sniped</a> by a version solving algorithm. Oh and would you help fix the <a href="https://github.com/purescript/registry-dev/pull/580">versioning issues for legacy packages</a> while youʼre at it? Sure, sure I will.</p>
<h3 id="version-solving">Version solving</h3>
<p>The challenge of version solving in a package ecosystem is coming up with particular version of packages that satisfy not only the dependencies of the current project, but their own dependencies too. You also want to ensure they are up-to-date by taking the latest possible versions – but sometimes those are not compatible with other declared dependencies. The problem is expected to be difficult and slow to solve in general, but it is possible to optimize for what package dependencies look like in practice, and that is what I have done.</p>
<h4 id="details-of-versions-and-version-ranges">Details of versions and version ranges</h4>
<p>Quick notes on conventions/terminology before we get too far in:</p>
<p>The actual details of how versions are tagged doesnʼt matter, just that they are totally ordered.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> For example, it could just be flat integers for all we care. But usually we take them to be lexicographically-ordered lists of integers, like <code class="boo">5.0.3</code> which is less than <code class="boo">5.1.0</code>.</p>
<p>How we form <em>ranges</em> over versions is pretty important, though, and early on the registry decided to only allow half-open intervals. That is, ranges have the form <code class="boo">&gt;=A.B.C &lt;X.Y.Z</code>, which I will use throughout this article. Again, it isnʼt very sensitive to details here (who cares that it is half-open?), but this does seem to be the right level of generality. Supporting more complex queries is asking for trouble.</p>
<p>Finally, from a version-solving point of view, a registry contains information of what versions of packages there are, and for each package version a record of what dependencies it requires and the appropriate version ranges for those packages. That is, it can be represented with the following PureScript datatype:</p>
<pre class="purescript"><code>-- A list of required dependencies
-- with their version ranges
type Manifest = Map PackageName Range

-- A list of all extant package versions
type RegistryIndex =
  Map PackageName
    (Map Version Manifest)</code></pre>
<h4 id="the-problem-statement">The problem statement</h4>
<p>Solving means taking a manifest and finding versions for each package in it, preferring later versions<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>:</p>
<pre class="purescript"><code>solve
  :: RegistryIndex
  -&gt; Manifest
  -&gt; Either SolverErrors
      (Map PackageName Version)</code></pre>
<p>Along with some correctness constraints to ensure it is the solution we want.</p>
<details class="Details" data-box-name="CSS">
<summary>
Correctness constraints
</summary>
<pre class="purescript"><code>let r :: RegistryIndex
let m :: Manifest
let otherSol :: Map PackageName Version

-- We need the solution to solve the manifest and dependency's requirements
isASolutionFor r m (fromRight (solve r m)) &amp;&amp;
-- There are no strictly better versions to be found
( isASolutionFor r m otherSol
  `implies` isn'tWorseSolutionThan otherSol (fromRight (solve r m))
)
where
satisfies
  :: Map PackageName Version
  -&gt; Map PackageName Range
  -&gt; Boolean
satisfies sol m =
  allWithIndex
    ( \package range -&gt;
        case Map.lookup package sol of
          Nothing -&gt; false
          Just version -&gt; range `includes` version
    )
    m

isASolutionFor
  :: RegistryIndex
  -&gt; Manifest
  -&gt; Map PackageName Version
  -&gt; Boolean
isASolutionFor r m sol = and
  -- All packages received a version
  [ Map.keys m `isSubsetEqOf` Map.keys sol
  -- All solved versions fit into the range
  -- as required in the manifest
  , sol `satisfies` m
  -- All packages have their dependencies satisfied
  , allWithIndex
      ( \package version -&gt;
          case Map.lookup package r &gt;&gt;= Map.lookup version of
            Nothing -&gt; false
            Just deps -&gt;
              sol `satisfies` deps
    )
    sol
  ]

isn'tWorseSolutionThan :: Map PackageName Version -&gt; Map PackageName Version -&gt; Boolean
isn'tWorseSolutionThan other optimal =
  Maps.keys optimal `isSubsetEqOf` Map.keys other
  &amp;&amp; not allWithIndex
    ( \package version -&gt;
        case Map.lookup package other of
          Nothing -&gt; true

    )
    optimal
  -- FIXME</code></pre>
</details>
<h4 id="dependencies-are-tricky">Dependencies are tricky</h4>
<p>In particular, note that dependencies are associated with a particular <em>version</em>. A package <em>range</em> doesnʼt need to have well-defined dependencies at all!</p>
<p>This is something that we forget about when using packages in our day-to-day lives, but an algorithm needs to handle all cases we could throw at it.</p>
<h2 id="depth-first-backtracking-algorithm">Depth-first backtracking algorithm</h2>
<p>As I alluded to in the intro, I started off by copying <a href="https://github.com/elm/compiler/blob/0.19.1/builder/src/Deps/Solver.hs">Elmʼs version solving algorithm</a>. Itʼs a very simple depth-first backtracking algorithm:</p>
<ol type="1">
<li>Try the latest compatible version of the package in front of you, based on the global requirements</li>
<li>Add its dependency ranges to the global requirements<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></li>
<li>Recursively see if the new global requirements can be solved</li>
<li>Backtrack to the next latest version at each failure.</li>
</ol>
<p>Itʼs easy to see why this is worst-case exponential, and not going to hit fast cases particularly often. In fact, we expect the problem to remain worst-case exponential, but spoiler: we can do much better in most reasonable cases!</p>
<p>Besides performance, the main obstacle I wrestled with was that it had no errors. It turns out these are related concerns: because the algorithm is so naïve, it isnʼt making use of available information to make smart choices, and this would reflect in the errors it could produce.</p>
<h3 id="errors-for-a-backtracking-algorithm">Errors for a backtracking algorithm</h3>
<p>I discovered that this problem of solving package versions corresponds well to what I have been thinking about in terms of compiler/typechecker errors for the past couple years. So thereʼs some good lore here on what I believe errors should look like, but thatʼs for another post.</p>
<p>Basically, good errors should be a faithful reflection of the internal logic of the solver. This is the main hint that performance and errors are linked: if the solver is trying too many bad options, itʼs going to generate a ton of errors for all of those choices. These errors are bad because they mainly reflect bad choices of the solver, not necessarily problems with the underlying data (the manifests). Itʼs only once <em>every option</em> has failed that you know that the underlying manifests were not compatible. Our goal later, then, will be to reduce the number of choices to make and commit to errors as soon as possible.</p>
<p>The second problem with the errors is that the naïve backtracking does a <em>lot</em> of duplicate work, in between choices of packages. In the worst case scenario, two package versions have the same manifests, so trying them separately will duplicate most of the work!<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>It is possible to deduplicate errors after the fact, but those heuristics seem complex in general, and there are two problems still:</p>
<ol type="1">
<li>Youʼve already lost the performance associated with the duplicate work, and are spending more time trying to fix it</li>
<li>You might as well write the algorithm to incorporate the deduplication in the first place!!</li>
</ol>
<p>There are some existing approaches to increase sharing/reduce duplicate work, in the context of general constraint solving and more particularly version solving with these type of bounds. I briefly glanced at them, but they donʼt seem to address the heart of the issue like my algorithm does.</p>
<h4 id="algebraic-errors">Algebraic errors</h4>
<p>In a solver algorithm, we write programs in terms of some error monad. The backtracking algorithm essentially corresponds to a complicated Boolean expression, a tree of various constraints joined with conjunction and disjunction. Thinking of it as <code class="purescript">Applicative</code>+<code class="purescript">Alternative</code>, we see that <code class="purescript">&lt;*&gt;</code> corresponds to conjunction <code class="purescript">&amp;&amp;</code> and <code class="purescript">&lt;|&gt;</code> corresponds to disjunction <code class="purescript">||</code>.</p>
<pre class="boo"><code>console &gt;=5.0.0 &lt;6.0.0

(console == 5.0.0 &amp;&amp; prelude &gt;=5.0.0 &lt;6.0.0)
|| (console == 5.0.1 &amp;&amp; prelude &gt;=5.0.1 &lt;6.0.0)</code></pre>
<p>An error, then, is some kind of proof that the Boolean always evaluates to false. SAT solvers have done a great job of doing this in the general case. And you can think a bit about what this means.</p>
<p>In addition to the literal Boolean clauses, we want the errors to record some <a href="#provenance">additional metadata</a> about where they came from: particular manifests and the current dependency from the manifest we are trying to solve.</p>
<h3 id="drawbacks-of-depth-first">Drawbacks of depth-first</h3>
<p>However, we can only do so much: we remain limited to the logic of the algorithm. With a depth-first algorithm in particular, the errors donʼt convey the global picture that the user is looking for.</p>
<p>I mean, you <em>can</em> report these kinds of Boolean clause errors, but they are so confusing that you might as well just throw up your hands and say “I tried something and it didnʼt work.” Thatʼs all the user would get from the errors anyways, since thatʼs really all the algorithm did: It started with an essentially random package, committed to a version of it immediately, tried other things as a consequence, and eventually reported that nothing worked.</p>
<p>So, since my goal was better errors, <a href="https://github.com/purescript/registry-dev/pull/496#issuecomment-1225145757">my next idea</a> was to try to patch it to <em>run</em> the depth-first backtracking algorithm, but create a post-mortem analysis to <em>report</em> more sensible errors. For example, from the Boolean algebra perspective, you can do basic tricks to factor out common sub-expressions, which you can combine with what you know about comparing versions to ranges.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>I couldnʼt bring myself to write that. So I just wrote a novel breadth-first algorithm.</p>
<p>I spent a significant chunk of time writing it. I spent several weekends debugging its performance.</p>
<p>And the results are amazing. <em>/me pats self on back</em></p>
<h2 id="my-breadth-first-algorithm">My breadth-first algorithm</h2>
<p>Hereʼs where I admit my biggest weakness: prior art. I have a great difficulty reading existing research on some topics. Especially when the problem is so obviously begging for a nice solution like this! Itʼs easier to work out the details for myself to be honest. And then blog about it so that people who are <em>not</em> like me learn what I have done. (Apologies to those who are like me who will never read this and perhaps reinvent it. Godspeed.)</p>
<p>I spent a couple months designing a whole new algorithm from scratch. The basic idea is that we gather as much information we can before committing to any versions. This is done through the use of what I have coined as <a href="#intuitive-foundations-quasi-transitive-dependencies">quasi-transitive dependencies</a>.</p>
<div class="Details" data-box-name="Overview">
<p>The main steps are:</p>
<ol type="1">
<li>Load the slice of the registry index that we care about: package versions that are transitively reachable from the package ranges mentioned in the current manifest.</li>
<li>Gather information about <em>quasi-transitive</em> dependencies for manifests in the registry as well as the current manifest we are solving, looping until there is no more obvious information to discover.</li>
<li>Check if the requirements have hit an error in the requirements already.</li>
<li>If not, check if we have solved it: do all the latest versions of requirements work as a solution?</li>
<li>Only as a last resort do we succumb to picking a package and recursively solving each of its versions, starting from the latest.</li>
</ol>
<p>Note that the quasi-transitive dependencies check essentially commits to unique versions immediately, so by the time we reach step 5 we know that there are at least two possible versions of some dependency and are forced to commit to one to make progress. It turns out that in practice, we already hit errors before we have to do that, so weʼve avoided the worst of the exponential blowup!</p>
<p>You can <a href="https://github.com/purescript/registry-dev/blob/30a88ac7bd48a73bb2bcf9240b20b09a713ee0b9/lib/src/Solver.purs#L249-L289">read these steps in the code directly</a>.</p>
</div>
<h3 id="intuitive-foundations-quasi-transitive-dependencies">Intuitive foundations: quasi-transitive dependencies</h3>
<p>Recall what I said in <a href="#dependencies-are-tricky">Dependencies are tricky</a>: “A package <em>range</em> doesnʼt need to have well-defined dependencies at all!” Oh – but they often <em>do</em> in practice.</p>
<p>If we can get extra knowledge about requirements before committing to any particular versions, we have a chance at implementing some sort of breadth-first search.</p>
<p>How much extra knowledge we obtain depends on how packages treat their dependency bounds in the registry. In the case of how PureScript packages tend to bound dependencies, it turns out to be a lot of knowledge. This is because most stable PureScript libraries update with each breaking compiler release and depend on the corresponding major version range of <code>prelude</code> and various other core packages. Since a lot of versions move in lockstep, it is pretty safe to assign loose dependencies to a package range and even reach for further transitive dependencies.</p>
<p>In general, when bumping minor and patch versions, packages tend to keep the same list of dependencies at similar version ranges. Things are a bit more chaotic between major versions, but it is rarer that packages allowed different major versions in their manifests in the first place, and so there is some semblance of continuity.</p>
<p>Now we need to use this to our advantage:</p>
<div class="Key_Idea">
<p>The idea is that we come up with <em>quasi-transitive dependencies</em> for a package range – a lower bound of the absolutely necessary requirements that follow from a package <em>range</em> being required.</p>
<p>There are two rules here:</p>
<ol type="1">
<li>If a package is not required by all versions in the range, we cannot say it is required overall.</li>
<li>When it <em>is</em> depended on by all versions in a range, we take the loosest bounds we see: the lowest lower bound and the greatest upper bound.</li>
</ol>
</div>
<p>It turns out that we can formulate this rule as a <a href="https://pursuit.purescript.org/packages/purescript-functors/5.0.0/docs/Data.Functor.App#v:semigroupApp">semigroup instance</a> that applies the logic for us to a collection of manifests:</p>
<pre class="purescript"><code>instance Semigroup (App (Map PackageName) Loose) where
  append (App m1) (App m2) = append &lt;$&gt; m1 &lt;*&gt; m2

foldMap1
  :: NonEmptyArray (App (Map PackageName) Loose)
  -&gt; App (Map PackageName) Loose

instance Coercible Manifest (App (Map PackageName) Loose)</code></pre>
<p>Note that this is in fact not a monoid: <a href="https://pursuit.purescript.org/packages/purescript-ordered-collections/docs/Data.Map#t:Map"><code class="purescript">Map</code></a> only has an <a href="https://pursuit.purescript.org/packages/purescript-prelude/docs/Control.Apply#t:Apply"><code class="purescript">Apply</code></a> instance (which gives the <code class="purescript">&lt;*&gt;</code> operator to merge common keys), not <a href="https://pursuit.purescript.org/packages/purescript-prelude/docs/Control.Applicative#t:Applicative"><code class="purescript">Applicative</code></a> (which would give <code class="purescript">pure</code> but does not make sense for <code class="purescript">Map</code> since it would have to contain <em>all</em> possible keys!).</p>
<p>As a further optimization, while we are checking package versions, we may discard those that do not solve due to an obvious conflict. This may seem strange: In the PureScript registry, each package will solve individually, we check that on upload. But given the additional constraints of a particular manifest we are solving, we may end up with conflicts against various package versions that are incompatible with the global requirements, especially as we continue to aggregate quasi-transitive dependencies.</p>
<pre class="purescript"><code>-- | We record what dependency ranges are required no matter which version
-- | of the package we pick from the registry. That is, we report the loosest
-- | bounds when all packages report a bound for it. By filling in transitive
-- | dependencies on the registry itself, then, these bounds become more
-- | accurate.
-- |
-- | Also note that removing the redundant requirements via `addFrom` is safe
-- | with the assumptions here: if one local requirement is equal to or looser
-- | than a global requirement, then this result here would also be equal to or
-- | looser than the global requirement.
commonDependencies
  :: TransitivizedRegistry
  -&gt; PackageName
  -&gt; Intersection
  -&gt; SemigroupMap PackageName Intersection
commonDependencies registry package range =
  let
    inRange =
      getPackageRange registry package range
    solvableInRange =
      Array.mapMaybe (traverse toLoose) (Array.fromFoldable inRange)
  in
    case NEA.fromArray solvableInRange of
      Nothing -&gt; mempty
      Just versionDependencies -&gt;
        case NEA.foldMap1 App (un SemigroupMap &lt;$&gt; versionDependencies) of
          App reqs -&gt;
            SemigroupMap $ reqs &lt;#&gt; asDependencyOf range &lt;&lt;&lt; fromLoose</code></pre>
<h4 id="composing-relations">Composing relations</h4>
<p>This quasi-transitive dependency business looks a bit like a familiar formula: the composition of two relations in logic.</p>
<div class="Details">
<p>Phrased in terms of set theory, <a href="https://en.wikipedia.org/wiki/Composition_of_relations#Definition">Wikipedia says</a>:</p>
<blockquote>
<p>If <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⊆</mo><mi>X</mi><mo>×</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">R \subseteq X \times Y</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⊂</mo><mi>Y</mi><mo>×</mo><mi>Z</mi></mrow><annotation encoding="application/x-tex">S \subset Y \times Z</annotation></semantics></math></span> are two binary relations, then their composition <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo separator="true">;</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">R;S</annotation></semantics></math></span> . . . is defined by the rule that says <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>R</mi><mo separator="true">;</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">(x,z)\in R;S</annotation></semantics></math></span> if and only if there is an element <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">y\in Y</annotation></semantics></math></span> such that <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mtext> </mtext><mi>R</mi><mtext> </mtext><mi>y</mi><mtext> </mtext><mi>S</mi><mtext> </mtext><mi>z</mi></mrow><annotation encoding="application/x-tex">x\,R\,y\,S\,z</annotation></semantics></math></span> (that is, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">(x,y)\in R</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">(y,z)\in S</annotation></semantics></math></span>).</p>
</blockquote>
</div>
<p>The key part here is that we take our input and our output and we ask: is there something <em>in the middle</em> that serves to connect the input to the output? (Thinking of relations as boxes that connect certain inputs to certain outputs.)</p>
<p>However, we arenʼt dealing with general relations here, weʼre only dealing with half-open intervals. Weʼre asking: for a version <em>range</em>, what <em>range</em> is constructed by taking the ranges of <em>each version</em> in the middle?</p>
<p>To be a bit more direct with this analogy, a relation <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>⊆</mo><mi>X</mi><mo>×</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">R \subseteq X \times Y</annotation></semantics></math></span> can equivalently be written as <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∈</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>X</mi><mo>×</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R \in \mathcal{P}(X \times Y)</annotation></semantics></math></span>. (<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{P}(Z)</annotation></semantics></math></span> here is the powerset monad <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>Z</mi><mo>→</mo><mtext>Prop</mtext></mrow><annotation encoding="application/x-tex">\mathcal{P}(Z) = Z \to \textrm{Prop}</annotation></semantics></math></span>, which consists of all subsets of the given set <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span>.) And by currying, this can be viewed as <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>∈</mo><mi>X</mi><mo>→</mo><mi mathvariant="script">P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R \in X \to \mathcal{P}(Y)</annotation></semantics></math></span>. This construction <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>→</mo><mi>M</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X \to M(Y)</annotation></semantics></math></span> for a monad <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span> is called the Kleisli category. So now the question is: do intervals also form a monad, by taking loose bounds?</p>
<p>The easy answer is that we can certainly think of it as an approximation on top of the underlying set-relation model. That is, we know how to make intervallic dependencies a relation, so we compose them as relations and then take the smallest interval that contains every interval we came across.</p>
<p>Perhaps there is a way to categorify it directly, I donʼt know. We can come up with an identity, but Iʼm not so sure that associativity would hold.</p>
<div class="Details" data-box-name="Clarification">
<p>To see how it fits. Unit -&gt; Package X range -&gt; Package Y range (X depends on Y)</p>
<p>Thatʼs only dealing with versions of a single package. Bundle it together.</p>
</div>
<h3 id="implementing-it">Implementing it</h3>
<p>The core backtracking algorithm actually still exists in the spine of the solver, but its role is greatly reduced. In fact, this has a funny implication for testing the algorithm: <em>the correctness is visible not in finding the right solutions but in the algorithmʼs efficiency and errors.</em></p>
<p>The literal results of the solver were accurate all along. But when I finally got it working <em>fast</em>, I knew all my logic was in place for all the intermediate steps. In particular, this means that we preempted most of the (exponential) backtracking.</p>
<h4 id="monoids-monoids-everywhere">Monoids, monoids everywhere</h4>
<p>Again, a topic for another blog post, but I love monoids, especially semilattices, because they capture information gathering in ways that lend themselves to reliable implementation.</p>
<p>In particular, because of their idempotence, semilattices are great because you just need to make sure you cover all cases. Thereʼs no such thing as double-counting in a semilattice computation! When youʼre dealing with a well-behaved logical scenario, if have written your logic correctly (<span data-t="" data-widget="">i.e.</span> each derivation is valid) and you cover all the cases (you eventually produce every fact you are allowed to derive), thereʼs no chance that you accidentally make things break.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>We already saw our first semilattice <code class="purescript">Semigroup (App (Map PackageName) Loose)</code> above. However, I left out the definition of <code class="purescript">Loose</code> and its <code class="purescript">Semigroup</code> instance.</p>
<p>The <em>data</em> contained in <code class="purescript">Loose</code> is just a lower bound and an upper bound, and we want the lower bound to be less than the upper bound for it to be valid. We also pack in <em>metadata</em> that describes where each bound came from, the <code class="purescript">SolverPosition</code> datatype which we will discuss below in <a href="#provenance">Provenance</a>.</p>
<p>To achieve this, we first define a type that describes a bound with metadata packed in. Then we add to this operations that take the maximum and minimum of the bounds, and <em>aggregate</em> the metadata if they were the same bound. Thatʼs right, <strong>the metadata itself forms a semilattice!</strong><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<pre class="purescript"><code>data Sourced = Sourced Version SolverPosition

newtype MinSourced = MinSourced Sourced

instance Semigroup MinSourced where
  append a@(MinSourced (Sourced av as)) b@(MinSourced (Sourced bv bs)) =
    case compare av bv of
      LT -&gt; a
      GT -&gt; b
      EQ -&gt; MinSourced (Sourced av (as &lt;&gt; bs))

newtype MaxSourced = MaxSourced Sourced

instance Semigroup MaxSourced where
  append a@(MaxSourced (Sourced av as)) b@(MaxSourced (Sourced bv bs)) =
    case compare av bv of
      GT -&gt; a
      LT -&gt; b
      EQ -&gt; MaxSourced (Sourced av (as &lt;&gt; bs))</code></pre>
<p>Now we get both <code class="purescript">Loose</code> and <code class="purescript">Intersection</code> for free by the right arrangement of these types. Heck, we even get their coercion for free:</p>
<pre class="purescript"><code>newtype Loose = Loose
  { lower :: MinSourced
  , upper :: MaxSourced
  }
derive newtype instance Semigroup Loose

newtype Intersection = Intersection
  { lower :: MaxSourced
  , upper :: MinSourced
  }

derive newtype instance Semigroup Intersection

-- API for `Intersection`
upperBound :: Intersection -&gt; Version
upperBound (Intersection { upper: MinSourced (Sourced v _) }) = v

lowerBound :: Intersection -&gt; Version
lowerBound (Intersection { lower: MaxSourced (Sourced v _) }) = v

good :: Intersection -&gt; Boolean
good i = lowerBound i &lt; upperBound i

satisfies
  :: Version -&gt; Intersection -&gt; Boolean
satisfies v r = v &gt;= lowerBound r &amp;&amp; v &lt; upperBound r

-- `Loose` has to be a valid interval
toLoose :: Intersection -&gt; Maybe Loose
toLoose i | good i = Just (coerce i)
toLoose _ = Nothing

fromLoose :: Loose -&gt; Intersection
fromLoose = coerce</code></pre>
<p>Why donʼt we require <code class="purescript">Intersection</code> to be a valid interval? As we will talk about in the next section, <code class="purescript">Intersection</code> is the primary way we keep track of the knowledge we have learned already. Being in the business of aggregating information, we want to know all we can about the situation our solver is confronted with, and we just can accumulate knowledge by throwing it into this semilattice.</p>
<p>We could make taking the intersection of intervals a partially-defined operation (<code class="purescript">Intersection -&gt; Intersection -&gt; Either Error Intersection</code>), but that means we have to bail out once a single intersection becomes invalid. Instead, we integrate them directly into the semilattice structure by keeping invalid intervals around and turning them into <a href="#errors">errors</a> later (this is why we give them the metadata about <a href="#provenance">provenance</a>!). This gives us multiple errors emerging from one step for free, it is incredibly convenient.</p>
<h4 id="knowledge-propagation">Knowledge propagation</h4>
<p>Figuring out the correct way to propagate known requirements kept me occupied for days. It turns out I had done it wrong the first time, so it is good I thought it over again!</p>
<p>Our goal is to implement <code class="purescript">solveStep</code> here using <code class="purescript">commonDependencies</code> (see <a href="#intuitive-foundations-quasi-transitive-dependencies">above</a>) and <code class="purescript">exploreTransitiveDependencies</code>:</p>
<pre class="purescript"><code>-- Semilattice version of `Registry`
type TransitivizedRegistry =
  SemigroupMap PackageName
    (SemigroupMap Version
      (SemigroupMap PackageName Intersection)
    )

type RRU =
  { registry :: TransitivizedRegistry
  , required :: SemigroupMap PackageName Intersection
  , updated :: TransitivizedRegistry
  }

-- | Discover one step of quasi transitive dependencies, for known requirements
-- | and the rest of the registry too.
solveStep :: RRU -&gt; RRU

-- Key piece:
exploreTransitiveDependencies :: RRU -&gt; RRU</code></pre>
<p>The <code class="purescript">registry :: TransitivizedRegistry</code> and <code class="purescript">required :: SemigroupMap PackageName Intersection</code> represent the local dependencies for each package version and the global requirements of the initial manifest given to the solver, respectively. They both are purely accumulative: what goes in comes out with some more information. The additional information will simply be added dependencies and tightened bounds on existing dependencies. Provenance metadata may accumulate too (we donʼt really need to care about that, it is just along for the ride).</p>
<p>The other field, <code class="purescript">updated :: TransitivizedRegistry</code>, is a bit different: it does not carry over from step to step, it only talks about what changed at the last step. This is because as weʼre keeping <code class="purescript">registry :: TransitivizedRegistry</code> updated, we want to only calculate updates to the things that might need it.</p>
<p>When we first call <code class="purescript">solveStep</code>, we treat everything as updated:</p>
<pre class="purescript"><code>solveSeed :: RR () -&gt; RRU
solveSeed { registry, required } = { registry, required, updated: registry }</code></pre>
<p>and the process stabilizes when there are no updates:</p>
<pre class="purescript"><code>-- | Add quasi transitive dependencies until it stabilizes (no more updates).
-- | Needs to know what was updated since it last ran.
solveSteps :: RRU -&gt; RR ()
solveSteps r0 = go r0
  where
  go r@{ registry, required } | noUpdates r = { registry, required }
  go r = go (solveStep r)</code></pre>
<p>Keeping track of what was updated is certainly the trickiest part of the whole algorithm to reason about, but there is this one nugget of insight that coalesced into the knowledge I needed to turn it into an algorithm:</p>
<div class="Key_Idea">
<p>The manifests for package versions might need to update when some of their dependencies update. However, not all updates need to propagate like this from dependencies to their reverse dependencies.</p>
<p>In particular, in the case that a manifest is updating because its dependencies tightened, <em>if</em> this could affect its reverse dependencies they should <em>already</em> be depending on the transitive dependencies directly and updating because of it. This leaves us with the only major updates being because a dependency was <em>added</em>, which the parent did not know about yet so it needs to rescan its dependencies to potentially add the dependency itself.</p>
<p>The other case is that if a package version picks up an obvious failure, its reverse dependencies need to be notified. They may pick up a quasi-transitive dependency once this failing package version is dropped, if it was missing that particular dependency but others had it.</p>
</div>
<pre class="purescript"><code>-- | A package may update because its dependencies tightened, but any reverse
-- | dependencies should have already caught that update in this same tick.
-- | So what we look for is either a new transitive dependency picked up (which
-- | the parent will need to incorporate), or newly failing to solve,
-- | both of which may introduce new dependencies for reverse dependencies
-- | through the `commonDependencies` calculation.
majorUpdate :: SemigroupMap PackageName Intersection -&gt; SemigroupMap PackageName Intersection -&gt; SemigroupMap PackageName Intersection -&gt; Boolean
majorUpdate (SemigroupMap required) (SemigroupMap orig) updated =
  let
    minor = { added: false, failedAlready: false, failedNow: false }

    info :: { added :: Boolean, failedNow :: Boolean, failedAlready :: Boolean }
    info = updated # anyWithIndex \package range -&gt;
      case Map.lookup package orig of
        Nothing -&gt;
          -- This bound may have been omitted merely because it was subsumed by
          -- a global requirement (see `addFrom`), so adding it back does not
          -- count as a major update:
          case Map.lookup package required of
            Nothing -&gt; minor { added = true }
            Just range' -&gt; minor { added = lowerBound range &gt; lowerBound range' || upperBound range &lt; upperBound range' }
        Just r -&gt; minor { failedAlready = not good r, failedNow = not good range }
  in
    case info of
      { added: true } -&gt; true
      { failedNow: true, failedAlready: false } -&gt; true
      _ -&gt; false

-- | Update package versions in the registry with their quasi-transitive
-- | dependencies, if their dependencies were updated in the last tick. The set
-- | global requirements is needed here because those are elided from the
-- | dependencies in each package version, so to tell how the local requirements
-- | updated we need need to peek at that (see `majorUpdate`).
exploreTransitiveDependencies :: RRU -&gt; RRU
exploreTransitiveDependencies lastTick = (\t -&gt; { required: lastTick.required, updated: accumulated (fst t), registry: snd t }) $
  lastTick.registry # traverseWithIndex \package -&gt; traverseWithIndex \version deps -&gt;
    let
      updateOne depName depRange = case Map.isEmpty (unwrap (getPackageRange lastTick.updated depName depRange)) of
        true -&gt; mempty
        false -&gt; Tuple (Disj true) (commonDependencies lastTick.registry depName depRange)
      Tuple (Disj peek) newDeps = foldMapWithIndex updateOne deps
      -- keep GC churn down by re-using old deps if nothing changed, maybe?
      dependencies = if peek then deps &lt;&gt; newDeps else deps
      updated = case peek &amp;&amp; majorUpdate lastTick.required deps dependencies of
        true -&gt; doubleton package version dependencies
        false -&gt; mempty
    in
      Tuple updated dependencies

-- | Discover one step of quasi transitive dependencies, for known requirements
-- | and the rest of the registry too.
solveStep :: RRU -&gt; RRU
solveStep initial =
  { required: initial.required &lt;&gt; moreRequired
  , registry: moreRegistry
  , updated: updated &lt;&gt; updatedOfReqs
  }
  where
  -- Transitivize direct requirements
  moreRequired = initial.required # foldMapWithIndex (commonDependencies initial.registry)
  -- Record updates to them
  updatedOfReqs = requirementUpdates initial moreRequired
  -- Transitivize the rest of the registry, which should be:
  --   (1) Pruned at the start to only reachable package versions
  --   (2) Only touching packages that were directly updated last round
  { updated, registry: moreRegistry } = exploreTransitiveDependencies (initial { registry = map (addFrom moreRequired) &lt;$&gt; initial.registry })</code></pre>
<h4 id="one-simple-trick-for-efficiency">One simple trick for efficiency</h4>
<p>It turns out that the algorithm is naturally efficient, with some help.</p>
<p>The biggest trick is <em>using global constraints to discard redundant local constraints</em>. That is, if the manifest you are solving already constrains <code class="boo">prelude &gt;=6.0.0 &lt;7.0.0</code>, then each package that lists that requirement or a looser one can ignore it.</p>
<pre class="purescript"><code>-- | The key to efficiency: take information from the bounds of global
-- | requirements and add it to the local requirements of each package version
-- | in the registry, BUT remove redundant bounds as we do so.
-- |
-- | For example, if we have a global requirement `&gt;=3.1.0 &lt;4.0.0`, then in the
-- | registry we will keep local dependency ranges for the same package that
-- | look like `&gt;=3.2.0 &lt;4.0.0` or `&gt;=3.1.0 &lt;3.9.0` and remove ranges like
-- | `&gt;=3.0.0 &lt;4.0.0` or `&gt;=3.1.0 &lt;4.0.0` itself.
addFrom
  :: SemigroupMap PackageName Intersection
  -&gt; SemigroupMap PackageName Intersection
  -&gt; SemigroupMap PackageName Intersection
addFrom (SemigroupMap required) =
  over SemigroupMap $ Map.mapMaybeWithKey \package -&gt;
    case Map.lookup package required of
      Nothing -&gt; Just
      Just i -&gt; \j -&gt;
        if j `wouldUpdate` i then Just (j &lt;&gt; i)
        else Nothing

-- | Used in `addFrom, `wouldUpdate j i` is an optimized version of
-- | `(i &lt;&gt; j /= i)`.
wouldUpdate :: Intersection -&gt; Intersection -&gt; Boolean
wouldUpdate j i =
  lowerBound j &gt; lowerBound i ||
  upperBound j &lt; upperBound i</code></pre>
<p>Unfortunately I had to add a bit of special casing in the propagation to handle this, in particular <a href="https://github.com/purescript/registry-dev/blob/30a88ac7bd48a73bb2bcf9240b20b09a713ee0b9/lib/src/Solver.purs#L493-L495">when checking for major updates</a>, but the exceptional efficiency is more than worth the slight inelegance.</p>
<h5 id="oh-but-i-spent-so-much-time-getting-here">Oh but I spent so much time getting here</h5>
<p>I almost made a profiling analysis library. JavaScript performance testing is useless because it gets washed away in a sea of lambdas, and I couldnʼt find/make a tool to aggregate the lambda information into their named parents. Wrap particular segments in profiling.</p>
<p>I also needed a histogram viewer.</p>
<p>Lots of micro optimizations.</p>
<ul>
<li>Using a specific order of <code class="purescript">&lt;&gt;</code>, since <code class="purescript">Map</code> appends are implemented as a fold over the second argument so it should be the smaller argument.</li>
<li>Using a difflist (Cayley) representation when I know Iʼm only appending one key at a time but with mixed associativity.</li>
<li>Implementing <code class="purescript">wouldUpdate</code> directly instead of using the semigroup operation.</li>
<li>Optimizing the <code class="purescript">Ord Version</code> instance since it is the most common operation in this whole thing.</li>
</ul>
<p>Did they make a difference? I donʼt know! They appeared to make incremental difference as I was testing it, but once I did the big optimization above I gave up on testing that.</p>
<h3 id="errors">Errors</h3>
<p>Room for improvement. But decent off the bat. And a clear direction for improvement, unlike depth-first algorithms.</p>
<p>Conflicts. (Conflict “clauses.”) The problem with backtracking was that the errors . Particular clauses could conflict, sure, but then you had to work out why that made the whole boolean expression fail, and what that corresponds to in the version solving model.</p>
<p>In the new model, since we just keep adding requirements at each step to tighten bounds, the basic form of conflict is really simple: a required upper bound got pushed below a required lower bound. Or, we could have restricted to a range that has no registered versions.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>There are two ways we combine these errors within the logic of the solver:</p>
<ol type="1">
<li>First we note that we may encounter errors in multiple requirements at the same time, so we keep a (non-empty) map of package names to their conflicts. (Reporting multiple errors at once is very helpful!)</li>
<li>Second it may be the case that a package has versions in range, but we happen to know that none of them are still solvable, they all have conflicts of their own. (We actually just do a <a href="https://github.com/purescript/registry-dev/blob/30a88ac7bd48a73bb2bcf9240b20b09a713ee0b9/lib/src/Solver.purs#L300-L304">very shallow check of this</a>.)</li>
</ol>
<p>This gets us <a href="https://github.com/purescript/registry-dev/blob/30a88ac7bd48a73bb2bcf9240b20b09a713ee0b9/lib/src/Solver.purs#L149-L151">this data type for errors</a>:</p>
<pre class="purescript"><code>data SolverError
  = Conflicts (Map PackageName Intersection)
  | WhileSolving PackageName (Map Version SolverError)</code></pre>
<p>This isnʼt completely faithful to the logic of the solver. You have to trust that the system determined these are required: it wonʼt tell you exactly what decisions led to it requiring it.</p>
<p>But it does keep around provenance information that tells you enough about where it originated.</p>
<h4 id="provenance">Provenance</h4>
<p>Normally I like to keep full provenance to detail exactly the path a piece of data took to get through the logic.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> However, it is really slick in this domain: we only need to keep track of the endpoints, users donʼt exactly care about what came in between (just that it is reasonable to assume, because it is in fact correct).</p>
<p>So in this case I keep track of which particular package version manifest(s) gave us the constraint we are talking about (<code class="purescript">LocalSolverPosition</code>), and which constraints in the current manifest caused it to be required. Thereʼs some logic to combine these positions which I will not reproduce here.</p>
<pre class="purescript"><code>data LocalSolverPosition
  -- | Dependency asked for in manifest
  = Root
  -- | Committed to a specific version
  | Trial
  -- | Required transitive dependency seen in said packages
  | Solving
      ( NonEmptySet
          { package :: PackageName
          , version :: Version
          }
      )

data SolverPosition = Pos LocalSolverPosition (Set PackageName)</code></pre>
<p>It seems that it weakens the logical connection just a bit, I donʼt know if they can be put into formal properties anymore. (<span data-t="" data-widget="">E.g.</span> “Deleting the mentioned constraint from the current manifest affects it in <em>this</em> way.”)</p>
<p>But I believe it is the information that users want to see; it certainly falls into the category of making it actionable so they can fix things and run it again to make progress. In the case that it is a local error, knowing which clauses of the current manifest led to it is crucial in answering the question, “What do I need to change to fix the error”. And sometimes it is a deeper error of outdated dependencies, so you want to know what package is responsible for that incongruous version requirement.</p>
<div class="Bonus" data-box-name="Side thought">
<p>Itʼs interesting that nothing here required that dependencies are acyclic. I actually made some tiny decisions that ensured that this would work, without causing an infinite loop for example, but it was minor things.</p>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The Elm version solver has <a href="https://github.com/elm/compiler/blob/c9aefb6230f5e0bda03205ab0499f6e4af924495/builder/src/Reporting/Exit.hs#L902-L905">network errors</a>, but apparently <a href="https://github.com/elm/compiler/blob/c9aefb6230f5e0bda03205ab0499f6e4af924495/builder/src/Deps/Solver.hs#L102">no actual errors</a> from the simple solve-by-backtracking algorithm.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>No, for real this time!!<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Actually we probably donʼt even need a total order, a partial order would work fine for it?<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This is actually a weird requirement, since there can be incomparable solutions that need to be tie-broken arbitrarily. In practice I do it alphabetically just by dint of how the package versions are tried.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Since we chose a particular version in the previous step, its dependency ranges are well-defined, just being given in its manifest.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p> The only difference between two versions of the same package with the same manifests is that some later requirements may constrain that packageʼs range to eliminate one or the other.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Foreshadowing&nbsp;…<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p> If the logical scenario does not have a finite upper bound of information to derive, this naïve process may not terminate, but in our case it is certainly finite: the registry itself is finite, so any logical derivations from it will eventually be saturated.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>I cannot emphasize how key this is to a lot of the work of carrying around metadata by bundling it in with data like this.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>It turns out these are the <a href="https://github.com/purescript/registry-dev/blob/30a88ac7bd48a73bb2bcf9240b20b09a713ee0b9/lib/src/Solver.purs#L308-L311">same check</a>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p> In particular, in dependently-typed languages it is really helpful to be able to trace terms through their evaluation, so that by the time you get to a type error you know exactly why those particular things popped up, not just a rough idea of where in the source they were originally found once upon a time. Especially because once separate terms are unified, you donʼt want to arbitrarily pick a location, you want to know both locations!<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Impossible Bézier Calligraphy</title>
<pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/bezier_calligraphy.html</guid>
<description><![CDATA[<p>The story of how I implemented calligraphy for <a href="https://www.jasondavies.com/animated-bezier/">cubic Bézier curves</a> (the kind widely used in graphics programs, especially the common <a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">Scalable Vector Graphics (SVG) format</a>).</p>
<p>The problem statement:</p>
<div class="Key_Idea" data-box-name="Challenge">
<p>Given a pen nib of some shape, what composite shape is produced when that pen is drawn along any particular path?</p>
<p>If the inputs are cubic Bézier curves, is the output as well?</p>
<div class="Bonus" data-box-name="Jargonized">
<p>Is the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of two piecewise cubic Bézier hulls a <a href="https://en.wikipedia.org/wiki/Composite_B%C3%A9zier_curve">piecewise cubic Bézier hull</a>?</p>
<p>More specifically, is the the convolution of two cubic Bézier curves a cubic Bézier curve?</p>
</div>
</div>
<p>The catch? Itʼs mathematically impossible to model the output using cubic curves, as I determined after a bit calculus. In fact, it fails already for <em>quadratic</em> curves (the simpler companion to cubic curves, which would have simpler, more tractable solutions).</p>
<p>The cubic in “cubic Bézier curve” refers to the fact that they are parametric curves modeled by <em>cubic polynomials</em> (one polynomial for the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span> coordinate and one polynomial for the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span> coordinate, in terms of a shared time variable <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span>). Simply put, the solution for how the curves of the pen and the curves of the path interact means that the solution wonʼt be a polynomial anymore, it would at least be a <a href="https://en.wikipedia.org/wiki/Rational_function">rational function</a>, <span class="foreign" lang="la">i.e.</span> a polynomial divided by another polynomial.</p>
<p>However, that doesnʼt prevent us from getting pretty darn close. Let me show you how it works out.</p>
<div class="Note">
<p>Cubic polynomials have nothing to do with Cubism. At least, not that I know of.</p>
</div>
<h2 id="backstory">Backstory</h2>
<p>You want to know how I got here? The story begins with a car trip. My customary activity while riding in the car is to invent new writing systems, drawing on my tablet to try different calligraphic curves to start establishing what shapes I want to represent various sounds. (I tend to develop <a href="https://en.wikipedia.org/wiki/Featural_writing_system">featural writing systems</a> based on sounds represented by the <a href="https://en.wikipedia.org/wiki/International_Phonetic_Alphabet">International Phonetic Alphabet</a>.)</p>
<p>Of course, doing this in the car is hard mode already! The bumps of the car mean I have to use the tablets undo feature for more strokes than not. Plus, not only are there the mistakes of my hand being jostled by the car going over bumps, thereʼs also the mistakes of me just being mediocre at calligraphy, <em>plus</em> the fact that I have to teach myself the script as Iʼm inventing it! (I do love the creative interaction of drawing random shapes, seeing what feels good, and refining it both intentionally and through the natural iterations.)</p>
<p>Iʼve done this for many years, since before I could drive. As long as Iʼve done that, Iʼve also wanted to digitize the shapes, maybe to make them into a computer font so I donʼt have to manually write things out when I want to see how full sentences look. (ʼTwould also be a great way to explore ligatures and open type features to really make a natural flowing calligraphic font&nbsp;…)</p>
<p>As I mentioned above, the precisely stated mathematical problem says the curves we are looking for arenʼt the type of curves supported by graphics programs today. But why let the mathematical impossibilities get in the way of actually quite good enough? It took me until now to have the skills/insight/motivation to finally realize my dream, and I want to share the result and the process with you.</p>
<h2 id="demo">Demo</h2>
<p>But first, always start with the demo! Here you can see the musculoskeletal anatomy of a Minkowski calligraphy stroke:</p>
<script src="https://cdn.jsdelivr.net/npm/path-data-polyfill@1.0.3/path-data-polyfill.min.js"></script>
<style>
  #superpath path:nth-child(2n) {
    stroke: blue;
  }
  .annot path:hover {
    stroke: blue;
    fill: #0059;
    pointer-events: stroke;
  }
  [id$="-calligraphy-demo"] > svg {
    width: 50%;
  }
  @media (max-width: 760px) {
    [id$="-calligraphy-demo"] > svg {
      width: 100%;
    }
  }
</style>
<div id="main-calligraphy-demo">

</div>
<label><input id="anatomy" type="checkbox" checked=""> Overlay anatomy</label>
<script src="assets/js/quartic.js"></script>
<script src="assets/js/calligraphy.js"></script>
<script src="assets/js/minkowski.js"></script>
<p><br></p>
<div class="Details" data-box-name="Legend">
<ul>
<li>Black area – the algorithm as it current stands.</li>
<li>Red area – the ideal output, approximated. (double click on the black to generate a more and more fine approximation)</li>
<li>Green lines – the patchwork of simple segments (click to debug, double click to delete).</li>
<li>Orange lines – the special paths added via the approximate convolution algorithm. </li>
</ul>
</div>
<h2 id="big-picture">Big picture</h2>
<p>We can take apart the pen nib and pen path into a bunch of segments and compute the composite of each segment with each segment (<a href="https://en.wikipedia.org/wiki/Cartesian_product">Cartesian product</a>). Each composite of individual segments produces a section of the result, resulting in a patchwork of sections that form the whole composite shape. Having a lot of overlapping sections is OK, since <span class="foreign" lang="la">e.g.</span> Inkscapeʼs builtin Boolean operations will simplify the shapes for us.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>In fact, we will end up subdividing the original segments a bunch to produce accurate results:</p>
<ul>
<li>We donʼt want any self-intersecting segments [not implemented yet].</li>
<li>We also donʼt want any segments that stop (their derivative is zero).</li>
<li>The pen nib needs to be split up at inflection points, so its slope is monotonic along the segment.
<ul>
<li>This is because the slope of the pen path needs to be mapped onto the pen nib, and we want a unique solution.</li>
</ul></li>
<li>The pen nib also needs to be split up so that it doesnʼt loop around [not implemented yet].
<ul>
<li>More specifically, each segment needs to be split at the tangent of an endpoint.</li>
</ul></li>
<li>The pen paths need to be split at the tangents of the endpoints of the pen nib segment it is being combined with.
<ul>
<li>This ensures that each segment either traces out the obvious thing or has a composite.</li>
<li>Basically we want that either the tangents are disjoint or the pen nibʼs tangents are contained in the pen pathʼs tangents.</li>
</ul></li>
</ul>
<p>Then the task is to come up with the sections that form the patchwork:</p>
<ul>
<li>The original segments form corners (especially if they are disjoint)
<ul>
<li>With only this, you essentially get stamps at the endpoints, connected by rakes from the points; see the <a href="#smooth-sailing">smooth sailing</a> section.</li>
</ul></li>
<li>Finally the special composite that we will spend a lot of time discussing (if the tangents are a subset)</li>
</ul>
<p>But thatʼs the end result, letʼs see how I got to this algorithm.</p>
<h3 id="smooth-sailing">Smooth sailing</h3>
<p>The simplest approach is to paste each path on each segment, something like this:</p>
<pre class="javascript"><code>(Ps,Qs) =&gt; Ps.flatMap(P =&gt; Qs.flatMap(Q =&gt; [shift(Q, P[0]), shift(P, Q[0])]))</code></pre>
<p>Mathematically we would say weʼre taking the <a href="https://en.wikipedia.org/wiki/Cartesian_product">Cartesian product</a> of the segments.</p>
<p>I was able to do this much in Inkscape directly: copy some segments, align them. You can even make linked clones so it updates altogether.</p>
<div id="simplest-calligraphy-demo">

</div>
<p><label><input id="anatomy-simplest" type="checkbox" checked=""> Overlay anatomy</label></p>
<p>But there were problems: when the paths crossed over it got noticeably too thin. Even before then, the curves were trending too close, as you can see by double-clicking on it to reveal the red approximation. Basically if the pen nib wasnʼt made of perfectly straight lines, the composite stroke would be missing stuff.</p>
<p>Essentially this process is simulating what you would get by stamping the pen nib in certain points, and then drawing a rake through the path to connect them with curves. (The rake only touching the paper at the segmentation points of the pen nib.)</p>
<p>It appeared that anything more complex would require algorithmic help, and oh was I right&nbsp;… There were more issues lurking with curved segments.</p>
<h3 id="point-of-no-return">Point of no return</h3>
<p>Where tangents go wrong.</p>
<p>I sat down and tried to analyze where this occurred. My first thought was what I said above: itʼs where the crossovers happen, right? Right??</p>
<p>However, I realized that canʼt possibly be right: when the curves fail to cover the actual sweep of the pen, it has already separated by the time the curves actually cross over each other, and continues afterwards. That is, the cross-over is a symptom of the issue but not the part the delimits it.</p>
<p>Looking at it more closely (literally) I realized that the separation occurs precisely when the path of the pen parallels the endpoint tangent of one of the curvy segments of the pen nib.</p>
<p>My first thought was to stamp out the problem: insert more stamps of the pen nib at these problematic tangent points where it wants to detach from the real path. Little did I know this was only the start of unraveling a long thread&nbsp;… it was not enough! For longer curvy segments, it was clear that the extra stamps only masked the problem and did not account for what lay between them.</p>
<div id="simple-calligraphy-demo">

</div>
<p><label><input id="anatomy-simple" type="checkbox" checked=""> Overlay anatomy</label></p>
<p>The main insight, which I have already spoiled for you, is that we need to find some composite of the curves of the pen nib with the curves in the pen path, a composite which is not identical to either curve.</p>
<h4 id="need-for-composite-curves">Need for composite curves</h4>
<p>To step back from calligraphy for a moment, consider a simpler example: drawing with a circular sponge, marker, whatever. Make it comically big in your mind.</p>
<p>If you draw a straight line, the composite path is very simple: the two endpoints are capped by a semicircle and are connected by a rectangle.</p>
<p>Now consider a curved path: you can quickly imagine that two semicircles joined by the exact path will not do the job. First of all the endpoints are wrong to connect with the endcaps, second of all the curve would look funny!</p>
<p>If you slow down and look at some point on the curve very closely, what points on the circle are actually doing the work of drawing? What part of the circle is extremally far from the curve at that point? The part that is tangent to the curve!</p>
<p>Thus we will end up offsetting each point on the curve by the radius perpendicular to the curveʼs tangent.</p>
<div class=".Bonus">
<p>In fact, this offset curve is no longer a Bézier curve: it is an <a href="https://raphlinus.github.io/curves/2022/09/09/parallel-beziers.html">analytic curve of degree 10</a>.</p>
<p>Funnily enough, although it is mathematically complicated, all graphics programs support approximating this cubic Bézier + circular pen combo: this is just the stroke width parameter of SVG Bézier curves.</p>
<p>As far as the main topic of this post goes, the underlying mathematic impossibility should not discourage us quite yet: circles cannot be exactly captured by Bézier curves either, so our focus on cubic Bézier pen nibs may still be okay. (Spoiler: it is not.)</p>
</div>
<p>This thought experiment shows that we really want to find the tangent point on the pen nib that corresponds with the tangent from the pen path. If we can correlate the two for each point in time, we would get a composite path that fills out the proper area, more than the rake and stamp method.</p>
<h3 id="dead-reckoning">Dead reckoning</h3>
<p>Now we can find a precise curve to work towards: given two “nice” curves, we add up all the points where their tangents are parallel, to obtain a new curve. (This is called the convolution of the two curves.)</p>
<p>We hope to solve this in the case of cubic curves in particular: given a tangent from one curve (the pen path), find the time when the other curve (the pen nib) has the same tangent, and add those points together.</p>
<h4 id="death">Death</h4>
<p>Letʼs try a simpler thing first and see why it fails: we can keep the pen path as a cubic Bézier, but restrict the pen nib to being quadratic.</p>
<p>Taking the tangent <em>vector</em> of each curve decreases degree by one: the cubic Bézier has a quadratic tangent <em>vector</em>, and the quadratic Bézier has a linear tangent <em>vector</em>. This sounds okay so far, but recall that we want the tangents to have the same <em>slope</em> (to be parallel). This makes us take fractions (see below for more details in the cubic case).</p>
<p>So the solution is a <a href="https://en.wikipedia.org/wiki/Rational_function">rational function</a> (ratio of two polynomials). Bézier curves are polynomials, not rational functions, so the result will not be a Bézier curve.</p>
<p>Dealing with cubic curves, their tangent vector (being the derivative of their position vector) is a quadratic function. We want the two tangent vectors to be parallel, so we end up with a quadratic equation of one in terms of the other. Solving the quadratic equation introduces radicals, so it is no longer even a rational function in the cubic case.</p>
<h4 id="reckoning">Reckoning</h4>
<p>So we set about approximating the exact curve by a Bézier one.</p>
<p>The first question to ask ourselves is: what are the tangents of the curve at the endpoints? This is a simple question, actually: since we are picking points from the curves where the tangents match, the tangent is simply what it was for the base curve. (We will work through the math below to prove why this is the case.)</p>
<p>If we were approximating by a quadratic curve, this would be all we need to know: the last control point would be at the intersection of the tangents from the endpoints.</p>
<p>But since it is cubic, we have two more points to pick, which should correspond abstractly to another parameter to control at each endpoint, in addition to the tangent there.</p>
<p>Youʼd think this parameter would be curvature. Youʼd <strong>think</strong>!!</p>
<h3 id="why-curvature">Why curvature?</h3>
<p>The obvious first parameter to control is the tangent angles. If we were approximating with quadratic curves, this would be all there is to it: two points and two tangents.</p>
<p>Working with cubic curves, however, we expect an extra degree of freedom: more control over how it matches our curve. The obvious place to look is curvature.</p>
<p>Curvature (often denoted <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>κ</mi></mrow><annotation encoding="application/x-tex">\kappa</annotation></semantics></math></span>) is a geometric quantity that captures second-order behavior of a curve, regardless of parametrization. That is, regardless of how <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span> maps to actual <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle x, y \rangle</annotation></semantics></math></span> points on the curve, if the curve looks the same, it will have the same curvature.</p>
<p>However, it is not so simple to map curvature onto the Bézier curve parameters, as weʼll see next.</p>
<p>For one thing, the formula involves a complex mix of components: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>κ</mi><mo>=</mo><mfrac><mrow><msup><mi>x</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>y</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>−</mo><msup><mi>x</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi>y</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><msup><mo stretchy="false">)</mo><mrow><mn>3</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\kappa = \frac{x'y'' - x''y'}{(x'^2 + y'^2)^{3/2}}.</annotation></semantics></math></span></p>
<p>And then add in the complexities of the Bézier parameterization and you have a fun problem that yields non-unique solutions.</p>
<p>The proliferation of solutions is kind of problematic since it means we need to guess what is the right solution. At least we know we are looking for clean-looking solutions that do not deviate too much.</p>
<div class="Bonus" data-box-name="Aside">
<p>Itʼs funny: in order to display curvature in a geometrically meaningful way, you want it to be in units of distance, which means youʼd take its inverse <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>κ</mi></mrow><annotation encoding="application/x-tex">1/\kappa</annotation></semantics></math></span>. This inverse is the radius of the <em>osculating circle</em> that just barely touches the curve in the most graceful way. (Perhaps you know that you can form a circle passing through any three points, possibly a circle with infinite radius if the points are <a href="https://en.wikipedia.org/wiki/Collinearity">along the same line</a>. This is why it is a second-order property.)</p>
<p>However, despite being in the right units, the radius of the osculating circle is poorly behaved because it can blow up to infinity when the curvature is near zero! (<span class="foreign" lang="la">E.g.</span> near inflection points.)</p>
<p>So people often resort to displaying curvature as a kind of vector field associated with the curve, with some implicit conversion of units from inverse distance to real distance.</p>
<p>There is a third-order analogue of curvature called <a href="https://www.jstor.org/stable/2690245">aberrancy</a>. It is related to the <em>osculating parabola</em>, since parabolas rotated in space can be fit to four points.</p>
</div>
<h2 id="details.-oh-so-many-details">Details. Oh so many details</h2>
<p>In which we work through the math to compute a cubic Bézier approximation to cubic Bézier convolution, based on matching the known curvature at the endpoints of the exact convolution.</p>
<h3 id="background-and-notation">Background and notation</h3>
<p>If you want to dig into the details youʼll want some familiarity with vectors, calculus, and parametric curves.</p>
<p>Bézier curves are parametric curves based on some control points. Weʼll only be dealing with 2D cubic Bézier curves. Weʼll put the control points in boldface like <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>, and give the 2D vectors arrows over top like <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>u</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{u}</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{v}</annotation></semantics></math></span>.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">P</mi><mo>=</mo><mo stretchy="false">[</mo><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>0</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>0</mn><mi>y</mi></mrow></msub><mo stretchy="false">⟩</mo><mo separator="true">,</mo><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>1</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>1</mn><mi>y</mi></mrow></msub><mo stretchy="false">⟩</mo><mo separator="true">,</mo><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>2</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>2</mn><mi>y</mi></mrow></msub><mo stretchy="false">⟩</mo><mo separator="true">,</mo><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>3</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>3</mn><mi>y</mi></mrow></msub><mo stretchy="false">⟩</mo><mo stretchy="false">]</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{P} = [\langle \mathbf{P}_{0x}, \mathbf{P}_{0y}\rangle, \langle \mathbf{P}_{1x}, \mathbf{P}_{1y}\rangle, \langle \mathbf{P}_{2x}, \mathbf{P}_{2y}\rangle, \langle \mathbf{P}_{3x}, \mathbf{P}_{3y}\rangle].</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">P</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo stretchy="false">]</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{P} = [\mathbf{P}_{0}, \mathbf{P}_{1}, \mathbf{P}_{2}, \mathbf{P}_{3}].</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">P</mi><mi>x</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>0</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>1</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>2</mn><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">P</mi><mrow><mn>3</mn><mi>x</mi></mrow></msub><mo stretchy="false">]</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}_ {x} = [\mathbf{P}_{0x}, \mathbf{P}_{1x}, \mathbf{P}_{2x}, \mathbf{P}_{3x}].</annotation></semantics></math></span></p>
<p>We need the formula for the Bézier polynomial that results from the control points, and weʼll also need its first and second derivatives:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mstyle scriptlevel="0" displaystyle="true"><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mstyle></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><msup><mo stretchy="false">)</mo><mn>3</mn></msup><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo>+</mo><mn>3</mn><mi>t</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>+</mo><mn>3</mn><msup><mi>t</mi><mn>2</mn></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>+</mo><msup><mi>t</mi><mn>3</mn></msup><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo>+</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi>t</mi><mo>+</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msup><mi>t</mi><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo>−</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msup><mi>t</mi><mn>3</mn></msup><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>6</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mi>t</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>3</mn><msup><mi>t</mi><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>6</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi>t</mi><mo>+</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo>−</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msup><mi>t</mi><mn>2</mn></msup><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>6</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>6</mn><mi>t</mi><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>+</mo><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>6</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>6</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">P</mi><mn>3</mn></msub><mo>−</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi mathvariant="bold">P</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">P</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi>t</mi><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\displaystyle \mathbf{B}_\mathbf{P}(t)
  &amp;= (1-t)^3 \mathbf{P}_0 + 3t(1-t)^2 \mathbf{P}_1 + 3t^2(1-t) \mathbf{P}_2 + t^3 \mathbf{P}_3\\
  &amp;= \mathbf{P}_0 + 3(\mathbf{P}_1 - \mathbf{P}_0)t + 3(\mathbf{P}_2 - 2\mathbf{P}_1 + \mathbf{P}_0)t^2 + (\mathbf{P}_3 - 3\mathbf{P}_2 + 3\mathbf{P}_1 - \mathbf{P}_0)t^3.\\
\mathbf{B}'_\mathbf{P}(t)
  &amp;= 3(1-t)^{2}(\mathbf{P} _{1}-\mathbf{P} _{0})+6(1-t)t(\mathbf{P} _{2}-\mathbf{P} _{1})+3t^{2}(\mathbf{P} _{3}-\mathbf{P} _{2})\\
  &amp;= 3(\mathbf{P}_1 - \mathbf{P}_0) + 6(\mathbf{P}_2 - 2\mathbf{P}_1 + \mathbf{P}_0)t + 3(\mathbf{P}_3 - 3\mathbf{P}_2 + 3\mathbf{P}_1 - \mathbf{P}_0)t^2.\\
\mathbf{B}''_\mathbf{P}(t)
  &amp;= 6(1-t)(\mathbf{P} _{2}-2\mathbf{P} _{1}+\mathbf{P} _{0})+6t(\mathbf{P} _{3}-2\mathbf{P} _{2}+\mathbf{P} _{1})\\
  &amp;= 6(\mathbf{P}_2 - 2\mathbf{P}_1 + \mathbf{P}_0) + 6(\mathbf{P}_3 - 3\mathbf{P}_2 + 3\mathbf{P}_1 - \mathbf{P}_0)t.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>Naturally the first derivative of a cubic Bézier is quadratic, and the second derivative is linear.</p>
<h4 id="d-cross-product"><span style="font-variant-numeric: lining-nums">2D</span> cross product</h4>
<p>Normally we think of it in 3D space, because the cross product of two 3D vectors is another 3D vector. But it also works in 2D space, it just produces a scalar (1D vector) instead! And it turns out to be a useful abstraction for a lot of our calculations.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>u</mi><mo>⃗</mo></mover><mo>×</mo><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mo>=</mo><msub><mi>u</mi><mi>x</mi></msub><msub><mi>v</mi><mi>y</mi></msub><mo>−</mo><msub><mi>u</mi><mi>y</mi></msub><msub><mi>v</mi><mi>x</mi></msub><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\vec{u} \times \vec{v} = u_x v_y - u_y v_x.</annotation></semantics></math></span></p>
<h3 id="matching-the-curves-up">Matching the curves up</h3>
<p>The two curves are controlled by their own <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span> parameters that are independent of each otherʼs! We need to match them up somehow, and as discussed above, thereʼs a particular way to do that for our application: We need to find the times when they have <em>parallel tangent lines</em>, since that will tell us what is the furthest point of the pen nib (<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>) (locally) along any given point of the pen path (<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span>).</p>
<p>The slope of the tangent line at time <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span> is given by the ratio of the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span> components of the first derivative of the curve. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>t</mi><msub><mo stretchy="false">)</mo><mi>y</mi></msub></mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>t</mi><msub><mo stretchy="false">)</mo><mi>x</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\frac{\mathbf{B}'_\mathbf{P}(t)_y}{\mathbf{B}'_\mathbf{P}(t)_x}.</annotation></semantics></math></span></p>
<p>Weʼll start using <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><msub><mi>t</mi><mi mathvariant="bold">P</mi></msub></mrow><annotation encoding="application/x-tex">p = t_\mathbf{P}</annotation></semantics></math></span> to refer to the time along curve <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>=</mo><msub><mi>t</mi><mi mathvariant="bold">Q</mi></msub></mrow><annotation encoding="application/x-tex">q = t_\mathbf{Q}</annotation></semantics></math></span> to refer to the time along curve <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>. Weʼll think of it as solving for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span> in terms of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>; <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span> is the input and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span> the output. Our goal is to match them up, so the curves have the same slope at corresponding times!</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><msub><mo stretchy="false">)</mo><mi>y</mi></msub></mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><msub><mo stretchy="false">)</mo><mi>x</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><msub><mo stretchy="false">)</mo><mi>y</mi></msub></mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><msub><mo stretchy="false">)</mo><mi>x</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\frac{\mathbf{B}'_\mathbf{Q}(q)_y}{\mathbf{B}'_\mathbf{Q}(q)_x} = \frac{\mathbf{B}'_\mathbf{P}(p)_y}{\mathbf{B}'_\mathbf{P}(p)_x}.</annotation></semantics></math></span></p>
<p><strong>Cross</strong> multiply <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><msub><mo stretchy="false">)</mo><mi>y</mi></msub></mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><msub><mo stretchy="false">)</mo><mi>x</mi></msub></mrow><mo>=</mo><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><msub><mo stretchy="false">)</mo><mi>x</mi></msub></mrow><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><msub><mo stretchy="false">)</mo><mi>y</mi></msub></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">{\mathbf{B}'_\mathbf{Q}(q)_y} {\mathbf{B}'_\mathbf{P}(p)_x} = {\mathbf{B}'_\mathbf{Q}(q)_x} {\mathbf{B}'_\mathbf{P}(p)_y}.</annotation></semantics></math></span></p>
<p>Or use the <strong>cross</strong> product: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>×</mo><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">\mathbf{B}'_\mathbf{Q}(q) \times \mathbf{B}'_\mathbf{P}(p) = 0.</annotation></semantics></math></span></p>
<p>(Recall that the cross product is a measure of how <em>perpendicular</em> two vectors are, so they are <em>parallel</em> exactly when their cross product is zero. This is true in 2D just like in 3D, itʼs just that the cross product is now a scalar quantity, not a vector quantity.)</p>
<p>What does this get us? Well, we can think of it either way, but letʼs assume that weʼre given <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>, so we plug it in and obtain an equation to solve for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span>. Since <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{B}'_ \mathbf{Q}</annotation></semantics></math></span> is quadratic, we get a quadratic equation to solve, with some nasty scalar coefficients <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span> coming from the control points of our curves <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>, evaluated at <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>:<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><mi>b</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi>q</mi><mo>+</mo><mi>c</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">a(p)q^2 + b(p)q + c(p) = 0.</annotation></semantics></math></span></p>
<p>Obviously it gets tedious to write all of that, so we omit the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span> parameter and simply write: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><mi>b</mi><mi>q</mi><mo>+</mo><mi>c</mi><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">aq^2 + bq + c = 0.</annotation></semantics></math></span></p>
<h4 id="issues">Issues</h4>
<p>Thereʼs a few issues we run into.</p>
<p>The first is that the solution doesnʼt necessarily lie on the actual Bézier segment drawn out by <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>q</mi><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \le q \le 1</annotation></semantics></math></span>.</p>
<p>Second there might be two solutions, since weʼre solving a quadratic!</p>
<p>The solution to both is to split things up! We need to split up the <em>pen path</em> so it indexes the tangents at the end of the Bézier segments of the pen nib, after first splitting the <em>pen nib</em> at its inflection points.</p>
<p>Splitting at inflection points ensures that the tangent slope is always increasing or decreasing along the segment, making there only be a single solution. Actually this requires also knowing that the Bézier segment doesnʼt rotate 180°, so we need to split it if it reaches its original tangents again.</p>
<p>Solving these issues means we can think of the equation above as giving us a function for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span> in terms of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo>−</mo><mi>b</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>±</mo><msqrt><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>p</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi>c</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></msqrt></mrow><mrow><mn>2</mn><mi>a</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">q(p) = \frac{-b(p) \pm \sqrt{b(p)^2 - 4a(p)c(p)}}{2a(p)}.</annotation></semantics></math></span></p>
<p>This puts the functions in lock-step in terms of their tangents, giving us what we need to calculate the outside of their sweep.</p>
<h4 id="derivative-of-this">Derivative of this</h4>
<p>Weʼll need the derive of this equation soon, so letʼs calculate it while weʼre here.</p>
<p>My first thought was great, we have a quadratic equation, so we know the formula and can just take the derivative of it!</p>
<p>This was&nbsp;… naïve, oh so naïve. Letʼs see why.</p>
<p>We have our solution here:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
q = q(p) = \frac{-b\pm\sqrt{b^2 - 4ac}}{2a}.
</annotation></semantics></math></span></p>
<p>So we can take its derivative <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q' = q'(p)</annotation></semantics></math></span>, using the chain rule, quotient rule, product rule&nbsp;… oh Iʼll spare you the gory details.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mo>−</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>±</mo><mfrac><mrow><mn>2</mn><mi>b</mi><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>−</mo><mn>4</mn><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>c</mi><mo>−</mo><mn>4</mn><mi>a</mi><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt></mfrac><mo stretchy="false">)</mo><mn>2</mn><mi>a</mi><mo>+</mo><mn>2</mn><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt><mo stretchy="false">)</mo></mrow><mrow><mn>4</mn><msup><mi>a</mi><mn>2</mn></msup></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mo>−</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>±</mo><mfrac><mrow><mn>2</mn><mi>b</mi><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>−</mo><mn>4</mn><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>c</mi><mo>−</mo><mn>4</mn><mi>a</mi><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt></mfrac></mrow><mrow><mn>2</mn><mi>a</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn><msup><mi>a</mi><mn>2</mn></msup></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
q'
  &amp;= \frac{(-b'\pm\frac{2bb' - 4a' c - 4ac'}{\sqrt{b^2 - 4ac}})2a + 2a'(-b\pm\sqrt{b^2 - 4ac})}{4a^2}\\
  &amp;= \frac{-b'\pm\frac{2bb' - 4a' c - 4ac'}{\sqrt{b^2 - 4ac}}}{2a} + \frac{a'(-b\pm\sqrt{b^2 - 4ac})}{2a^2}
\end{aligned}
</annotation></semantics></math></span></p>
<p>(Recall that <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span> are functions of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>, so they have derivatives <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">a'</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">b'</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">c'</annotation></semantics></math></span> in terms of that variable.)</p>
<p>Notice any problems?</p>
<p>Well, first off, itʼs an ugly, messy formula! And thatʼs even with hiding the definitions of the coefficients <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span>.</p>
<p>The biggest problem, though, is that everything is divided by <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>a</mi></mrow><annotation encoding="application/x-tex">2a</annotation></semantics></math></span> or <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><msup><mi>a</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">4a^2</annotation></semantics></math></span>, which means it doesnʼt work when <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a = 0</annotation></semantics></math></span>. That shouldnʼt be too surprising, given that the quadratic formula also fails in that case. (Itʼs the <em>quadratic</em> formula after all, not the <em>quadratic-or-linear</em> formula!)</p>
<p>I mean, we could solve the linear case separately:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>b</mi><mi>q</mi><mo>+</mo><mi>c</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">
bq + c = 0
</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo>=</mo><mfrac><mrow><mo>−</mo><mi>c</mi></mrow><mi>b</mi></mfrac></mrow><annotation encoding="application/x-tex">
q = \frac{-c}{b}
</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mfrac><mrow><mo>−</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>b</mi><mo>+</mo><mi>c</mi><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><msup><mi>b</mi><mn>2</mn></msup></mfrac><mo>=</mo><mfrac><mrow><mo>−</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mi>b</mi></mfrac><mo>+</mo><mfrac><mrow><mi>c</mi><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><msup><mi>b</mi><mn>2</mn></msup></mfrac></mrow><annotation encoding="application/x-tex">
q' = \frac{-c' b + cb'}{b^2} = \frac{-c'}{b} + \frac{cb'}{b^2}
</annotation></semantics></math></span></p>
<p>But that also doesnʼt work; it omits the contribution of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">a'</annotation></semantics></math></span>, which does in fact influence the result of the rate of change of the quadratic formula, even when <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a = 0</annotation></semantics></math></span>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>So I took a deep breath, started texting my math advisor, and I <a href="https://en.wikipedia.org/wiki/Rubber_duck_debugging">rubber ducked</a> myself into a much <em>much</em> better solution.</p>
<p>You see, the quadratic formula is a lie. How did we define <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span>? Certainly not as a complicated quadratic formula solution. It is <strong>really</strong> defined as the implicit solution to an equation (an equation which happens to be quadratic): <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><mi>b</mi><mi>q</mi><mo>+</mo><mi>c</mi><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">aq^2 + bq + c = 0.</annotation></semantics></math></span></p>
<p>Look, we can just take the derivative of that whole equation, even before we attempt to solve it (only takes the product rule this time!):</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mi>a</mi><mi>q</mi><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi><mo>+</mo><mi>b</mi><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">
a'q^2 + 2aqq' + b'q + bq' + c' = 0.
</annotation></semantics></math></span></p>
<p>And <strong>this</strong>, now <em>this</em> has a nicer solution: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mfrac><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi><mo>+</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mrow><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
q' = \frac{a' q^2 + b' q + c'}{2aq + b}.
</annotation></semantics></math></span></p>
<p>I think itʼs cute how the numerator is another quadratic polynomial with the derivatives of the coefficients of the original polynomial. Itʼs also convenient how we have no square roots or plusminus signs anymore – instead we write the derivative in terms of the original solution <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span>.</p>
<p>We still have a denominator that can be zero, but this is for deeper reasons: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi><mo>=</mo><mo>−</mo><mi>b</mi><mo>±</mo><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt><mo>+</mo><mi>b</mi><mo>=</mo><mo>±</mo><msqrt><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi></mrow></msqrt><mo>=</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">2aq + b = -b \pm \sqrt{b^2 - 4ac} + b = \pm \sqrt{b^2 - 4ac} = 0.</annotation></semantics></math></span></p>
<p>Obviously this is zero exactly when <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mn>2</mn></msup><mo>−</mo><mn>4</mn><mi>a</mi><mi>c</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">b^2 - 4ac = 0</annotation></semantics></math></span>. This quantity is called the discriminant of the quadratic, and controls much of its behavior: the basic property of how many real-valued solutions it has, as well as deeper number-theoretic properties studied in <a href="https://blog.veritates.love/">Galois theory</a>.</p>
<div class="Bonus" data-box-name="Aside">
<p>I was looking at this and seeing <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">q^2</annotation></semantics></math></span> made me think that it could be rewritten a bit, since we can solve for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">q^2</annotation></semantics></math></span> in the defining equation:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>q</mi><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mo>−</mo><mi>c</mi><mo>−</mo><mi>b</mi><mi>q</mi></mrow><mi>a</mi></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
q^2 = \frac{-c-bq}{a}.
</annotation></semantics></math></span></p>
<p>With some work that gives us this formula: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mfrac><mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi><mo>+</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mrow><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>a</mi><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>−</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>b</mi><mo stretchy="false">)</mo><mi>q</mi><mo>+</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>a</mi><mo>−</mo><mi>c</mi><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><mrow><mi>a</mi><mo stretchy="false">(</mo><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mfrac><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">
q' = \frac{a' q^2 + b' q + c'}{2aq + b} = \frac{(ab' - a' b)q + c' a - ca'}{a(2aq + b)},
</annotation></semantics></math></span> which is nice and symmetric (it is patterned a little like the cross product in the numerator) but not what I ended up going for, I think I was worried about floating-point precision but idk.</p>
</div>
<div class="Bonus">
<p>For fun we can see what the second derivative is, though we wonʼt end up using it! (I was scared we would need it at one point but that was caused by me misreading my code.)</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi><mo>+</mo><msup><mi>c</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">
(2aq+b)q' = a' q^2 + b' q + c'
</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>a</mi><mi>t</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>+</mo><mo stretchy="false">(</mo><menclose notation="updiagonalstrike"><mrow><mn>2</mn><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi></mrow></menclose><mo>+</mo><mn>2</mn><mi>a</mi><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><menclose notation="updiagonalstrike"><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></menclose><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msup><mi>a</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><menclose notation="updiagonalstrike"><mrow><mn>2</mn><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi>q</mi><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow></menclose><mo>+</mo><msup><mi>b</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mi>q</mi><mo>+</mo><menclose notation="updiagonalstrike"><mrow><msup><mi>b</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow></menclose><mo>+</mo><msup><mi>c</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">
(2at+b)q'' + (\cancel{2a'q} + 2aq' + \cancel{b'})q' = a'' q^2 + \cancel{2a'qq'} + b'' q + \cancel{b' q'} + c''
</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>=</mo><mfrac><mrow><mo>−</mo><mn>2</mn><mi>a</mi><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi>a</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mi>q</mi><mo>+</mo><msup><mi>c</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><mrow><mn>2</mn><mi>a</mi><mi>q</mi><mo>+</mo><mi>b</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">
q'' = \frac{- 2aq'^2 + a'' q^2 + b'' q + c''}{2aq+b}
</annotation></semantics></math></span></p>
</div>
<h4 id="mystery-coefficients">Mystery coefficients</h4>
<p>In which I attempt to write out what <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span> actually are. Wish me luck.</p>
<p>We take the standard quadratic form of the tangent of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mn>6</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi>q</mi><mo>+</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>3</mn></msub><mo>−</mo><mn>3</mn><msub><mi mathvariant="bold">Q</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><msup><mi>q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
\mathbf{B}'_\mathbf{Q}(q) =
3(\mathbf{Q}_1 - \mathbf{Q}_0) + 6(\mathbf{Q}_2 - 2\mathbf{Q}_1 + \mathbf{Q}_0)q + 3(\mathbf{Q}_3 - 3\mathbf{Q}_2 + 3\mathbf{Q}_1 - \mathbf{Q}_0)q^2
</annotation></semantics></math></span></p>
<p>(Notice how there is a constant term, a term multiplied by <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span>, and a term with <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">q^2</annotation></semantics></math></span>.)</p>
<p>We want to wrangle this cross product of that with <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{B}'_\mathbf{P}(p)</annotation></semantics></math></span> into a quadratic equation of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>×</mo><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mi>a</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mn>2</mn></msup><mo>+</mo><mi>b</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi>q</mi><mo>+</mo><mi>c</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\mathbf{B}'_\mathbf{Q}(q) \times \mathbf{B}'_\mathbf{P}(p)
  = a(p)q^2 + b(p)q + c(p)
</annotation></semantics></math></span></p>
<p>So by distributivity, each coefficient we saw above is cross-producted with <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{B}'_\mathbf{P}(p)</annotation></semantics></math></span> to obtain our mystery coefficients: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>a</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>3</mn></msub><mo>−</mo><mn>3</mn><msub><mi mathvariant="bold">Q</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>×</mo><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>6</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>×</mo><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>c</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>3</mn><mo stretchy="false">(</mo><msub><mi mathvariant="bold">Q</mi><mn>1</mn></msub><mo>−</mo><msub><mi mathvariant="bold">Q</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>×</mo><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
a(p) &amp;= 3(\mathbf{Q}_3 - 3\mathbf{Q}_2 + 3\mathbf{Q}_1 - \mathbf{Q}_0) \times \mathbf{B}'_\mathbf{P}(p),\\
b(p) &amp;= 6(\mathbf{Q}_2 - 2\mathbf{Q}_1 + \mathbf{Q}_0) \times \mathbf{B}'_\mathbf{P}(p),\\
c(p) &amp;= 3(\mathbf{Q}_1 - \mathbf{Q}_0) \times \mathbf{B}'_\mathbf{P}(p).\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>You <em>could</em> expand it out more into the individual components, but it would be painful, not very insightful, and waste ink.</p>
<p>Note that this vector cross-product <em>cannot</em> be cancelled out as a common term, because the <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>-vector coefficients control how the separate components of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{B}'_\mathbf{P}(p)</annotation></semantics></math></span> are mixed together to create the coefficients of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>, and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span>. However, it could be divided by its norm without a problem (that is, only the direction of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{B}'_\mathbf{P}(p)</annotation></semantics></math></span> matters, not is magnitude – and this is by design.)</p>
<h3 id="dead-reckoning-revisited">Dead reckoning revisited</h3>
<p>Now that we have a formula for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span> in terms of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>, we can just plug it in and get our whole curve.</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">C</mi><mrow><mi mathvariant="bold">P</mi><mo separator="true">,</mo><mi mathvariant="bold">Q</mi></mrow></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">P</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi mathvariant="bold">B</mi><mi mathvariant="bold">Q</mi></msub><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{C}_{\mathbf{P},\mathbf{Q}}(p) = \mathbf{B}_\mathbf{P}(p) + \mathbf{B}_\mathbf{Q}(q(p)).</annotation></semantics></math></span></p>
<p>Now for the main question: is this a Bézier curve? Nope!</p>
<p>Even if <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span> was a quadratic Bézier curve, the solution <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(p)</annotation></semantics></math></span> would still be a <a href="https://en.wikipedia.org/wiki/Rational_function">rational function</a>, which is not compatible with the polynomial structure of Bézier curves.</p>
<p>That means we canʼt just stick the curve into an SVG file or similar graphics format, its true form is not natively supported by any graphics libraries. (And for good reason, because itʼs kind of a beast!)</p>
<p>However, we know a lot of information about the curve, and we can use it to reconstruct a decent approximation of its behavior, meaning all is not lost.</p>
<h4 id="computing-compound-curvature">Computing compound curvature</h4>
<p>We now know an exact formula for the idealized <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">C</mi><mrow><mi mathvariant="bold">P</mi><mo separator="true">,</mo><mi mathvariant="bold">Q</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{C}_{\mathbf{P}, \mathbf{Q}}</annotation></semantics></math></span>. We can use this to get some key bits of information that will allow us to construct a good approximation to its behavior.</p>
<p>In particular, we want to know the slope at the endpoints and also the curvature at the endpoints. The curvature is the complicated part.</p>
<p>Itʼs going to get verbose very quickly, so letʼs trim down the notation a bit by leaving <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span> implicit, focusing on <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">t = q(p)</annotation></semantics></math></span>, and remove the extraneous parts of the Bézier notation:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">C</mi><mo>=</mo><mi mathvariant="bold">P</mi><mo>+</mo><mi mathvariant="bold">Q</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{C} = \mathbf{P} + \mathbf{Q}(q).</annotation></semantics></math></span></p>
<p>By construction, the slope at the endpoints is just the slope of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span> at the endpoints: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∥</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\mathbf{C}' = \mathbf{P}' + \mathbf{Q}'(q)q' \parallel \mathbf{P}',</annotation></semantics></math></span> since those vectors are parallel by the construction of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(p)</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∥</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}' \parallel \mathbf{Q}'(q).</annotation></semantics></math></span></p>
<p>The curvature is a bit complicated, but we can work through it and just requires applying the formulas, starting with this formula for curvature of a parametric curve:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">C</mi><mi>κ</mi></msup><mo>=</mo><mfrac><mrow><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><msup><mi mathvariant="bold">C</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><mrow><mi mathvariant="normal">∥</mi><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi mathvariant="normal">∥</mi><mn>3</mn></msup></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{C}^\kappa = \frac{\mathbf{C}' \times \mathbf{C}''}{\|\mathbf{C}'\|^3}.</annotation></semantics></math></span></p>
<p>We already computed <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\mathbf{C}'</annotation></semantics></math></span> above, so we just need to compute <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">C</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{C}''</annotation></semantics></math></span> and compute the cross product. <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi mathvariant="bold">C</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>=</mo><msup><mi mathvariant="bold">P</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\mathbf{C}'' = \mathbf{P}'' + \mathbf{Q}''(q)q'^2 + \mathbf{Q}'(q)q''.</annotation></semantics></math></span></p>
<p>However, I promised that we wouldnʼt need the second derivative <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">q''</annotation></semantics></math></span>, so letʼs see how it cancels out in the cross product. With some distributivity we can expand it:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left right left" columnspacing="0em 1em 0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><msup><mi mathvariant="bold">C</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">×</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>×</mo><msup><mi mathvariant="bold">P</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">+</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>×</mo><msup><mi mathvariant="bold">Q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">+</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><menclose notation="updiagonalstrike"><mrow><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></menclose><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">+</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><menclose notation="updiagonalstrike"><mrow><mo stretchy="false">(</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>×</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></menclose><msup><mi>q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><msup><mi mathvariant="bold">C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><mo stretchy="false">(</mo><msup><mi mathvariant="bold">P</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo>+</mo><msup><mi mathvariant="bold">Q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mn>2</mn></mrow></msup><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\mathbf{C}' \times \mathbf{C}''
  &amp;&amp; = &amp;\ (\mathbf{P}' + \mathbf{Q}'(q)q')\\
  &amp;&amp; \times &amp;\ (\mathbf{P}'' + \mathbf{Q}''(q)q'^2 + \mathbf{Q}'(q)q'')\\\\
  &amp;&amp; = &amp;\ (\mathbf{P}' + \mathbf{Q}'(q)q') \times \mathbf{P}''\\
  &amp;&amp; + &amp;\ (\mathbf{P}' + \mathbf{Q}'(q)q') \times \mathbf{Q}''(q)q'^2\\
  &amp;&amp; + &amp;\ \cancel{(\mathbf{P}' \times \mathbf{Q}'(q))}q''\\
  &amp;&amp; + &amp;\ \cancel{(\mathbf{Q}'(q) \times \mathbf{Q}'(q))}q'q''\\\\
  &amp;&amp; = &amp;\ \mathbf{C}' \times (\mathbf{P}'' + \mathbf{Q}''(q)q'^2).\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>Obviously <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>×</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathbf{Q}'(q) \times \mathbf{Q}'(q) = 0</annotation></semantics></math></span>, since those are parallel, being the same vector. But <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">P</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><msup><mi mathvariant="bold">Q</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathbf{P}' \times \mathbf{Q}'(q) = 0</annotation></semantics></math></span> as well, since those are parallel by construction of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>=</mo><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q = q(p)</annotation></semantics></math></span>. That means we do not need to deal with the second derivative <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">q''</annotation></semantics></math></span>.</p>
<h4 id="reconstructive-surgery">Reconstructive surgery</h4>
<p>Now we can get down to business. How do we find the best Bézier curve to fill in for the much more complicated curve <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">C</mi><mrow><mi mathvariant="bold">P</mi><mo separator="true">,</mo><mi mathvariant="bold">Q</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{C}_{\mathbf{P},\mathbf{Q}}</annotation></semantics></math></span> that combines the two curves <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi></mrow><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span>?</p>
<p>Weʼll take six (6) pieces of data from <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">C</mi><mrow><mi mathvariant="bold">P</mi><mo separator="true">,</mo><mi mathvariant="bold">Q</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{C}_{\mathbf{P},\mathbf{Q}}</annotation></semantics></math></span>:</p>
<ol type="1">
<li>The endpoints: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">f_0</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">f_1</annotation></semantics></math></span> (x2),</li>
<li>The tangents at the endpoints: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">d_0</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">d_1</annotation></semantics></math></span> (x2), and</li>
<li>The curvature at the endpoints: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>κ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\kappa_0</annotation></semantics></math></span>, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>κ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\kappa_1</annotation></semantics></math></span> (x2).</li>
</ol>
<p>This should be enough to pin down a Bézier curve, and indeed there is a way to find cubic Bézier curves that match these parameters.</p>
<p>We will be following the paper <a href="https://minds.wisconsin.edu/bitstream/handle/1793/58822/TR692.pdf;jsessionid=E008B26966FD35F59178ECBD7500CB56?sequence=1">High accuracy geometric Hermite interpolation</a> by Carl de Boor, Klaus Höllig, and Malcolm Sabin to answer this question. The basic sketch of the math is pretty straightforward, but the authors have done the work to come up with the right parameterizations to make it easy to compute and reason about.</p>
<p>The bad news is we end up with a quartic (degree 4) equation, to solve the system of two quadratic equations. So we see that there can be up to 4 solutions. But we can narrow them down a bunch, like if there are solutions with loops (self-intersections) we can rule them out, or other outlandish solutions with far-flung control points.</p>
<p>For example, one can take these same datapoints from a real cubic Bézier curve and reconstruct its control points from those six pieces of information. In our case, we are hoping that the curves we come across, although not technically being of that form, are very close and will still produce a similar curve to the perfect idealized solution.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="Bonus">
<p>In fact, one cool thing about this implementation is that we can use it to find the closest Bézier curve <em>without a loop</em> to one <em>with a loop</em>. (And the reverse, though I have not implemented that.)</p>
<div id="delooper-demo">

</div>
</div>
<h5 id="steps-to-a-solution">Steps to a solution</h5>
<p>Basically a lot of shuffling variables around.</p>
<p>We will be solving for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\delta_0</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\delta_1</annotation></semantics></math></span>, which scale the control handles along the predefined tangents, giving these Bézier control points: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>b</mi><mn>0</mn></msub><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><mo separator="true">,</mo><mtext>&nbsp;</mtext></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><msub><mi>b</mi><mn>1</mn></msub><mo>=</mo><msub><mi>b</mi><mn>0</mn></msub><mo>+</mo><msub><mi>δ</mi><mn>0</mn></msub><msub><mi>d</mi><mn>0</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>b</mi><mn>3</mn></msub><mo>=</mo><msub><mi>f</mi><mn>1</mn></msub><mo separator="true">,</mo><mtext>&nbsp;</mtext></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;</mtext><msub><mi>b</mi><mn>2</mn></msub><mo>=</mo><msub><mi>b</mi><mn>3</mn></msub><mo>−</mo><msub><mi>δ</mi><mn>1</mn></msub><msub><mi>d</mi><mn>1</mn></msub><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
b_0 = f_0,\ &amp;\ b_1 = b_0 + \delta_0 d_0,\\
b_3 = f_1,\ &amp;\ b_2 = b_3 - \delta_1 d_1.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>Now we compute the curvature at the endpoints for this Bézier curve: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>κ</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mn>2</mn></msub><mo>−</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>3</mn><msubsup><mi>δ</mi><mn>0</mn><mn>2</mn></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>κ</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mn>1</mn></msub><mo>−</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>3</mn><msubsup><mi>δ</mi><mn>1</mn><mn>2</mn></msubsup><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\kappa_0 &amp;= 2d_0 \times (b_2 - b_1)/(3\delta_0^2),\\
\kappa_1 &amp;= 2d_1 \times (b_1 - b_2)/(3\delta_1^2).\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>And with these substitutions, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>f</mi><mn>0</mn></msub><mo>−</mo><msub><mi>f</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo>:</mo><mi>a</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>b</mi><mn>2</mn></msub><mo>−</mo><msub><mi>b</mi><mn>1</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo>:</mo><mi>a</mi><mo>−</mo><msub><mi>δ</mi><mn>0</mn></msub><msub><mi>d</mi><mn>0</mn></msub><mo>−</mo><msub><mi>δ</mi><mn>1</mn></msub><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
f_0 - f_1 &amp;=: a,\\
b_2 - b_1 &amp;=: a - \delta_0 d_0 - \delta_1 d_1,\\
\end{aligned}
</annotation></semantics></math></span> we get a system of two quadratic equations for <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\delta_0</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\delta_1</annotation></semantics></math></span>: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>δ</mi><mn>0</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mi>a</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><mn>3</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo><msub><mi>κ</mi><mn>1</mn></msub><msubsup><mi>δ</mi><mn>1</mn><mn>2</mn></msubsup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mi>a</mi><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><mn>3</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo><msub><mi>κ</mi><mn>0</mn></msub><msubsup><mi>δ</mi><mn>0</mn><mn>2</mn></msubsup><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
(d_0 \times d_1)\delta_0 = (a \times d_1) - (3/2)\kappa_1 \delta_1^2,\\
(d_0 \times d_1)\delta_1 = (d_0 \times a) - (3/2)\kappa_0 \delta_0^2.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>Itʼs easy to deal with the case when <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">d_0 \times d_1 = 0</annotation></semantics></math></span> (that is, when the starting and ending tangents are parallel). For the nonzero case, we reparameterize again according to:</p>
<p><span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>δ</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo>:</mo><msub><mi>ρ</mi><mn>0</mn></msub><mfrac><mrow><mi>a</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub></mrow><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub></mrow></mfrac><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>δ</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo>:</mo><msub><mi>ρ</mi><mn>1</mn></msub><mfrac><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mi>a</mi></mrow><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub></mrow></mfrac><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\delta_0 &amp;=: \rho_0 \frac{a \times d_1}{d_0 \times d_1},\\
\delta_1 &amp;=: \rho_1 \frac{d_0 \times a}{d_0 \times d_1}.\\
\end{aligned}
</annotation></semantics></math></span> <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>R</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>:</mo><mo>=</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mfrac><mrow><msub><mi>κ</mi><mn>0</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mi>a</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mfrac><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>R</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>:</mo><mo>=</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mfrac><mrow><msub><mi>κ</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>a</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mfrac><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
R_0 &amp;:= \frac{3}{2}\frac{\kappa_0 (a \times d_1)}{(d_0 \times a)(d_0 \times d_1)^2},\\
R_1 &amp;:= \frac{3}{2}\frac{\kappa_1 (d_0 \times a)}{(a \times d_1)(d_0 \times d_1)^2}.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>Thus we end up with the very pretty system of quadratics: <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>ρ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>1</mn></msub><msubsup><mi>ρ</mi><mn>1</mn><mn>2</mn></msubsup><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>ρ</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>0</mn></msub><msubsup><mi>ρ</mi><mn>0</mn><mn>2</mn></msubsup><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\rho_0 = 1 - R_1 \rho_1^2,\\
\rho_1 = 1 - R_0 \rho_0^2.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>We can solve for one of these variables, by substituting from the other equation, <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>ρ</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>0</mn></msub><msubsup><mi>ρ</mi><mn>0</mn><mn>2</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mn>2</mn><msub><mi>R</mi><mn>0</mn></msub><msub><mi>R</mi><mn>1</mn></msub><msubsup><mi>ρ</mi><mn>0</mn><mn>2</mn></msubsup><mo>−</mo><msubsup><mi>R</mi><mn>0</mn><mn>2</mn></msubsup><msub><mi>R</mi><mn>1</mn></msub><msubsup><mi>ρ</mi><mn>0</mn><mn>4</mn></msubsup><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\rho_0
  &amp;= 1 - R_1 (1 - R_0 \rho_0^2)^2\\
  &amp;= 1 - R_1 + 2R_0R_1\rho_0^2 - R_0^2 R_1 \rho_0^4.\\
\end{aligned}
</annotation></semantics></math></span></p>
<p>This is a depressed quartic equation, with coefficients <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo>−</mo><msub><mi>R</mi><mn>1</mn></msub><mo separator="true">,</mo><mtext>&nbsp;</mtext><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mn>2</mn><msub><mi>R</mi><mn>0</mn></msub><msub><mi>R</mi><mn>1</mn></msub><mo separator="true">,</mo><mtext>&nbsp;</mtext><mn>0</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mo>−</mo><msubsup><mi>R</mi><mn>0</mn><mn>2</mn></msubsup><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1 - R_1,\ -1,\ 2R_0R_1,\ 0,\ -R_0^2R_1]</annotation></semantics></math></span>.</p>
<h5 id="pruning-solutions">Pruning solutions</h5>
<p>We want solutions with <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\delta_0, \delta_1 \ge 0</annotation></semantics></math></span> – that is, with the control handles pointing the correct way. We also want to generally minimize those variables too, otherwise there are outlandish solutions with huge coefficients (particularly ones with loops). Finally I also added a check that ensures we are getting the correct curvature out of them – for some reason I was getting solutions with flipped curvature.</p>
<div class="Bonus">
<p>Itʼs actually really pretty to see solutions with all signs of curvatures together:</p>
<div id="all-fits-demo">

</div>
</div>
<h2 id="implementation">Implementation</h2>
<p>I have an implementation in vanilla JavaScript of the algorithm described in this post.</p>
<p>Of course it needs some basic theory of vectors and polynomials and Bézier curves. For example, <code class="javascript">bsplit(points, t0)</code> returns a vector of two new Bézier curves that cover intervals <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, t_0]</annotation></semantics></math></span> and <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>t</mi><mn>0</mn></msub><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[t_0, 1]</annotation></semantics></math></span> of the input curve, respectively.</p>
<p>The important functions in <a href="https://github.com/MonoidMusician/blog/blob/main/assets/js/calligraphy.js"><code>calligraphy.js</code></a> are as follows:</p>
<ul>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/calligraphy.js#L464-L481"><code class="javascript">compositeI(P,Q)</code></a> computes the approximate Bézier convolution of <code>P</code> with <code>Q</code>.</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/calligraphy.js#L414-L444"><code class="javascript">PQ_CURVATURE(P,Q)(p,q=T_SOL(P,Q)(p))</code></a> computes the curvature of the exact convolution between <code>P</code> and <code>Q</code> at <code>(p,q)</code> (where <code>q</code> should be the point on <code>Q</code> corresponding to <code>p</code> on <code>P</code>, <span data-t="" data-widget="">i.e.</span> parallel).</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/calligraphy.js#L483-L490"><code class="javascript">INFLXNS(P)</code></a> computes the inflection points of <code>P</code>.</li>
</ul>
<p>And the full algorithm is put together (with visualization) in <a href="https://github.com/MonoidMusician/blog/blob/main/assets/js/minkowski.js"><code>minkowski.js</code></a>:</p>
<ul>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/minkowski.js#L185-L216"><code class="javascript">doTheThing(p1, p2)</code></a> does the thing, as it says.</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/minkowski.js#L1327-L1341"><code class="javascript">splitPathAtInflections(p2)</code></a> removes pathologies from the pen nib.</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/minkowski.js#L1264-L1267"><code class="javascript">splitBezierAtTangents(c1, getTangentsL(c2))</code></a> splits the pen path according to the points of interest of the pen nib.</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/minkowski.js#L201-L203"><code class="javascript">getTangentsL(c2)</code></a> includes both the control point tangents of the Bézier as well as the beginning-to-end tangent, to make the tangent function injective on the length of each segment.?? ??</li>
<li><a href="https://github.com/MonoidMusician/blog/blob/4147508e0dfd2e0451ba89a5e6ed5116e9628d73/assets/js/minkowski.js#L239-L303"><code class="javascript">doTheTask(c1, c2)</code></a> creates a patch or two from two Bézier curves, which will either be the “parallelogram” formed by translating them, or will include their convolution if it exists.</li>
</ul>
<h3 id="hacks">Hacks</h3>
<p>Uhhh&nbsp;… I allowed the control points to go backwards (<span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>δ</mi><mn>0</mn></msub><mo>∗</mo><msub><mi>δ</mi><mn>1</mn></msub><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\delta_0 * \delta_1 &lt; 0</annotation></semantics></math></span>) and I perturbed the tangential splits due to numeric issues. The latter could be fixed by actually remembering those splits and not trying to solve <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q(p)</annotation></semantics></math></span> there.</p>
<h2 id="symmetries">Symmetries</h2>
<p>Throughout this post, Iʼve been emphasizing “the pen nib this” and “the pen path that” for the sake of giving you a concrete image in your mind. But the reality of the underlying math is that there is no fundamental distinction between the two curves. The convolution and Minkowski sum are commutative, and do not care which curve is which.</p>
<h2 id="references">References</h2>
<p>My primary sources/inspiration:</p>
<ul>
<li>The wonderful, fabulous, extraordinary <a href="https://pomax.github.io/bezierinfo/">Primer on Bézier Curves</a> by Pomax.</li>
<li><a href="https://raphlinus.github.io/curves/2021/03/11/bezier-fitting.html">Fitting cubic Bézier curves</a>, <a href="https://raphlinus.github.io/curves/2018/12/28/bezier-arclength.html">How long is that Bézier?</a>, and other posts by the excellent Raph Levien.</li>
<li>Linked from the above, my main reference that convinced me it was possible and made my life easier (except for the hour I spent chasing down a minus sign I forgot): <a href="https://minds.wisconsin.edu/bitstream/handle/1793/58822/TR692.pdf;jsessionid=E008B26966FD35F59178ECBD7500CB56?sequence=1">High accuracy geometric Hermite interpolation</a> by Carl de Boor, Klaus Höllig, and Malcolm Sabin.</li>
</ul>
<p>Other miscellanea on Bézier curves:</p>
<ul>
<li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4049692">The Uniqueness of the Rational Bézier Polygon is Unique</a> by Javier Sánchez-Reyes</li>
<li><a href="https://sealedabstract.com/posts/bezier-curvature/">The problem with cubic bezier curvature</a> and <a href="https://math.stackexchange.com/questions/3833973/smoothing-asymptotic-behavior-in-the-curvature-of-a-cubic-bezier">related StackExchange post</a></li>
<li>Special cases to <a href="https://math.stackexchange.com/questions/3024630/arc-length-reparameterization-of-a-cubic-bezier-in-parts">arc length reparameterization of a cubic Bézier</a></li>
<li><a href="https://math.stackexchange.com/questions/3294/how-to-approximate-connect-two-continuous-cubic-b%C3%A9zier-curves-with-to-a-single-o#comment8479_3983">the term for the third-derivative analog of curvature for curves is “aberrancy”</a></li>
<li><a href="https://math.stackexchange.com/questions/1954845/bezier-curvature-extrema/1956264#1956264">Bézier curvature extrema</a></li>
<li>… can time-parameterization cut down on the configuration space of cubic curves too?</li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>It should be possible to only compute the outer segments and skip that step, but for now itʼs better to overapproximate it and optimize later.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Even though weʼre putting a lot of vector information in from the control points of the curves, the coefficients are just scalars, and in fact are even quadratic polynomials in terms of <span class="katex"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>! Knowing that they are quadratic polynomials does not really help things at all.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>I first verified this numerically, but it makes a lot of sense if you think about it.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Note that we arenʼt doing other methods of error reduction, like <a href="https://raphlinus.github.io/curves/2021/03/11/bezier-fitting.html#signed-area">minimizing area</a>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
<item>
<title>Interactive Parser Explanations</title>
<pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
<guid>https://blog.veritates.love/parser.html</guid>
<description><![CDATA[<p>I have been building this framework for explaining, analyzing, and teaching about LR(1) grammars for a couple months now. I hope to turn it into a series of interactive blog posts to explain what parsing is and some approaches we can take to it, most notably <a href="https://en.wikipedia.org/wiki/Canonical_LR_parser">LR(1)</a> parsing. Many notable parser generators like Haskellʼs <a href="https://www.haskell.org/happy/">Happy</a> and the mainstream <a href="https://en.wikipedia.org/wiki/Yacc">Yacc</a>, <a href="https://en.wikipedia.org/wiki/GNU_Bison">Bison</a>, and <a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a> use variants of LR(1), modified for efficiency by reducing the number of generated states.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>The interactive widgets here will allow you to build and verify your intuition by clicking through examples, because I believe that once you are armed with the basic ideas and the right intuition, you can figure out the rest of details for yourself.</p>
<p>Alternatively, it can serve as a playground to test out hypotheses about grammars, see exactly where things go wrong when conflicts occur, and what to do to fix those errors.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>My real goal is to show you how intuitive LR(1) parsing can be! Thatʼs right, thereʼs nothing too advanced or magical going on, just some intuitive ideas carried to their logical conclusions. I used to be scared of parser generators, but once I was introduced to them I followed this approach to understand them for myself and I hope to share that with you.</p>
<p>As (functional) programmers, weʼre used to learning topics in terms of the appropriate datatypes and operations for the job, and thatʼs what I will go through for you here. Hint: weʼll use a lot of monoids!</p>
<pre class="purescript"><code>data ShiftReduce s r
  = Shift s
  | Reduces (NonEmptyArray r)
  | ShiftReduces s (NonEmptyArray r)

instance Semigroup (ShiftReduce s r) where
  -- We do not expect to see two shifts, so arbitrarily prefer the first one
  append (Shift s) (Shift _) = Shift s
  append (Shift s) (ShiftReduces _ rs) = ShiftReduces s rs
  append (ShiftReduces s rs) (Shift _) = ShiftReduces s rs
  append (ShiftReduces s rs) (ShiftReduces _ rs') = ShiftReduces s (rs &lt;&gt; rs')
  append (Shift s) (Reduces rs) = ShiftReduces s rs
  append (Reduces rs) (Shift s) = ShiftReduces s rs
  append (Reduces rs) (Reduces rs') = Reduces (rs &lt;&gt; rs')
  append (ShiftReduces s rs) (Reduces rs') = ShiftReduces s (rs &lt;&gt; rs')
  append (Reduces rs) (ShiftReduces s rs') = ShiftReduces s (rs &lt;&gt; rs')</code></pre>
<p>Thatʼs my big complaint: thereʼs too many numbers floating around in traditional explanations of LR(1) tables, without any indication of what they mean or how they tie together. So I have used semantic formatting to indicate what they all mean: numbered states <span class="state">0</span>, <span class="state">1</span>, <span class="state">2</span> are highlighted differently from named rules <span class="rule">0</span>, <span class="rule">1</span>, <span class="rule">2</span> and differently from number tokens <span class="terminal">0</span>, <span class="terminal">1</span>, <span class="terminal">2</span>. Hopefully the pretty colors will keep your attention!</p>
<p>All of the mechanical steps in generating LR(1) parsers will be broken down and their motivation explained. What does it mean to “close” a state? How do you know what states are next, and when are you done? Why are “reduce–reduce” conflicts bad? Stay tuned to find out!</p>
<p>Skip to <a href="#widgets">Widgets</a> below to start using! Or click this button to see them on their own:</p>
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<h2 id="blog-posts">Blog Posts</h2>
<p>Right now I donʼt have much helpful content below, but I will slowly add more posts. I am finally ready to start writing explanatory content now, after working a lot on the behind-the-scenes code to animate it.</p>
<p>EDIT: this project kind of stalled, sorry. Iʼm still thinking about parsers a lot, but not in this introductory way. You can bug or help me write more ^^</p>
<h3 id="topics">Topics</h3>
<ul>
<li><span data-t="" data-widget="">TODO</span>: <a href="https://blog.veritates.love/parser_by_example.html">Using this tool by example</a></li>
<li><span data-t="" data-widget="">TODO</span>: <a href="https://blog.veritates.love/parser_terminology.html">Terminology reference</a></li>
<li><span data-t="" data-widget="">WIP</span>: <a href="https://blog.veritates.love/parser_basics.html">Basics: What are grammars</a> (BNF, RegExp)
<ol>
<li>Nonterminals and terminals</li>
<li>Sequencing and alternation (regexes)</li>
</ol></li>
<li><span data-t="" data-widget="">WIP</span>: <a href="https://blog.veritates.love/parser_applications.html">Uses of grammars</a>:
<ol>
<li>Generators: nondeterministically generate strings in the grammar by following the rules as state transitions</li>
<li>Recognition: recognize which strings belong to the grammar and which do not</li>
<li>Syntax highlighting: cursed.</li>
<li>Parsing: find an unambiguous parse tree for inputs that belong to the grammar</li>
</ol></li>
<li><span data-t="" data-widget="">WIP</span>: <a href="https://blog.veritates.love/parser_lr1.html">Basics of LR(1) Parsing</a>
<ol>
<li>States</li>
<li>State transitions</li>
<li>Closure of states</li>
<li>Lookahead</li>
</ol></li>
<li>Precedence
<ol>
<li>Refresher on operator precedence</li>
<li>Operator precedence mapped to LR(1) table parsing</li>
<li>Conflict resolution using precedence operators à la Happy.</li>
</ol></li>
<li>Grammars as datatypes
<ol>
<li>AST/CSTs as ADTs</li>
<li>Data associated with tokens</li>
<li>Finding perfect representations, <span data-t="" data-widget="">e.g.</span> no leading zeroes, if you want it to encode data exactly</li>
<li>Common practice of using grammars this way (<span data-t="" data-widget="">e.g.</span> in type theory papers)</li>
</ol></li>
</ul>
<h3 id="ideas-questions">Ideas &amp; Questions</h3>
<ul>
<li>State exploration: current state, next states, previous states</li>
<li>Emulate Happy, especially precedence operators</li>
<li>Can Happy precedence operators be explained in terms of alternative grammars? Can the conflict resolutions always be “pulled back” to a grammar that would generate the same table, or a larger table that represents the same abstract grammar? Does it require quotiented grammars to explain?</li>
<li>Generate example inputs for each state, especially to diagnose conflicts<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></li>
<li>Explain <a href="https://en.wikipedia.org/wiki/Earley_parser">Earley parsing</a> using a similar approach</li>
<li>Better errors!</li>
<li>Hm maybe I can uhh suggest fixes to grammars, has that been done before&nbsp;…
<ul>
<li>at least precedence</li>
<li>other ambiguity fixes are harder, but maybe factoring</li>
</ul></li>
<li>Whitespace</li>
</ul>
<h2 id="widgets">Widgets</h2>
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Widget.Query" data-widget-empty="true" data-widget-datakey="default" data-widget-data-keys="grammar" data-widget-loading="true">

</div>
<h3 id="enter-a-grammar">Enter a grammar</h3>
<p>Craft a grammar out of a set of rules. Each rule consists of a nonterminal name, then a colon followed by a sequence of nonterminals and terminals. Each rule must also have a unique name, which will be used to refer to it during parsing and when displaying parse trees. If ommitted, an automatic rule name will be supplied based on the nonterminal name.</p>
<p>The top rule is controlled by the upper input boxes (LR(1) grammars often require a top rule that contains a unique terminal to terminate each input), while the lower input boxes are for adding a new rule. The nonterminals are automatically parsed out of the entered rule, which is otherwise assumed to consist of terminals.</p>
<p>Click “Use grammar” to see the current set of rules in action! It may take a few seconds, depending on the size of the grammar and how many states it produces.</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.Grammar" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<h3 id="generate-random-matching-inputs">Generate random matching inputs</h3>
<p>This will randomly generate some inputs that conform to the grammar. Click on one to send it to be tested down below!</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.Random" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<h3 id="explore-building-trees-in-the-grammar">Explore building trees in the grammar</h3>
<p>Each rule can be read as a transition: “this nonterminal may be replaced with this sequence of terminals and nonterminals”. Build a tree by following these state transitions, and when it consists of only terminals, send it off to be parsed below!</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.Explorer" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<h3 id="see-parsing-step-by-step-on-custom-input">See parsing step-by-step on custom input</h3>
<p>Text entered here (which may also be generated by other widgets below) will be parsed step-by-step, and the final parse tree displayed if the parse succeeded. (Note that the closing terminal is automatically appended, if necessary.) Check the state tables above to see what state the current input ends up in, and the valid next terminals will be highlighted for entry.</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.Input" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<h3 id="list-of-parsing-states">List of parsing states</h3>
<p>To construct the LR(1) parse table, the possible states are enumerated. Each state represents partial progress of some rules in the grammar. The center dot “•” represents the dividing line between already-parsed and about-to-be-parsed.</p>
<p>Each state starts from a few seed rules, which are then closed by adding all nonterminals that could be parsed next. Then new states are explored by advancing on terminals or nonterminals, each of which generates some new seed items. That is, if multiple rules will advance on the same (non)terminal, they will collectively form the seed items for a state. (This state may have been recorded already, in which case nothing further is done.)</p>
<p>When a full rule is parsed, it is eligible to be reduced, but this is only done when one of its lookaheads come next (highlighted in red).</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.StateTable" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<h3 id="table-of-parse-actions-for-each-state">Table of parse actions for each state</h3>
<p>Once the states are enumerated, the table of parse actions can be read off:</p>
<p>Terminals can be “shifted” onto the stack, transitioning to a new state seeded by pushing through that terminal in all applicable rules in the current state.</p>
<p>Completely parsed rules will be “reduced” when their lookahead appears, popping the values matching the rule off of the stack and replacing it with the corresponding nonterminal, which then is received by the last state not involved in the rule.</p>
<p>Nonterminals received from another state trigger “gotos” to indicate the next state.</p>
<p>Two types of conflicts may occur: if a terminal indicates both a shift and reduce actions (shift–reduce conflict) or multiple reduce actions (reduce–reduce conflict). Note that there cannot be multiple shift actions at once, so most implementations (including this one) choose to do the shift action in the case of shift–reduce conflict.</p>
<div class="widget-group">
<div data-widget="Widget.Control" data-widget-datakey="main">

</div>
<div class="widget" data-widget="Parser.ParseTable" data-widget-datakey="default" data-widget-loading="true">

</div>
</div>
<div data-widget="Widget.Control" data-widget-datakey="main" data-widget-parent="#TOC">

</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Specifically LALR(1) is the most common alternative, and it cuts down on states by merging ones that are the same except for their lookaheads. We will not focus on any of those details in this series, most likely.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Have you ever had to debug a Happy grammar by opening up the <a href="https://www.haskell.org/happy/doc/html/sec-invoking.html"><code>.info</code></a> file? Itʼs overwhelming!<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>currently it only generates example inputs for nonterminals/productions<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></description>
</item>
</channel>
</rss>
